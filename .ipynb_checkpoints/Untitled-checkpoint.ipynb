{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18aaffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bridgeon/miniconda3/envs/gptenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments,get_scheduler\n",
    "from torch import nn, optim \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0eab043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"heegyu/gpt2-emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c39eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('heegyu/gpt2-emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2535ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class movRevDataSet(Dataset):\n",
    "    def __init__(self,root_dir,transform = None):\n",
    "        self.root_dir = root_dir \n",
    "        self.transform = transform\n",
    "        self.file_list = os.listdir(root_dir)\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.root_dir, file_name)\n",
    "        with open(file_path, 'r', encoding = 'utf-8') as file:\n",
    "            txt = file.read()\n",
    "#         label = int(file_name.split('_')[1].split('.')[0])\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5856664",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataRoot = './aclImdb/train/merged'\n",
    "testDataRoot = './aclImdb/test/merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b761cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movRevTrainDS = movRevDataSet(root_dir=trainDataRoot)\n",
    "movRevTrainDS, movRevValDS = torch.utils.data.random_split(movRevTrainDS,[0.8,0.2])\n",
    "movRevTestDS = movRevDataSet(root_dir= testDataRoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4abb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "movRevTrainDL= DataLoader(movRevTrainDS, batch_size = 8, shuffle= True, )\n",
    "movRevValDL = DataLoader(movRevValDS, batch_size =8, shuffle = True, )\n",
    "movRevTestDL = DataLoader(movRevTestDS, batch_size = 8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe60aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "['A missed train. A wrong phone number. An extra cup of coffee. What happens to those around you when you make a seemingly innocuous decision? Most people don\\'t give it a thought as they absorbed in their own thoughts and actions.<br /><br />\"Happenstance\" tells the story of the interrelations and cause-and-effect of the mundane as it pertains to a group of normal Parisian folk. It has all the components of what passes for contemporary theater, with the full cast of the dysfunctional and disillusioned.<br /><br />There\\'s a cheating husband, an illegal immigrant, a classic slacker, a pickpocket, a crazy grandmother, an annoying girlfriend, a selfish roommate, and a homeless man. Audrey Tautou serves as the erstwhile protagonist (in the sense that she\\'s on camera as much as anyone else and opens and closes the film) and normal girl who just can\\'t seem to find the right rhythm in her life.<br /><br />She learns at the beginning of her day from a stranger on a train what her horoscope holds for her. What happens to her in the course of the day is told through various characters. Does the prediction come true? The concept is good, but the storytelling is flimsy. The connections from one event to the next are weak. There\\'s better storytelling in 15 seconds of the Liberty Mutual insurance commercial where one person sees a good deed and passes it along to another than there is in two hours of Happenstance.<br /><br />If you enjoy Audrey Tautou, then you certainly can sacrifice the time for this film, but you\\'ll finish it dissatisfied and wondering what this same storyline could be if it were handled by a better producer and director.', '\"The Last Hard Men\" is a typical western for the 70\\'s. Most of them seem to be inspired by Sam Peckinpah. Also this one, but Director Andrew McLaglan is a John Ford Pupil and this can be obviously shown in many scenes. IMO the beginning is very good. In a certain way McLaglan wanted to show the audience a travel from the civilization to the wilderness. In the third part there are some illogical flaws and I complain a bit about Charlton Heston. He has to play an old ex-lawman named Sam Burgade but he is in a fantastic physical shape. I never got the feeling that he really has problems to climb on a horse or on a rock. For me he didn\\'t looks very motivated as he usual do in most of his epic movies. Same goes to the beautiful Barbara Hershey who is playing the sheriff\\'s daughter. Maybe both had troubles with the director or were unhappy with their roles. Hershey and Coburn are not showing their best but they are still good. If the scriptwriter had John Wayne in their mind as Sam Burgade? Also Michael Parks as modern sheriff is a bit underused in his role. On the other Hand there is James Coburn as outlaw Zach Provo. Coburn is a really great villain in this one. He is portraying the bad guy between maniac hate and cleverness. His role and his acting is the best of the movie.<br /><br />Landscapes and Shootouts are terrific. The shootings scenes are bloody and the violence looks realistic. Zach Provo and his gang had some gory and violent scenes. What I miss is the typical western action in the middle of the movie. I would have appreciated a bank robbery or something similar. Overall it\\'s an entertaining western flick. Not a great movie but above the average because of a great Coburn, a very good beginning and some gory and violent scenes.', \"After Life is a Miracle, I did not expect much. It's hard to believe that these films were made by the same man as Do You Remember Dolly Bell, for instance. Zavet is two hours of silly antics with no story. The wild and unbridled humor of Underground seems to have degenerated into pathetic buffoonery here. It appears that Kusturica has been going steadily downhill since he started making life-affirming comedies, beginning with Black Cat, White Cat, which I think was great, but already had some disturbing signs of dementia. I liked his early films so much, and this is why it's especially disappointing to see something like this. Let's hope his next one will be great.\", 'This film has a powerful philosophical ending. But that ending has meaning only if you watch the movie from the beginning.<br /><br />Youth alienation in the late 1960\\'s, from the viewpoint of a young man and a young woman, is the obvious theme of \"Zabriskie Point\". Neither Mark Frechette nor Daria Halprin had much acting experience, a fact that actually enhances the film\\'s message. Having untrained actors conveys a sense of realism, as both players seem emotionally detached from the turmoil around them.<br /><br />This is not a script-driven film. Except for the first ten minutes, it is mostly visual, with stunning cinematography. The beautiful naturalistic images seem other-worldly, and perfectly in sync with the emotional detachment of Mark and Daria.<br /><br />I would have replaced the thematically weak Pink Floyd music with the more cogent music of The Doors. Many scenes cry out for \"Riders On The Storm\".<br /><br />Even so, I like this film. It\\'s different; it\\'s unique; it is artistic and imaginative. And the desert badlands are beautiful.<br /><br />As the years go by, \"Zabriskie Point\" seems more and more attractive. It conveys the mood of the late 1960\\'s in America. It is amazingly artistic, in a bohemian sort of way. And the film\\'s last eight minutes are philosophically mesmerizing.', 'If it wasn\\'t for some immature gullible idiot I know insisting that I watch this \"documentary\" I would never have seen this comedy! This film is full of bad scripting and laughable moments. One in particular is where the Afghan police / soldiers arrest Don Larson for filming in the streets while they allow the cameraman to carry on filming his arrest and then drive away, still filming, presumably to his plush hotel. Then there\\'s the scene where a car crashes into another car which has been turned upside down and parked nicely on the side of the road without any evidence of it being in a crash or explosion.<br /><br />I am surprised this has currently got the rating it has (5.8 / 10). I thought IMDb users had more sense.', \"Yes i'll say before i start commenting, this movie is incredibly underrated.<br /><br />Sharon Stone is great in her role of Catherine Trammell as is Morrissey as Dr glass. He is an analyst sent in to evaluate her after the death of a sports star. Glass is drawn into a seductive game that Trammel uses to manipulate his mind.<br /><br />The acting was good (apart from Thewlis)<br /><br />Stone really has a talent with this role. She's slick, naughty and seductive and doesn't look a day older than she did in the first.She really impressed me(like in Casino). Morrisey was also good. He showed much vunerablitity in a role that needed it. Thewlis however was lame. He ruined his character and was over-the-top the whole way. He really sucked.<br /><br />Overall, this movie not as good the first but Stone is a hoot to watch. Just ignore Thewlis.\", \"This was the beginning of it all! Granted, this is not Friends at its best, but this was the show's pilot, let's not forget and not a bad one at that. We're introduced to the gang and Central Perk, where our story begins. Even from this first episode we get a sign of the Ross-Rachel relationship that will come over the next ten years, when Ross says: 'I just want to be married again' and Rachel storms in with a wedding dress on... probably not intentional as at the time the writers were going for a Monica-Joey relationship but fits nicely now when looking back. Something else.. in this episode Rachel is introduced to Chandler as if the two have never met before but in later episodes, the so-called 'flashbacks' this is contradicted as the two have met on three previous occasions. Nevertheless, the point is this a fine start to a great show. This episode may not be the usual Friends as we are accustomed to them, with the cast still a bit inexperienced but over the next few episodes we see why the show came to be what it was! Keep watching, first season is a blast!!\", 'PLEASE TAKE A MINUTE TO READ MY ENTIRE REVIEW. I AM NOT KNOCKING THE FILM ITSELF - ONLY THE DVD VERSIONS CURRENTLY AVAILABLE.<br /><br />***<br /><br />I really wanted to give this film even two stars. I mean how could it possibly rank a mere 1 out of 10!?!<br /><br />Here\\'s how: An epic film adaptation of Tolstoy\\'s novel \"War and Peace\" with historically accurate battle scenes, courtesy of the Red Army, and an extremely faithful, scene-for-scene adaptation of the novel would be difficult but worth sitting through for seven hours - if that\\'s what you were seeing.<br /><br />The trouble is you can\\'t see that film - anywhere as far as I know.<br /><br />I am attempting to watch the RusCiCo DVD version - widely considered the best version available since it\\'s letter boxed and restores the scenes that were cut from other DVD releases. <br /><br />But, it is one of the worst film prints I\\'ve ever seen transfered to DVD. The picture is muddy and inconsistent, often strobing. It\\'s almost tolerable if you crank your brightness, color and picture levels up to maximum.... but the problem doesn\\'t end there.<br /><br />The sound is also way inconsistent, blaringly loud in parts, virtually inaudible in others. <br /><br />And as for languages, it\\'s a HUGE problem for English speakers - the dubbed option has some good actors, and some really terrible ones whose performance grates, and parts of the film just aren\\'t dubbed at all, slipping back into Russian and even French randomly.<br /><br />The subtitled option isn\\'t much better. The subtitles don\\'t appear below the image, but right over it - obscuring some of the beauty (or what\\'s left of it) in the scenery. Furthermore, the subtitles are often a poor translation (a shame given that the script took pains to hew so close to Tolstoy\\'s actual words), and the subtitles too seem to just drop out in parts. <br /><br />So, even if you max out the color, brightness and picture settings, and turn the volume way up, and choose subtitled *and* English dubbed, you\\'re still going to get a film that\\'s annoying to watch and listen to.<br /><br />Can it\\'s content overcome that? It might have been able to, but at seven hours - who can stand it for that long?<br /><br />Maybe someday, someone will come along and restore this - and maybe then I will see a masterpiece - but for now, I just can\\'t give more than one star to something I\\'ve only been able to stand watching about the first 12% of.']\n",
      "Sample 2:\n",
      "[\"Personally, this is one of my favorites of all time! no, i'm not 10.. i'm 30! i own an old, original VHS of this that i bought from a rental store. i've watched it countless times..<br /><br />while it's an amusing movie for kids, it's an intriguing movie for adults. i once saw this movie whiile i was.. not sober. my eyes were opened to things i had never noticed before. i saw morals being strongly encouraged, both overtly and somewhat subliminally.. i wish i could remember all the things i noticed in particular, but it's been a very long time since then. rest assured, there are TONS of things that are alluded to throughout the movie. if you get the chance to view it.. not sober.. do so, you won't be disappointed.. as a matter of fact, you will probably feel rather happy and warm.<br /><br />unique and wonderful!\", \"This show comes up with interesting locations as fast as the travel channel. It is billed as reality but in actuality it is pure prime time soap opera. It's tries to use exotic locales as a facade to bring people into a phony contest & then proceeds to hook viewers on the contestants soap opera style.<br /><br />It also borrows from an early CBS game show pioneer- Beat The Clock- by inventing situations for its contestants to try & overcome. Then it rewards the winner money. If they can spice it up with a little interaction between the characters, even better. While the game format is in slow motion versus Beat The Clock- the real accomplishment of this series is to escape reality. <br /><br />This show has elements of several types of successful past programs. Reality television, hardly, but if your hooked on the contestants, locale or contest, this is your cup of tea. If your not, this entire series is as I say, drivel dripping with gravy. It is another show hiding behind the reality label which is the trend it started in 2000.<br /><br />It is slick & well produced, so it might last a while yet. After all, so do re-runs of Gilligan's Island, Green Acres, The Beverly Hillbillies & The Brady Bunch. This just doesn't employ professional actors. The intelligence level is about the same.\", 'Although the plot was a bit sappy at times, and VERY rushed at the end, as if the director had run out of his alloted time and needed to hurry up and finish the story, overall it was pretty good for the Made-For-Backwoods-Cable-TV genre. <br /><br />However, the actress who played the babysitter, Mariana Klaveno, was very good! I hope to see more of her around in movie-land. The music was also well done, getting every possible chill out of the dah-DUH-dah-DUH (think \"JAWS\") type music-based tension build-ups.<br /><br />I don\\'t think I\\'d want to watch \"While the Children Sleep\" again, but if I did, it would be to focus on the performance of the talented Klaveno.', 'I guess this is meant to be a sort of reworking or updating of \"Beauty and the Beast\", but I can\\'t say I\\'ve ever watched a movie that began with several minutes of graphic horse sex. Wow. Anyway it seems that a young woman and her..aunt? Have traveled to this castle in France where the woman is to be married to the son of the castle owner, who is the man who takes care of making sure the horses get their rocks off. It seems that there are legends in that area of a beast that was rather, uh, frisky, I guess you could say, with the ladies, or at least, one in particular. There are all kinds of references tucked away in that regard but every time the soon-to-be-blushing young bride gets her curious little hands on one the groom\\'s father removes it from her sight. Anyway, the young bride-to-be goes upstairs to sleep while the family is waiting for a Cardinal to show up to the wedding (a family member, I guess) and as she dreams she dreams of a beast in the woods that has its way with her. The effects in this leave a little to be desired, and any attempt at eroticism (not that I know much about that) is kind of rendered laughable, especially when certain featured appendages appear about as realistic as a bed post or a baseball bat. This has a rather strange and abrupt, yet twist ending, with not really any clues or much build up to it, but it was kind of fitting and definitely not what I expected. I don\\'t know, this is kind of a tough one to get through but it has its moments and is definitely weird. 7 out of 10.', 'This is the least scary film i have ever seen. How the blob manages to eat anyone is the biggest mystery of the film. The blob moves so slowly that an o.a.p in a zimmerframe could escape it. The blob has a large slice of luck coming across a typical horror film woman who instead of running away stands still for half an hour so that she can be eaten. If you havent seen this film i recommend you do, its far too funny to be taken seriously.', 'I could not believe the low 5.6 rating on IMDb about Johnny Dangerously at the moment I wrote this review and I thought I had to do something to promote that memorable piece of comedy as much as I can. Seriously, to get a rating so low, the people who voted must have a very limited sense of humor, not to mention a very shallow opened mind. If you don\\'t like humorous flicks, don\\'t watch them! Combining absurd humour, a very good storytelling, and an outstanding pace given by the multiple running gags, this movie has made its way into my DVD collection. And that is without mentioning the visual farces embedded here and there and of course, the use of \"clin d\\'oeils\" and \"clichés\" based on our favorite organized crime movies. <br /><br />I showed this movie to a lot of people and, being introduced to it without any specific expectations (except maybe watching a comedy)- the very state of mind you should have to watch any movie in my opinion - they all liked it very much. It goes well, it\\'s not long to watch and there are absolutely no slowing downs in the evolution of the story, which I think is really straightforward. Sure it\\'s not perfect, some gags fall a bit short, but no movie is perfect, especially when considering other opinions that yours. That is why I rated this movie 9 out of 10. This movie is in my opinion a precursor like \"Top Secret\" and \"Spaceballs\" in the field of absurd but well-thought comedies. Which are nowadays more and more absurd while cutting down on the thought and ingeniosity side. Sometimes gags need more culture than a lot of people imagine to be understood correctly, if at all. As a final word, I would like to say : watch it for yourself, do not follow average Joe\\'s saying and if you don\\'t like it, then you\\'ll know for real it was not good for your tastes, which is understandable but unlikely in my opinion.', \"I was never quite sure where this thing was going. These people seem interested in what is going on on some mountain. They investigate, have narrow escapes, leave, come back, leave, put each other in danger, sleepwalk, get attacked by witches who have consistent wardrobes, etc., etc. The guy seems to like the girl, but leaves her unprotected numerous times. She gets taken off, he gets her back, leaves her again. You get the point. The whole thing seems to get around to some sort of sacrifice, I think, but I'm not sure, or turning people into witches, but I'm not sure. It's just dull and endless and not worth the time. There are some atmospheric scenes, but the print is so bad that there times when twenty seconds of blackness is not unusual. Is this caused by age or the overuse of night filters.\", \"I found the characters mediocre and the story uninteresting. I never had to read this book (thankfully), or it would have been a painful experience. I got the tickets to the preview for free but it still wasn't worth my time, or my friend's. I think this story is not worth telling. It's like saying that old people have a past before they got old (no kidding). The lives of the main characters were painful to watch, one generation no better than the next at avoiding stupid mistakes. However, I think the actors did the best they could with a lame story. I've always been a big fan of Ellen Burstyn. I'm writing this review to counteract the positive reviews given, which unfortunately convinced me to give this movie a try.\"]\n",
      "Sample 3:\n",
      "[\"A somewhat dull made for tv movie which premiered on the TBS cable station. Antonio and Janine run around chasing a killer computer virus and...that's about it. For trivia buffs this will be noted as debuting the same weekend that the real life 'Melissa' virus also made it's debut in e-mail inboxes across the world.\", 'I rented this DVD for two reasons. A cast of great actors, and the director, even though Robert Altman can be hit or miss. In this case, it was a big miss. Altman\\'s attempt at creating suspense fell on its keester. After seeing Kenneth Branagh in a good film like \"Dead Again\", I didn\\'t think he could possibly contribute to such a turkey, and I hope it didn\\'t ruin his reputation. Robert Duvall seems to have fallen the way of most one-time Oscar winners. On a downward spiral that includes acting in eating-money films such as this one. Duvall was once a great actor in excellent films, even though his best performance was not \"Tender Mercies\", but \"The Great Santini\". This movie was truly a big waste of time. I give it a 2 out of 10.', 'It\\'s somewhat telling that most of the great reviews for the film on IMDb all come from people who have only reviewed one film in their entire IMDb career and yes you\\'ve guessed it, that film is \"Parasomnia\". I\\'ve often suspected suspiciously good reviews on IMDb for what turns out to be an anything but good films as underhand marketing , but it seems fairly transparent in this case.<br /><br />That\\'s not to say Parasomnia is terrible, but it stops well short of being the good or great film it had the potential to be.<br /><br />On the plus side, it has a great baddie in Patrick Kilpatrick who does a brilliant job projecting menacing and evil, I could easily see him having what it takes to play a truly memorable baddie on a par with Hannibal Lecter. There are some beautiful visuals in the dream sequences, in fact if the film had decided to explore that terrain more it might have been something better. The actual concept of devious misuse of hypnosis is great too.<br /><br />Although I understand suspension of disbelief is necessary for immersion in any good story, it\\'s the mark of a good story that it succeeds in letting you do that. If you find yourself being annoyed at what you find illogical or just plain silly, then the story is losing you and that\\'s what kept happening to me with this film. Other reviewers have mentioned this here and I don\\'t want to get into spoiler territory, but I will say the setup at the ending was particularly ludicrous and disappointing, not too mention the varying mental age of a character that is only supposed to have experienced a few years of life.<br /><br />All in all, there is the germ of a great idea here in diabolically misused hypnotism, but sadly this film fails to realise it into anything special.', 'Good historical drama which is very educational and also very entertaining to people who like history.Very good acting and script.Not as sensual and sexy as it is sometimes marketed,be prepared to peek into the pioneer spirit and human ability to adjust.Very touching as well for the spiritually mature. Not for people who do not like to think......', \"If you're a T-Rex/Marc Bolan fan, I recommend you check this out. It shows a whimsical side of Marc Bolan as well as Ringo Starr, apparently having a pretty good time shooting some of the scenes that aren't part of the concert, but fun to watch, leaving you with a sense of getting to know them as just people, and when the concert is shown a talented musician, both playful and professional that rocks and seems to impress the screaming girls. Watching him in concert, you would never know that being a rock star is a job, but just having a great time playing some great songs with some good friends, like Elton John and Ringo Starr appearing in some of the live performances. True, there are a few songs missing that I would like to have seen on there, but like any album it can't have everything. I just bought this in 2006, but if I would have know it came out in 1972, I would have definitely bought it years ago. Sad and strange that a man with so many songs about his love for cars, would never learn to drive and would die in a car crash!\", 'Over-powered mobile suits that can annihilate entire armies - Check! Weapons that hardly need to be aimed and still annihilate everything - Check! Mobile suits based on angels - Check!<br /><br />OK - its a Gundam series. This one, Gundam Wing, has good character development, real-world complexity, interesting ideas and some pretty eye-candy.<br /><br />With characters, the initially weak Relena Dorlan (later Peacecraft, then back to Dorlan) gets stronger and more independent (although is still absolutely besotted with Heero Yuy, the series main character). The aforementioned Heero, initially a cold, hard butcherer, becomes more and more human, while still remaining in-character. And seeing the lost Millardo Peacecraft (whos nomm de guerre is Zechs Marquise) float between OZ, freelance, and command of White Fang shows how some people can really lose themselves in their own creations.<br /><br />The complexity of the political and military situation is also quite good - reflecting how the real world works. However, in 49 half-hour episodes, it does become a bit of a liability in that this complexity isn\\'t used to its full potential.<br /><br />The ideas at the core of the series - the necessity of fighting, the desire for peace, etc - are ones that resonate even today. In retrospect, the series was ahead of its time, what with the \"War on Terrorism\" and all. But its exploration of these ideas, the monologues, especially those of Treize Kushrenada, is an incredible dramatic piece, forming some of the best writing in the series.<br /><br />But that sometimes good writing is also sometimes extremely poor, which dramatically causes it to lose some of its edge.<br /><br />In terms of eye-candy, which is what this one has in bucketloads, everything from the mobile suits to the battleship Libra (No not the tampons you idiot!) is wells designed, and explodes in big balls of orange (which is bad, because better animation would\\'ve had better explosions). But who cares?! Stuff explodes, and thats all that matters.<br /><br />In short though, the sheer complexity of the series means that if you miss out on a few episodes, you\\'ve missed out on a lot. The poor writing can leave you cringing, and sometimes the animation makes you go \"WTF?!?!\" But this is made up for in its classic animation style, its scale, sparks of incredible dialogue, and its more mature exploration that one expects of such Japenese animations.', 'This has to be one of the worst films I have ever seen. The DVD was given to me free with an order I placed online for non DVD related items.<br /><br />No wonder they were given away, surely no one could part with money for this drivel.<br /><br />How some reviewers can say they found it hilarious beggars belief, the person who includes it in the worst five films ever has got it spot on.<br /><br />How on earth a talented actor like Philip Seymour Hoffman could get involved in this rubbish is unbelievable. Mostly toilet humour and badly done at that.<br /><br />Anyone wanting to be entertained should avoid this at all costs.', 'This movie really, i mean REALLY, sucks. Its got plot holes so big, and 30 foot dragon can fit through them. Not to mention the dragon itself, which is inevitably the worst computer generated image ever to be put on the film real. I mean, when you see something like this, you gotta be thinking \"Wow, someone actually made this movie. Then released it. That takes guts\". Whoever they are, i\\'m sure they don\\'t work in the film business anymore.<br /><br />When i hired this movie, it wasn\\'t in on DVD, so i (reluctantly) took it out on video. The first thing to appear, was a Lord of the Rings trailer, for the Two Towers. This was a very clever move, putting this trailer on the video. It justifies me (reluctantly) giving the film 1 star, otherwise i would have given it zero stars. Maybe the producers though the star attraction of Dean Cain (I think thats how you spell it) would draw in the crowds (uh, to the video store that is).<br /><br />Next they employed split screen technique (like in Hulk) to (i assume) compensate for what an atrocity this piece of crap film is. On the box cover, we see a picture of our hero, and the dragon. Does the dragon look exactly like the one in Dragonheart, or is it just me? Either way, the dragon in the film looks like a reject from Gremlins 2, and has the CGI of a Nintendo video game villain from the early 90\\'s (perhaps worse). Also, not the Dragons movement as it pursues its victims- its the same F##cking monotonous movement- right leg, left leg, right leg left leg- dom, dom, dom, dom DOM, DOM F#$king DOOOOOM! This just pisses me off. Maybe the filmmakers thought this was thrilling and would have the same effect of Jaws. Why not then have a Dragon POV shot. Either way, that was just funny, much like watching a Weebl toon.<br /><br />Dean Cain gives many puzzled looks during the film (maybe his coming to terms with the fact that this film could end his career). Don\\'t expect Superman here. The first time i saw the trailer for this film, i thought it was an add for a PS2 game.<br /><br />As for the story, its so so bad, my 5 year old brother can come up with better ones when he\\'s unconvincingly trying to lie about why he was messing around in my room while i wasn\\'t there. Oh, and did i mention that I F@#KING HATE THE PEOPLE WHO MADE THIS INCREDIBLY STUPID STUPID CRAP ATROCIOUS FILM?!!!']\n",
      "Sample 4:\n",
      "['This is not really a zombie film, if we\\'re defining zombies as the dead walking around. Here the protagonist, Armand Louque (played by an unbelievably young Dean Jagger), gains control of a method to create zombies, though in fact, his \\'method\\' is to mentally project his thoughts and control other living people\\'s minds turning them into hypnotized slaves. This is an interesting concept for a movie, and was done much more effectively by Fritz Lang in his series of \\'Dr. Mabuse\\' films, including \\'Dr. Mabuse the Gambler\\' (1922) and \\'The Testament of Dr. Mabuse\\' (1933). Here it is unfortunately subordinated to his quest to regain the love of his former fiancée, Claire Duvall (played by the Anne Heche look alike with a bad hairdo, Dorothy Stone) which is really the major theme.<br /><br />The movie has an intriguing beginning, as Louque is sent on a military archaeological expedition to Cambodia to end the cult of zombies that came from there. At some type of compound (where we get great 30s sets and clothes) he announces his engagement to Claire, and then barely five minutes later, she gives him back his ring declaring her love for his pal, Clifford Greyson (Robert Noland). It\\'s unintentionally funny the way they talk to each other without making eye contact. This would have been a great movie for \\'Mystery Science Theater 3000\\', if they hadn\\'t already roasted it.<br /><br />It\\'s never shown how Louque actually learns the \\'zombification\\' secret, but he then uses it to kill his enemies, create a giant army of rifle carrying soldiers and body guards. We won\\'t see such sheer force of will until John Agar in \\'The Brain From Planet Arous\\' (1957).<br /><br />Finally Claire consents to marry him if he will let Greyson live and return to America. Louque agrees, but actually turns him into one of his hypnotized slaves. On their wedding night he realizes that Claire will only begin to love him if he gives up his \\'powers.\\' To gain her love, he does so, causing the \\'revolt\\' of the title, in which all his slaves awaken and attack his compound and kill him. Greyson embraces Claire, and we seem to be at the end of a parable: \"Whom the gods would destroy, they first make mad.\" <br /><br />So really then, it\\'s not that bad of a film, despite the low IMDb rating it currently has. On repeated viewings (?) one can see the artistry in the well formed script! Dean Jagger had yet to develop into a good actor, and is almost unrecognizable in his youngness -- is that really his own hair? We remember him more for his bald, old man roles in \\'White Christmas\\' (1954), \\'X The Unknown\\' (1956) and \\'King Creole\\' (1958). The story borrows a lot of its basic themes from the Halperin brothers better, earlier film \\'White Zombie\\' (1932) in which hapless Robert Frazier (as Charles Beaumont) uses \\'zombification\\' to win the love of Madge Bellamy (as Madeline Parker).<br /><br />If you want real zombie movies (of which there are hundreds!) I\\'d start with \\'White Zombie\\' (1932), \\'King of the Zombies\\' (1941), \\'I Walked with a Zombie\\' (1943), \\'Night of the Living Dead\\' (1968), \\'The Last Man on Earth\\' (1964) and its two remakes. In the modern era of classy films, there are \\'Horror Express\\' (1972), \\'The Serpent and the Rainbow\\' (1988), \\'28 Days Later\\' (2002) and its sequel, as well as many, many, others too numerous to mention.<br /><br />This one is not really a zombie film. Judging this movie on its own terms, it\\'s more of a semi-Gothic romance. As such it ranks a little below some of Universal\\'s bottom billed B horror movies of the late 30s and early 40s. So I\\'ll give it a 5.', \"This is one of the few episodes (if not the only one) with an indisputable error in its storytelling. While handling the Ralphie situation Christopher states that he has heard about Pie-O-My's death in the fire accident. This is an important detail because in this context it is quite obvious that Christopher knows from the beginning that Tony is the one who must have killed Ralphie. There is however no way Chris could have heard about the accident. Who should have told him and when? By the time he is torn out of his delirium by Tony's call nobody else was informed. Tony knows that - which makes it even worse! Hearing Christopher talk about Pie- O-My's death could therefore only lead Tony to the conclusion that Chris himself has set the fire. Given the impressively elaborate writing process as told by the writers themselves on the DVD I really wonder none of them realized the problem there. The story just doesn't work that way. Unnecessary to add that I'm a huge fan of the Sopranos. Otherwise, I certainly wouldn't care.\", \"And how it made it into production astounds me. The main character is an obnoxious show off who isn't the least bit funny. I can't stand the character at all. He's a dumb ass with nothing to offer the show. <br /><br />This is the worst cartoon to surface in the last 10 years, no joke. The story lines are both poorly written and executed. The jokes are as bad as the ones on Disney's Sweet Life of Zack and Cody. I could not dislike this show more, it's terrible and should be canceled. Even the theme song is bad. The title, even worse.<br /><br />It's as though this show is written by a couple of 15 year olds that based the character on themselves and think they're hot stuff when they're really just arrogant and lack creativity as well as humor.<br /><br />Johnny Test, go away far and fast!\", \"Gypo Nolan (Victor McLaglen) is as poor as anyone on Earth. Living in 1920s Ireland, Gypo and his fellow Irishmen are part of an underground rebellion against the oppressive Brits. One particular rebel, wanted for murder by the English, arrives back into town secretly. He thinks he can trust his friend Gypo, but the £20 reward proves too tempting. Gypo gets his friend killed and sinks into a pit of despair and drunkenness. Meanwhile, the other Irish rebels are searching for the informer. Right away, Gypo, with money burning a hole in his pocket, is their main suspect, but they, who are his friends, don't want to believe it. The story of The Informer is simple in its plot, but complex in its moral and emotional issues. It's easily one of John Ford's most emotionally involving films. What Gypo did was wrong, but we can certainly understand his motives. We also understand his sorry character, and there's a lot of sympathy that arises for him. The script is very suspenseful, as well. It's the kind of suspense where we are pretty sure we know how everything will end up, so we have to grit our teeth and bear along with it. The acting is remarkable. Victor McLaglen, who acted in many of Ford's films, probably gave his best performance here (and won an Oscar for it). Every other performer in the film deserves his or her kudos. In addition to an amazing script and acting, The Informer is one of John Ford's most expressionistic films. I love the darker side of Ford. In its mood, as well as in its themes, The Informer reminds me of two of my other favorite Ford films, The Long Voyage Home (1940) and The Fugitive (1948); it's also a bit similar to The Grapes of Wrath (1940) in these respects. 10/10.\", 'Wow! Wow! Wow! I have never seen a non-preachy documentary on globalization until I saw MARDI GRAS: MADE IN CHINA. This film has zero narration and combines verite footage with sensitive interviews with four teenage workers in China who live inside a factory compound. They play with toys, jump rope, and dance. Yet, the majority of their days and nights consist of work, work, and work -- but the footage of their work is illuminating and mesmerizing to watch. The owner of the factory in China is amazingly open, so much so that he hits home the effects of globalization while he \"punishes\" the workers. Astutely following Mardi Gras beads from China to the Carnival, the film reveals how the local is connected to the global through humor and interesting, compelling footage from both cultures. One of the most interesting parts in this film is the cross cultural introduction of factory workers and Mardi Gras revelers to each other through pictures. Here, the film comes full circle and shows how images can be a point of communication and transformation. The film is never preachy, is not guilt driven, and allows everyone\\'s point of view to be present. At the end, we -- the viewers -- make up our own conclusions about the complexity of the film, and globalization.', '\"Panic\" is a captivating, blurred-genre film about a brooding and conflicted middle aged hitman\\'s reconciliation of infatuation with a younger uninhibited hairstylist, his love of wife and son, his duty to his employer/father with his own identity. Although the film has a nebulous purpose and an ambiguous ending, it is a superb production in almost all aspects. The characters\\' clarity and sincerity in such an improbable story may both fascinate and annoy audiences.', 'This movie is basically about some girls in a Catholic school that end up getting into trouble because of putting red dye in one in one of their school mates shampoo and after being reprimanded for this act they decide to take off to Florida for a vacation. On their way there they meet up with some guys in a local diner and decide that they would both meet up with each other in another location later on. The girls end up on a road side near the woods and stop for awhile and while one of the girls decides to walk around a bit she sees a murder happen in which the local sheriff himself is involved. She becomes scared and runs to tell the others what happened. The other girls decide to go take a look with her and two of them get killed by the killer. Then the two remaining girls are caught by the killer and are placed in local jail cell. The deputy sheriff meanwhile is keeping watch over the girls and despite their insistence that the sheriff is the killer he ignores them both and acts as ignorant and everybody else in this movie who just can\\'t put two and two together much less some lousy detective work at that. The best part was the rape scene between the killer and one of the girls where he decides to rape her in her jail cell and it seems that the girl actually WANTS to be raped by this man and the bare chest scene I admit was good but before their lips meet he has other things in mind. This movie reminds me of the low-budget thriller \"Blood Song\" with Frankie Avalon staring in it, the same motive just a different character part. It\\'s not a movie worth renting not even for an 80\\'s low-budget movie and the ending was the worst ending I have ever seen in a movie and it left me wanting my money back!', 'With a well thought out cast, this movie was a great comedic relief. The plot is well-written and the cast was knockout. Every bit as good as the reviews suggested (a rarity) and was highly entertaining. Being a huge John Candy fan myself, this movie was no disappointment.']\n",
      "Sample 5:\n",
      "['Well, I couldn\\'t even enjoyed this movie much for its cult values. It\\'s a B-movie action-flick, by the director of \"Commando\", that is however far too lame and silly to consider it a good B-movie with enough entertainment value in it.<br /><br />It\\'s an \\'90\\'s flick but foremost the movie should remind of an \\'80\\'s action movie, when these type of B-movies were at an all time high. These movies always went over-the-top and never paid much attention to its story or acting. It was all about blowing stuff up, big muscle heroes and bullets flying around. This movie has all of that ingredients in it but yet I really didn\\'t liked watching this movie as much as I like watching some similar type of movies. Hard to say why really, since the story and acting and such are just as bad as would be the case in basically any other genre movie from the same era.<br /><br />It\\'s probably because the movie is being often far too silly. All these type of movies have its silly moments but this movie is just filled with it. The fighting, Dolph Lundgren running around shirtless, the characters, the story. It all just isn\\'t very good because it\\'s often just too lame for words. The story at times isn\\'t even trying to make a bit sense and what\\'s even the main plot-line of the overall movie? Its story is all over the place really and seems only to be written to create a movie out of with fighting sequences, gun fights and such. And those sequences aren\\'t even much good to watch really. The moments are way too short and quite disappointing to watch really, from the man who brought us \"Commando\".<br /><br />It\\'s foremost a Dolph Lundgren, in which he gets to play the big action hero star, who kicks butt with seemingly relative ease, knows how to handle guns and other weapons and of course also gets the girl, played by Tia Carrere. This all also brings us one of the worst montage sequence in action movie history and also definitely one of the worst sex sequence I have seen in any movie really. Both are just too lame for words and just very poorly put together.<br /><br />None of the characters work out really. The good guys are cops but they never seem to behave like one. They simply kill around without having to face responsibility to anyone and they are not very keen on making any arrest, or to inform anyone about their discoveries. Not even when they find out a big Japanese crime syndicate is trying to take over the streets of L.A. and a beer brewery is working as a cover for a drugs factory and large scale drugs smuggling. And also just think about it for a moment, what is Brandon Lee\\'s overall purpose in the movie? The movie could had easily done without him and the girl as well.<br /><br />Too silly, lame and simplistic and just not entertaining enough.<br /><br />4/10', 'After having red the overwhelming reviews this film got in my country, I but wanted to see it. But - what a disappointment! To see a bunch of one-dimensional characters in a plot that lacks of originality is not worth the money and the time to spend. I sometimes wonder about the filmcritics in switzerland.', \"Disappearance is set in the Mojave desert as Jim (Harry Hamlin) & Patty Henley (Susan Dey) plus their two kids Katie (Basia A'Hern) & Matt (Jeremey Lelliott) along with Ethan (Jamie Croft) a friend of the family are travelling along, they stop at a roadside diner & ask about an old deserted mining town on the map called Weaver. No-one claims to have heard of it but it's definitely there & the family decide to take a detour in order to check it out & take some pictures. Once at the town they take some pictures & have a look around but when it comes time to leave their car won't start & they have to spend the night there. While looking around they find a camcorder videotape which they play only to discover footage of a scared woman saying all her friends have disappeared, the next morning & their car has disappeared as things take a very sinister turn. What is Weaver's secret? Will the Henley's ever leave there alive...<br /><br />Written, co-executive produced & directed by Walter Klenhard I have to say that Disappearance is one of the most frustrating films I have ever watched. For the first 85 minutes it was a pretty good mysterious mix of thriller & horror film but then we are treated to one of the single worst endings ever in motion picture history. The script suggest lots of different things but never elaborates or confirms & I was sitting there genuinely intrigued about what was going on, from the families car mysterious disappearing, the four recent graves, the thing in the abandoned mines, the supernatural sandstorm, the sudden & unexplained disappearance of Ethan & his just as unexplained reappearance, the Sheriff's sinister motives, the compass in the car going crazy, the crashed plane, the townspeople denying Weaver existed & the possible side effects of a neutron bomb being dropped near Weaver in the 40's but they are all tossed out of the window & for all we know could have been totally separate random events. Everything was coming along nicely & was set up for a big twist revelation but none was forthcoming & instead I was treated to the most ambiguous, strange, surreal & downright frustrating ending possible. If nothing else the ending contradicts much of what has gone before & leaves the viewer with more questions than answers. It's almost as if the makers had these great ideas but then didn't know what to do with them & just made the ending up on the spot. I just felt I put so much effort into watching the film which can be pretty slow at times without any sort of reward & in fact the ending felt more like a kick in the teeth or a good two finger salute!<br /><br />Director Klenhard does a reasonable job here, the old ghost town has a certain atmosphere & the large expansive desert locations give a good sense of isolation. It's well made but what were they thinking with that ending? Nothing fits, nothing makes sense & it's just a huge frustrating mess that after sitting through the thing for nearly an hour & a half leaves you confused & wanting to know more. Despite being a horror film there's no blood or gore although there are one or two creepy moments here & there. The film actually reminds of The Hills Have Eyes (2006) remake for large parts as that is what the film is set-up to be before a bizarre ending which does nothing to bring any closure to the film.<br /><br />Technically the film is good with high production values, good special effects, sets, locations & cinematography. Set in America but filmed in South Australia. The acting is fine from a decent cast.<br /><br />Disappearance is a really odd film, for a long time it shapes up to be a neat little horror mystery thriller but it never explains anything which happens & the truly surreal ending just throws up more questions than answers. I really can't see anyone making head nor tail of this, I really can't.\", \"At least among those movies with 100 votes or more. Nominated for best screenplay written directly for the screen? Brenda Blethyn nominated for best actress in a leading role?? Nominated for best picture?? I always disagree with many of the Oscar picks, but this movie might very well be the worst movie of all time to be honored by the Academy. The writing and acting were both horrible. Blethyn's perfomance in particular was one of the worst I've ever seen, and probably the most over-rated acting performance of all time. Awful movie, not worthy of the big screen and not worthy of any cable or television channel that has ever played it, including HBO(where I saw it). I am only thankful I didn't actually pay to see one of the most over-rated movies of all time.\", 'With a story and screenplay that seems to have been written by a high schooler, \\'The Art of Seduction\\' fails to deliver the romantic, sophisticated experience it tries to bill itself as. The two main characters have the potential to be interesting - both male and female lead are \"swinging singles (or in the female lead\\'s case, engaged)\", but \\'The Art of Seduction\\' doesn\\'t even try. Shirking from a frank examination of these two characters\\' personalities, \\'The Art of Seduction\\' eschews anything of substance for a basis of thin, lean stereotype. <br /><br />\\'The Art of Seduction\\' is insulting - insulting to its characters, insulting to men and women, and insulting to its audiences\\' expectations. It takes the awful beautiful people we all know and plays out their painful interactions while expecting us to idolize them. Ji-wan is an immature, spoiled, manipulative bitch. The viewer is expected to like and forgive her flaws because she\\'s pretty. Min-jun, well, he\\'s exactly the same. Neither are nice people. The \"humour\" in this film primarily revolve around Ji-wan and Min-jun\\'s outlandish attempts at outdoing each other in the honourable art of lying and manipulation. No character development occurs, and we never learn why Ji-wan and Min-jun are like this. We are simply expected to take them as they are, and not ask questions - they\\'re cute!, and that\\'s all that matters. The copious references to the celebrity of the main actors in azn cinema scenester\\'s reviews may tip you off to \\'Art of Seduction\\'s shallowness. <br /><br />If you\\'re still in high school, you liked Grease, or you are a yellow fever victim, you may like this movie.<br /><br />Despite its \"Romance\" tag, this is not a very good date movie.', 'It is enjoyable and fast-paced. <br /><br />There is no way on Earth that the actor playing Mat could be eighteen. However, the main thing is that he does act eighteen very convincingly. It must be a credit to his audition that he convinced them to cast him. I quite soon accepted him as being a naive young country boy.<br /><br />While his was the best performance, most of the others were also very engaging. In particular, the interplay between the policemen was natural and well-balanced, and worked very well.<br /><br />It is only about 45 minutes long, so the plot is not complex. More key is the style of the whole thing. It is very slick and vibrant, and the backdrops are atmospheric, especially from the fact that all the colours are extremely rich. The gangland is identifiable to foreign audiences, but still manages to be distinctly Australian.', \"This film is so bad it simply defies reality. The filming is grade school material at best, the acting is pathetic and the director should forever be banished from film making in any form. So bad it can't even be watched as comedy such something along the lines of Showgirls. The ONLY thing this DVD had going for it was the cover art. <br /><br />All I can write to those of you who haven't had the misfortune to witness this is to please do yourself a well deserved favor in advance and don't waste your time or your money on this piece of garbage. If you want to see a movie for the comedy aspects, there are many other more worthy in such a realm than this trash.\", \"Oh God,what an idiotic movie!Incredibly cheap with fake special effects(the creature is played by one guy in lame costume)and stupid plot.All dialogues are unbelievably bad and these actors(HA!HA!HA!)...they're simply ludicrous.For example I have never seen so annoying characters like in this junk(these dumb kids or pregnant woman with his husband and many more).All in all,this is a great entertainment if you're drunk.Avoid it like the plague.Am I drunk?I don't think so...\"]\n"
     ]
    }
   ],
   "source": [
    "for i, (data) in enumerate(movRevTrainDL):\n",
    "        print(f\"Sample {i+1}:\")\n",
    "        print(data)\n",
    "#         print(\"Label:\", label)\n",
    "        if i == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59a0fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),lr=2e-5)\n",
    "num_epochs = 30\n",
    "num_training_steps = num_epochs * len(movRevTrainDL)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps=1000,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92849123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/75000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ff955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca1b265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d52dac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/2500 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 81.29 GB, other allocations: 174.73 MB, max allowed: 81.60 GB). Tried to allocate 383.25 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m         predicted_token_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(predicted_token_ids)\n\u001b[0;32m---> 18\u001b[0m loss_func(model, movRevTrainDL, criterion)\n",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m, in \u001b[0;36mloss_func\u001b[0;34m(model, DL, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     10\u001b[0m batch_tokenized[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50256\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(batch_tokenized)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m model(batch_tokenized[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     13\u001b[0m logit\u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     14\u001b[0m predicted_token_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1302\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1302\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[1;32m   1303\u001b[0m     input_ids,\n\u001b[1;32m   1304\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1305\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1306\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1307\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1308\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1309\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1310\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1311\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[1;32m   1312\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1313\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1314\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1315\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1317\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1116\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1105\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1106\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         output_attentions,\n\u001b[1;32m   1114\u001b[0m     )\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m block(\n\u001b[1;32m   1117\u001b[0m         hidden_states,\n\u001b[1;32m   1118\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[1;32m   1119\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1120\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i],\n\u001b[1;32m   1121\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1122\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask,\n\u001b[1;32m   1123\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1124\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1125\u001b[0m     )\n\u001b[1;32m   1127\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:614\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    612\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 614\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m    615\u001b[0m     hidden_states,\n\u001b[1;32m    616\u001b[0m     layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[1;32m    617\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    618\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    619\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    620\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    621\u001b[0m )\n\u001b[1;32m    622\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    623\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:344\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    342\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    346\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_heads(attn_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    347\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(attn_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/gptenv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:196\u001b[0m, in \u001b[0;36mGPT2Attention._attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_attn\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, key, value, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, head_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 196\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(query, key\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_attn_weights:\n\u001b[1;32m    199\u001b[0m         attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(\n\u001b[1;32m    200\u001b[0m             [], value\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mattn_weights\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mattn_weights\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    201\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 81.29 GB, other allocations: 174.73 MB, max allowed: 81.60 GB). Tried to allocate 383.25 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "pad_idx = tokenizer.pad_token_id\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\n",
    "\n",
    "def loss_func(model, DL, criterion, optimizer = None, scheduler = None):\n",
    "    N = len(DL.dataset)\n",
    "    rloss = 0 \n",
    "    for texts in tqdm(DL, leave=False):\n",
    "        texts = [s for s in texts]\n",
    "        batch_tokenized = tokenizer(texts ,max_length=1024,padding=\"max_length\", truncation = True, return_tensors='pt').input_ids.to(device)\n",
    "        batch_tokenized[:, -1] = 50256\n",
    "        # print(batch_tokenized)\n",
    "        output = model(batch_tokenized[:,:-1])\n",
    "        logit= outputs.logits\n",
    "        predicted_token_ids = torch.argmax(logits, dim = -1)\n",
    "        print(predicted_token_ids)\n",
    "        \n",
    "\n",
    "loss_func(model, movRevTrainDL, criterion)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in movRevTrainDL:\n",
    "        input_tokens = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        outputs = model(input_tokens, attention_mask=attention_mask)\n",
    "        print(outputs)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gptenv)",
   "language": "python",
   "name": "gptenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
