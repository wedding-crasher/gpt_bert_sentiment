{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "18aaffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments,get_scheduler, pipeline, AutoModelForSequenceClassification\n",
    "from torch import nn, optim \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d93b72-68ad-4991-9530-5e1655af3be6",
   "metadata": {},
   "source": [
    "<h1>Load Data and Set for CUDA PARALLEL</h1>\n",
    "I rented NVIDIA 4090 GPU X 2 for the training and inference for this project.\n",
    "Belows are code for 1) loading dataset, 2) setting data loader and 3) implementing CUDA NNPARALLEL system.\n",
    "For the Batch Size, I wanted to use 1024 but due to my GPU memory I used 512 input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8791f4a3-eb31-4885-9ab8-8270bf1b8237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6775260134582633173\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:11:19.754445: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-05 19:11:19.754695: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-05 19:11:19.754844: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0eab043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"heegyu/gpt2-emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c39eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('heegyu/gpt2-emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2535ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class movRevDataSet(Dataset):\n",
    "    def __init__(self,root_dir,transform = None):\n",
    "        self.root_dir = root_dir \n",
    "        self.transform = transform\n",
    "        self.file_list = os.listdir(root_dir)\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        file_path = os.path.join(self.root_dir, file_name)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='unicode_escape') as file:\n",
    "                txt = file.read()\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Error decoding file {file_path}: {e}\")\n",
    "            raise e\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5856664",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataRoot = './aclImdb/train/merged'\n",
    "testDataRoot = './aclImdb/test/merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e6b761cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movRevTrainDS = movRevDataSet(root_dir=trainDataRoot)\n",
    "movRevTrainDS, movRevValDS = torch.utils.data.random_split(movRevTrainDS,[0.8,0.2])\n",
    "movRevTestDS = movRevDataSet(root_dir= testDataRoot)\n",
    "movRevTestDS, movRevTestSubDS = torch.utils.data.random_split(movRevTestDS,[0.9,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bb4abb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "movRevTrainDL= DataLoader(movRevTrainDS, batch_size = BATCH_SIZE, shuffle= True, num_workers =8 )\n",
    "movRevValDL = DataLoader(movRevValDS, batch_size =BATCH_SIZE, shuffle = True,num_workers =8 )\n",
    "movRevTestDL = DataLoader(movRevTestDS, batch_size = BATCH_SIZE, num_workers =8)\n",
    "movRevTestSubDL = DataLoader(movRevTestSubDS, batch_size = BATCH_SIZE, num_workers =8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82ff955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ca1b265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.DataParallel(model, device_ids=[0, 1]).cuda()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391ab20-32f5-4a80-8f28-9a9c733c88eb",
   "metadata": {},
   "source": [
    "<h1>FineTune GPT2</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d52dac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested lr = 2e-5, 2e-4, 2e-3\n",
    "optimizer = AdamW(model.parameters(),lr=0.001)\n",
    "\n",
    "#Number of epochs\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "#Input Sequence\n",
    "MAX_LENGTH = 512\n",
    "#Total LOOP\n",
    "NUM_TRAINING = NUM_EPOCHS * len(movRevTrainDL)\n",
    "# progress_bar = tqdm(range(NUM_TRAINING), leave=True)\n",
    "lr_scheduler = StepLR(\n",
    "    optimizer = optimizer,\n",
    "    step_size = 10,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5645b755-ff44-480a-9751-36685425c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    exps = torch.exp(logits - torch.max(logits, dim = -1, keepdim =True).values)\n",
    "    return exps / torch.sum(exps, dim = -1, keepdim=True)\n",
    "    \n",
    "def cross_entropy_loss(logits, targets):\n",
    "    # logits의 모양: 개단차\n",
    "    # targets의 모양: 개단\n",
    "\n",
    "    probs = softmax(logits)\n",
    "    \n",
    "\n",
    "    log_probs = torch.log(probs)\n",
    "    \n",
    "\n",
    "    nll_loss = -log_probs[range(logits.shape[0]), targets]\n",
    "    return torch.mean(nll_loss)\n",
    "    \n",
    "def my_loss(inputs, logits):\n",
    "\n",
    "    # logits을 [개*단, 차] 형태로 변형해줘야함. \n",
    "    logits = logits.view(-1, logits.size(-1))\n",
    "    \n",
    "    # inputs을 [개*단] 형태로 변형 꼭!\n",
    "    inputs = inputs.view(-1).long()\n",
    "\n",
    "    loss_value = cross_entropy_loss(logits, inputs)\n",
    "    \n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefe873-c24b-450e-822d-fe4d8a1ddf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model_epoch_4_2024-06-05_08-31-56.pt'))\n",
    "\n",
    "\n",
    "def train(model, num_epochs, trainDL, valDL, tokenizer, optimizer, scheduler, max_length, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()  \n",
    "        train_progress_bar = tqdm(trainDL, desc=f\"Epoch {epoch + 1} [Train]\", leave=True)  # 학습 프로그레스 바 설정\n",
    "        for texts in train_progress_bar:\n",
    "            batch_tokenized = tokenizer(texts, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "            input_ids = batch_tokenized['input_ids'].to(device)\n",
    "            attention_mask = batch_tokenized['attention_mask'].to(device)\n",
    "            labels = batch_tokenized['input_ids'].to(device)  # labels를 input_ids와 동일하게 설정\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = my_loss(input_ids, outputs.logits)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.sum().backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        \n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        torch.save(model.state_dict(), f\"./model_epoch_{epoch + 1}_{current_time.replace(' ', '_').replace(':', '-')}.pt\")\n",
    "        \n",
    "        # Eval\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_progress_bar = tqdm(valDL, desc=f\"Epoch {epoch + 1} [Validation]\", leave=True)  # 검증 프로그레스 바 설정\n",
    "        with torch.no_grad():\n",
    "            for texts in val_progress_bar:\n",
    "                batch_tokenized = tokenizer(texts, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "                input_ids = batch_tokenized['input_ids'].to(device)\n",
    "                attention_mask = batch_tokenized['attention_mask'].to(device)\n",
    "                labels = batch_tokenized['input_ids'].to(device)  # labels를 input_ids와 동일하게 설정\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                val_loss = my_loss(input_ids, outputs.logits)\n",
    "                total_val_loss += val_loss.sum().item()\n",
    "\n",
    "    \n",
    "        total_val_loss /= len(valDL)\n",
    "       \n",
    "      # Early Stop\n",
    "        if total_val_loss < best_val_loss:\n",
    "            best_val_loss = total_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model.state_dict(), f\"./best_model_{current_time.replace(' ', '_').replace(':', '-')}.pt\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"Validation loss has not improved for {patience} epochs. Stopping training.\")\n",
    "                break\n",
    "\n",
    "train(model, NUM_EPOCHS, movRevTrainDL, movRevValDL, tokenizer, optimizer, lr_scheduler, MAX_LENGTH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b77b04-52d8-4f2d-a650-e77592e898b0",
   "metadata": {},
   "source": [
    "<h1>Generate 30 Reviews<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fe432-5560-4a93-86a9-36208fb9eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model_epoch_7_2024-06-05_15-56-39.pt'))\n",
    "prompt_1 = [\n",
    "    \"The movie was\",\n",
    "    \"The lead actor's performance was\",\n",
    "    \"The cinematography in the film was\",\n",
    "    \"The plot of the movie was\",\n",
    "    \"The supporting cast's performances were\",\n",
    "    \"The soundtrack of the film was\",\n",
    "    \"The direction of the movie was\",\n",
    "    \"The special effects in the film were\",\n",
    "    \"The pacing of the movie was\",\n",
    "    \"The dialogue in the film was\",\n",
    "    \"The film's setting was\",\n",
    "    \"The movie's themes were\",\n",
    "    \"The opening scene was\",\n",
    "    \"The ending of the movie was\",\n",
    "    \"The costumes and makeup were\",\n",
    "    \"The movie's humor was\",\n",
    "    \"The emotional impact of the film was\",\n",
    "    \"The character development was\",\n",
    "    \"The movie's message was\",\n",
    "    \"The action scenes were\",\n",
    "    \"The film's visual style was\",\n",
    "    \"The editing of the movie was\",\n",
    "    \"The movie's rewatch value is\",\n",
    "    \"The film's cultural impact was\",\n",
    "    \"The chemistry between the actors was\",\n",
    "    \"The movie's originality was\",\n",
    "    \"The film's use of symbolism was\",\n",
    "    \"The movie's suspense level was\",\n",
    "    \"The realism in the film was\",\n",
    "    \"The overall experience of watching the movie was\"\n",
    "]\n",
    "\n",
    "gen_text = []\n",
    "for text in prompt_1:\n",
    "    tokenized = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    gen_token = model.module.generate(\n",
    "        input_ids=tokenized, \n",
    "        min_length=50, \n",
    "        max_length=100,\n",
    "        no_repeat_ngram_size=3,\n",
    "        temperature=1,\n",
    "        num_beams=5,\n",
    "        top_p = 0.99\n",
    "    )\n",
    "    \n",
    "    pred = tokenizer.batch_decode(gen_token, skip_special_tokens=True)[0]\n",
    "    gen_text.append(pred)\n",
    "    print(\"생성토큰: \",pred)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608c392-5e6e-468a-ab08-5edb4bd17229",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = [\n",
    "    \"The movie was really good. I'm glad that I'm not the only one who has seen this film, but I think it's the best movie ever. The main problem with this film is that it's not a good movie, but it's a very good movie.\",\n",
    "    \"The lead actor's performance was excellent. The dialogue is excellent, but the direction and direction of the film is not as good as it was in the film. The main problem with this film is the fact that it lacks a lot of dialogue. The plot is not quite good.\",\n",
    "    'The cinematography in the film was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the movie. The main problem with this film is the fact that it is not a good film. There is a lot of fun to be done with it.',\n",
    "    'The plot of the movie was simple and simple. The main problem with this movie is that it suffers from a flawed plot. The plot is flawed. The dialogue is flawed, the direction of the film is flawed in terms of direction. The direction of this film is not as good as it was in the original film. There is a lot of potential for this film to be flawed.',\n",
    "    \"The supporting cast's performances were excellent. The dialogue is excellent, but the direction and direction of the film is not as good as it was in the film. The main problem with this film is the fact that it lacks a lot of dialogue. The fact that the main problem is that it's not as much of a problem as it is in the movie.\",\n",
    "    'The soundtrack of the film was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the film. The main problem with this film is the fact that it lacks a lot of dialogue. The fact is that it is not a good film.',\n",
    "    'The direction of the movie was not quite good, but it was better than it was supposed to be. The main problem with this film is that it is not quite as good as it could be. I think it is a lot of fun to watch.',\n",
    "    \"The special effects in the film were excellent. The film is not quite as good as it was in the original film. The main problem with this film is that it's not quite like the original movie. The dialogue is not particularly good. The movie is not as good, but it is not much better than the original.\",\n",
    "    \"The pacing of the movie was excellent. The dialogue is excellent, but the direction of the film is not as good as it was in the original film. The main problem with this film is that it is not a good film, but it is a very good film. I think it's not a bad film. If you're looking at this film, you'll be disappointed in the direction and direction of its direction.\",\n",
    "    \"The dialogue in the film was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the movie. The main problem with this film is the fact that it is not a good film. The fact is that it's not an excellent film.\",\n",
    "    \"The film's setting was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the film. The main problem with this film is the fact that it is not a good movie. The fact is that it's not a bad movie.\",\n",
    "    \"The movie's themes were simple and simple. The main problem with this film is that it is not a simple film, but it is a very good one. The plot is simple, but the main problem is not simple. It is a simple movie, but I think it deserves to be considered as a classic.\",\n",
    "    'The opening scene was excellent. The dialogue is excellent, but the direction and direction of the film is not as good as it was in the film. The main problem with this film is the fact that it is not a good film, but it is a very good film.',\n",
    "    'The ending of the movie was excellent. The dialogue is excellent, but the direction and direction of the film is not as good as it was in the film. The main problem with this film is the fact that it is not a good film. There is a lot of fun to be done with it.',\n",
    "    'The costumes and makeup were excellent, though they could have been better. The main problem with this film is that it lacks a lot of potential. The film is not particularly good. The dialogue is not quite good, but it could be better. A lot of fun to watch.',\n",
    "    \"The movie's humor was excellent, though it was not quite as good as it could be. The dialogue is excellent, but it wasn't quite as funny as it was. The main problem with the film is the fact that it's not really funny.\",\n",
    "    'The emotional impact of the film was apparent in the film, but it was not as much of a film as I think it could have been better than the film. The main problem with this film is that it lacks the emotional and emotional effects of the movie.',\n",
    "    \"The character development was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the film. The main problem with this film is the fact that it is not a good movie. The fact is that it's not a bad movie.\",\n",
    "    \"The movie's message was simple and simple. The main problem with this film is that it's not really about the movie. It's not about the film, but it's about the plot. The plot is simple, but the main problem is the fact that it wasn't about the main plot. It was about the direction of the film.\",\n",
    "    'The action scenes were excellent. The dialogue is excellent, but the direction and direction of the film is not as good as it was in the film. The main problem with this film is the fact that it is not a good film, but it is a very good film.',\n",
    "    \"The film's visual style was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the film. The main problem with this film is the fact that it is not a good film, but it is a very good film. There is a lot of fun to be done with it. The fact is that it's not a great film.\",\n",
    "    'The editing of the movie was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the original film. The main problem is that it is not a good movie. The plot is not quite good. The direction of the film is not very good.',\n",
    "    \"The movie's rewatch value is one of the best things I've ever seen in a movie. I'm glad that I'm not the only one who has seen this movie, but I think it's the best thing I've seen in the movie.\",\n",
    "    \"The film's cultural impact was not as much as it could have been. The main problem is the fact that it is not a film that I want to see again. The film is not about the film, but it is about the role of the director.\",\n",
    "    'The chemistry between the actors was excellent. The chemistry between them is excellent, but the chemistry is not as good as the chemistry between their roles. The dialogue is excellent and the dialogue is not quite as good. The direction of the movie is not particularly good, but it is not much better than the chemistry of the film. The main problem with this film is that it lacks a lot of potential.',\n",
    "    \"The movie's originality was restored to the original film, but it was not restored to its original film. The original film was restored from the original movie, and it is not restored. The main problem with this film is the fact that it's not restored, but the main problem is that it lacks a lot of originality.\",\n",
    "    \"The film's use of symbolism was not particularly good, but it was a very good film. I think it could have been better, but I think that it could be better, if it hadn't been so much of an effort. The main problem with this film is the fact that it's not quite as good as it was in the first place.\",\n",
    "    \"The movie's suspense level was surprisingly low, but it was surprisingly good. I think it was a very good movie. I'm glad that it's not as much of a suspenseful movie as it was. The main problem is that it wasn't much of an suspenseful one.\",\n",
    "    'The realism in the film was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the movie. The main problem with this film is the fact that it is not a realistic film. There is a lot of fun to be had in this film.',\n",
    "    \"The overall experience of watching the movie was excellent, but it was not quite as good as it could be. The film is not quite like it was. The dialogue is not particularly good, though it was excellent. The main problem is the fact that it wasn't quite as much fun as it would be if it hadn't been a fun movie. The fact is that it's not a fun film.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c44da-c99c-42a9-b9ce-e9b2fde65564",
   "metadata": {},
   "source": [
    "<h1>Bleu Score Computation: Result: 0.02008190923851741</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c6a77",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5348ce65-c8b3-44ce-9f93-29241025082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   0%|                                | 0/1250 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Two popular actors are paired in showtime like De Niro\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   0%|                        | 1/1250 [00:02<53:16,  2.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 349])\n",
      "Prompt: Prue and Piper bring Dr. Griffiths to their home to\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   0%|                        | 2/1250 [00:04<43:59,  2.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Its almost embarrassing to say I even saw this movie.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   0%|                        | 3/1250 [00:06<40:48,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: The Wind. Easily one of the worst films ever made.\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   0%|                        | 4/1250 [00:08<39:54,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: An airplane transporting some scientists and a prototype of a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   0%|                        | 5/1250 [00:10<42:24,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 389])\n",
      "Prompt: I love the so-called \"blaxploitation\" films and have seen dozens.\n",
      "Tokenized Prompt Shape: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   0%|                        | 6/1250 [00:12<41:07,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: 'Radio' is a beautiful movie based on a real story\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▏                       | 7/1250 [00:14<40:33,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: The movie opens with Charlie (Jeff Daniels), a business man\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▏                       | 8/1250 [00:15<40:03,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: Jewel Thief is one of those suspense thrillers in which\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▏                       | 9/1250 [00:17<38:53,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: this film was brilliant! i absolutely loved it! wesley snipes\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▏                      | 10/1250 [00:19<37:54,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I think this programme is a load of rubbish. All\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▏                      | 11/1250 [00:22<46:00,  2.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 500])\n",
      "Prompt: Even though some unrealistic things happen at the end (i.e.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▏                      | 12/1250 [00:24<43:29,  2.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Rating: 7 out of 10. Directed by Barbet Schroeder. If\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▏                      | 13/1250 [00:26<41:17,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: I feel terribly sorry! Where the Lubitsch-pic was enchanting, marvelous,\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▎                      | 14/1250 [00:27<40:08,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: Swoon focuses on Leopold and Loeb's homosexual relationship - a\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▎                      | 15/1250 [00:29<39:03,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: For pure gothic vampire cheese nothing can compare to the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▎                      | 16/1250 [00:31<38:13,  1.86s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Adenoid Hynkel, a lowly soldier in World War One, rises\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▎                      | 17/1250 [00:33<38:09,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: Jimmy Wang Yu, an authentic Asian superstar, directed and wrote\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   1%|▎                      | 18/1250 [00:35<37:51,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Strong evidences and it clearly shows government cover-ups and lies.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▎                      | 19/1250 [00:37<37:48,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Like an earlier commentor, I saw it in 1980 and\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▎                      | 20/1250 [00:38<37:35,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I've seen this movie n I can say that this\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▍                      | 21/1250 [00:40<37:30,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Wow! An amazing, lost piece of Australiana AND a lost\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▍                      | 22/1250 [00:42<38:16,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 341])\n",
      "Prompt: The only reason I decided to view this film is\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▍                      | 23/1250 [00:44<38:34,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: If the caper genre owes a lot to Walter Huston,\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▍                      | 24/1250 [00:46<37:44,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: King of the Underworld features an early role for Humphery\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▍                      | 25/1250 [00:48<37:18,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: One of the most entertaining of all silent comedies is\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▍                      | 26/1250 [00:49<36:51,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This is what happens when a franchise gets lazy, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▍                      | 27/1250 [00:51<36:24,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: With the plethora of repetitive and derivative sitcoms jamming fall,\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▌                      | 28/1250 [00:53<37:47,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 351])\n",
      "Prompt: Yeah great cult TV series. Great atmosphere, top script and\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▌                      | 29/1250 [00:55<37:05,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Closet Land. The title itself conjures up thoughts of secrets.\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▌                      | 30/1250 [00:57<38:29,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: ..this movie has been done when Hitler ( and Mussolini\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   2%|▌                      | 31/1250 [00:59<38:43,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: I have seen many many movies and this just totally\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▌                      | 32/1250 [01:01<39:17,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: I cannot believe it has been 25 yrs since I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▌                      | 33/1250 [01:03<38:41,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: It's just that. Chucky 1 was good. Chucky 2 was\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▋                      | 34/1250 [01:05<40:05,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 355])\n",
      "Prompt: This is an important historical film since it was the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▋                      | 35/1250 [01:07<39:15,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: I watched the world premiere of this on the Starz\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▋                      | 36/1250 [01:09<39:17,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Well, I read the other comments. Didn't think it sounded\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▋                      | 37/1250 [01:10<38:41,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: A film is beyond all expectations, an excellent insight into\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▋                      | 38/1250 [01:12<38:37,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: I played Sam (the porter, Lou's sidekick) in the Film\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▋                      | 39/1250 [01:14<37:31,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I still count \"Police Squad!\" as the absolute funniest TV\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▋                      | 40/1250 [01:16<37:07,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: MY Father the hero is sweet, funny and cute. Gerard\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▊                      | 41/1250 [01:18<36:39,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I wonder why I haven't heard of this movie before.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▊                      | 42/1250 [01:19<36:27,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: An inspired choice of director for this latest Brit-Flick, Rose\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   3%|▊                      | 43/1250 [01:21<37:40,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 352])\n",
      "Prompt: In Reunion Island in the Indian Ocean, the owner of\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▊                      | 44/1250 [01:23<37:20,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: Naach would have won an Razzie for the Worst Film\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▊                      | 45/1250 [01:25<36:57,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: EVAN ALMIGHTY (2007) ** Steve Carell, Morgan Freeman, Lauren Graham,\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▊                      | 46/1250 [01:27<36:31,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: This movie is important to those of us interested in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▊                      | 47/1250 [01:29<37:23,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: If you're a science fiction fan, and you've only seen\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▉                      | 48/1250 [01:31<36:57,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: I sat last night to see this film being played\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▉                      | 49/1250 [01:33<37:04,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: The story of Sweeney Todd evokes memories of the work\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▉                      | 50/1250 [01:34<36:33,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: How is it possible to like and dislike the same\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▉                      | 51/1250 [01:36<37:21,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: \"Two Hands\" is a good addition to the Australian Film\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▉                      | 52/1250 [01:38<37:14,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: This movie was *good* relatively during the first parts of\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▉                      | 53/1250 [01:40<37:02,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: David Morse and Andre Braugher are very talented actors, which\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|▉                      | 54/1250 [01:42<36:30,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: This is probably the worst film I have ever seen;\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|█                      | 55/1250 [01:44<37:17,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: Along with In the Army!, this ranks as one of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   4%|█                      | 56/1250 [01:46<37:21,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: Joe is the movie about the dark side of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█                      | 57/1250 [01:47<36:34,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I was surprised that the makers of this movie actually\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█                      | 58/1250 [01:49<37:28,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 344])\n",
      "Prompt: I saw this movie on the shelf at Blockbuster and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█                      | 59/1250 [01:51<36:58,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: The movie that would be included if Mystery Science Theater\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█                      | 60/1250 [01:53<36:43,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: wow! i just have to say this show is super\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█                      | 61/1250 [01:55<36:27,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: This film started off really tense when a poor young\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█▏                     | 62/1250 [01:57<37:11,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: A man by the name of Joseph Samuels is found\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█▏                     | 63/1250 [01:58<36:24,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Bone Eater is set in a small desert town in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█▏                     | 64/1250 [02:00<36:47,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Cult film-maker Corbucci's rarest of his thirteen Spaghetti Westerns (of\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█▏                     | 65/1250 [02:02<35:53,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: The Snowqueen is one of the best love stories I\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█▏                     | 66/1250 [02:04<35:59,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: I found this to be a tremendously disappointing version of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█▏                     | 67/1250 [02:06<35:28,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I don't leave IMDb comments about films but this.... this\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   5%|█▎                     | 68/1250 [02:08<36:08,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: \" While sporadically engrossing (including a few effectively tender moments)\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▎                     | 69/1250 [02:10<37:12,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 354])\n",
      "Prompt: 044: The Big Trail (1930) - released 10/24/1930; viewed 4/5/06.<br\n",
      "Tokenized Prompt Shape: torch.Size([1, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▎                     | 70/1250 [02:12<37:16,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 346])\n",
      "Prompt: Conrad Radzoff(Ferdy Mayne), a hammy cult icon, dies from a\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▎                     | 71/1250 [02:13<36:03,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Once I heard that the greatest and oldest preserved Germanic\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▎                     | 72/1250 [02:15<35:56,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I've been looking forward to watching \"Wirey Spindell\" since having\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▎                     | 73/1250 [02:17<35:33,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Naturally Sadie sucks big time, I have no idea what\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▎                     | 74/1250 [02:19<36:22,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: It is a rare and fine spectacle, an allegory of\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▍                     | 75/1250 [02:21<37:11,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 336])\n",
      "Prompt: I recommend Idiocracy to everyone. Luke Wilson is very funny,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▍                     | 76/1250 [02:22<36:09,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Please don't waste your money on this sorry excuse for\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▍                     | 77/1250 [02:24<35:49,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: I found the film quite good for what I was\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▍                     | 78/1250 [02:26<36:06,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: This is one for the Golden Turkey book. It's another\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▍                     | 79/1250 [02:28<36:52,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 344])\n",
      "Prompt: The spoof genre, which has lacked creativity and humor for\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▍                     | 80/1250 [02:30<36:35,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: This film is about the encounters of 7 couples on\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   6%|█▍                     | 81/1250 [02:32<35:52,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: The key scene in Rodrigo Garcia's \"Nine Lives\" comes when\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▌                     | 82/1250 [02:34<36:04,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: I know if I was a low budget film maker\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▌                     | 83/1250 [02:36<36:47,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: I was laying in bed, flicking through the channels... and\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▌                     | 84/1250 [02:37<36:04,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: When I fist watched the movie, I said to myself,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▌                     | 85/1250 [02:39<36:03,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: My bad film guru (and the president of the Exposed\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▌                     | 86/1250 [02:41<35:29,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: The Mummy's Curse is the last in the series of\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▌                     | 87/1250 [02:43<35:05,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I was fortunate enough to catch a midnight screening of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▌                     | 88/1250 [02:45<35:28,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: \"Hoods\" doesn't deliver the goods. This half-baked mafia comedy boasts\n",
      "Tokenized Prompt Shape: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▋                     | 89/1250 [02:46<34:53,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: I've always said that there's nothing to beat the original\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▋                     | 90/1250 [02:48<34:32,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: The action was episodic and there was no narrative thread\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▋                     | 91/1250 [02:50<34:16,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Perhaps one of the best movies ever made. Orry and\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▋                     | 92/1250 [02:52<34:28,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: This movie was horrible, and it doesn't even deserve to\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   7%|█▋                     | 93/1250 [02:54<34:47,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Although \"They Died with their Boots On\" is not entirely\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▋                     | 94/1250 [02:55<34:44,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: After being off the air for a while, Columbo returned\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▋                     | 95/1250 [02:57<34:56,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: This movie started out cringe-worthy--but it was meant to, with\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                     | 96/1250 [02:59<34:21,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: In comparison to other \"sand and sandal\" fare, The Egyptian\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                     | 97/1250 [03:01<33:54,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: **** SPOILERS THROUGHOUT **** This is a very strange film\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                     | 98/1250 [03:02<33:48,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Was this supposed to be a comedy? The black cape\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                     | 99/1250 [03:04<33:52,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I was shocked at how good this German version of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                    | 100/1250 [03:06<34:11,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Despite strong performances by Minnie Driver and Tom Wilkinson, this\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                    | 101/1250 [03:08<35:29,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 349])\n",
      "Prompt: I totally agree that the reenactments kill what could otherwise\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                    | 102/1250 [03:10<34:49,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I saw this when it came out in theaters back\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                    | 103/1250 [03:12<34:29,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Rented the video for a slow Saturday night. First viewing\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                    | 104/1250 [03:13<34:01,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Remember when Rick Mercer was funny? 22 Minutes was a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                    | 105/1250 [03:15<34:02,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: I've never seen a movie get a worse release then\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   8%|█▊                    | 106/1250 [03:17<34:46,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: <br /><br />This movie is best enjoyed amidst a large\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|█▉                    | 107/1250 [03:19<35:06,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: This has got to be the worst movie I haver\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|█▉                    | 108/1250 [03:21<34:43,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: After a group of young friends experience car trouble whilst\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|█▉                    | 109/1250 [03:23<35:22,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: Fabulous cinematography from Sergei Urusevsky help to make this a\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|█▉                    | 110/1250 [03:24<35:05,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: <br /><br />Emilio Estevez takes the wonderful play HOMEFRONT and\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|█▉                    | 111/1250 [03:26<35:53,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 353])\n",
      "Prompt: Cultural Vandalism Is the new Hallmark production of Gulliver's Travels\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|█▉                    | 112/1250 [03:28<36:45,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 359])\n",
      "Prompt: Universal Studios version of \"Flipper\" (1996) is a great heartwarming\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|█▉                    | 113/1250 [03:30<35:35,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: There is a point in the film where the female\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|██                    | 114/1250 [03:32<36:04,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: I was initially interested in this film after reading a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|██                    | 115/1250 [03:34<35:13,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: This is such a crappy movie I have no idea\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|██                    | 116/1250 [03:36<34:28,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: When It Comes to ANY Movie that was made in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|██                    | 117/1250 [03:37<34:19,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: This movie was sooooooo sloooow!!! And everything in it was\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:   9%|██                    | 118/1250 [03:39<33:56,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: How could this get a 6.0 rating? Are we as\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██                    | 119/1250 [03:41<33:27,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Though the Our Gang comedies still have their followers, I've\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██                    | 120/1250 [03:43<35:19,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 366])\n",
      "Prompt: Everything I can say, is that it's one of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▏                   | 121/1250 [03:45<35:05,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: If you are like me and observed the original \"Benji\"\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▏                   | 122/1250 [03:47<34:17,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Having seen the movie years ago and been disappointed by\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▏                   | 123/1250 [03:48<33:55,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I find it hard to believe this could happen at\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▏                   | 124/1250 [03:50<34:48,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 338])\n",
      "Prompt: This very loose retelling of Carmen begins on a high\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▏                   | 125/1250 [03:52<34:42,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: It'll be a blue Christmas indeed if you subject you're\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▏                   | 126/1250 [03:54<36:05,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 364])\n",
      "Prompt: Someone asked why it was canceled I tell you why\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▏                   | 127/1250 [03:56<35:42,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: The first time I had heard of Guest House Paridiso\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▎                   | 128/1250 [03:58<35:21,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: As someone who used to spend hours driving around the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▎                   | 129/1250 [04:00<34:39,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Great movie. Post-apocalyptic films kick ass. This one is no\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▎                   | 130/1250 [04:01<33:56,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: ***SPOILERS!*** I sometimes wonder what makes sequel-makers think that they\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  10%|██▎                   | 131/1250 [04:03<34:03,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: In the midst of a documentary about his parents, the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▎                   | 132/1250 [04:05<35:30,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 361])\n",
      "Prompt: Set in the 1970s Los Angeles, Christopher Boyce has just\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▎                   | 133/1250 [04:07<35:06,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Based on the actual event , this epic, is set\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▎                   | 134/1250 [04:09<36:56,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 382])\n",
      "Prompt: I appear to be in the minority, but I thought\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▍                   | 135/1250 [04:11<36:36,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: OK, please believe me when I say that this is\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▍                   | 136/1250 [04:13<35:53,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: Maybe James P. Lay knows what do to in the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▍                   | 137/1250 [04:15<35:42,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: This was a film based on the Novel written by\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▍                   | 138/1250 [04:17<34:42,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: GZSZ is the longest running daily soap in Germany and\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▍                   | 139/1250 [04:19<33:49,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: This stinker is in mystifyingly frequent rotation on one channel\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▍                   | 140/1250 [04:21<36:27,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 393])\n",
      "Prompt: This is one of the best \"Bloke\" movies from the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▍                   | 141/1250 [04:24<41:39,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 500])\n",
      "Prompt: Not even the Beatles could write songs everyone liked, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▍                   | 142/1250 [04:26<41:18,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 379])\n",
      "Prompt: I have no idea what these people were thinking when\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  11%|██▌                   | 143/1250 [04:28<40:01,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 347])\n",
      "Prompt: Being a gay man who lived through the time period\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▌                   | 144/1250 [04:30<37:54,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: As a flying and war movie buff, this ranks at\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▌                   | 145/1250 [04:32<36:13,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: When I first saw this film it was not an\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▌                   | 146/1250 [04:33<35:07,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: I saw this film as a sneak preview before the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▌                   | 147/1250 [04:36<36:34,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 358])\n",
      "Prompt: In the movie, \"The Falcon and the Snowman\", when they\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▌                   | 148/1250 [04:38<36:26,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 344])\n",
      "Prompt: Terrible adaptation of Heminway's low key love story. An American\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▌                   | 149/1250 [04:40<36:21,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 345])\n",
      "Prompt: So many bad reviewers, it made me wonder, what people\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▋                   | 150/1250 [04:41<36:00,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: Baby boom was bad enough, basically making a series of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▋                   | 151/1250 [04:43<34:54,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Roomies is the story of a guy who loses everything\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▋                   | 152/1250 [04:45<34:03,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Anatomie isn't very unique in horror genre, in fact it\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▋                   | 153/1250 [04:47<33:21,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: There are plenty of comments already posted saying exactly how\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▋                   | 154/1250 [04:48<32:52,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: On more than one level, I can relate to what\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▋                   | 155/1250 [04:50<32:43,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Dick and Jane Harper (Jim Carrey, TÃ©a Leoni) wind up\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  12%|██▋                   | 156/1250 [04:52<32:42,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: in his descriptions of CAA, platinum card lunches in Hollywood,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▊                   | 157/1250 [04:54<33:34,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: Look, we rated this a 10 on entertainment value. It's\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▊                   | 158/1250 [04:56<33:19,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: Lame B-horror that takes itself too damn seriously considering its\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▊                   | 159/1250 [04:58<34:25,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 355])\n",
      "Prompt: As if reality shows like \"American Idol\" weren't enough, in\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▊                   | 160/1250 [05:00<33:45,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: This movie was clearly an early attempt for a new\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▊                   | 161/1250 [05:01<33:39,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: What a boring movie. While it did have humorous parts,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▊                   | 162/1250 [05:04<36:47,  2.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 406])\n",
      "Prompt: Very enjoyable 50's Western. I have it in my collection\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▊                   | 163/1250 [05:06<35:20,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I recently saw this at the 2007 Palm Springs International\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▉                   | 164/1250 [05:09<40:39,  2.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 500])\n",
      "Prompt: What's there to say about \"Pink Flamingos\"? It is beyond\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▉                   | 165/1250 [05:11<40:30,  2.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 384])\n",
      "Prompt: When a bomber, a patricide, a pornographer, and a mad\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▉                   | 166/1250 [05:13<39:07,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 336])\n",
      "Prompt: The second (not animated) movie about the only people still\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▉                   | 167/1250 [05:15<36:53,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Purchased this film for one dollar and figured I could\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  13%|██▉                   | 168/1250 [05:16<35:21,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I don't really mind the creative ideas interjected in these\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|██▉                   | 169/1250 [05:18<36:05,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 364])\n",
      "Prompt: If you're not a fan of the 80s, and you\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|██▉                   | 170/1250 [05:20<34:44,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Fata Morgana, the 1971 documentary-like film by German filmmaker extraordinaire\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███                   | 171/1250 [05:22<33:55,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: My husband dragged me to this film as I had\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███                   | 172/1250 [05:24<34:11,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: Saw the film at it's Lawrence, Kansas premiere. This wavering\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███                   | 173/1250 [05:26<33:26,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: While it has been many decades since I last read\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███                   | 174/1250 [05:28<33:10,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: It's one of the imponderables of low-budget independent film-making that\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███                   | 175/1250 [05:29<32:35,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: For those who still prefer films focusing on human relationships,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███                   | 176/1250 [05:31<32:05,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Although Bullet In The Brain is, without question, superior amongst\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███                   | 177/1250 [05:33<32:09,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: River's Edge is more than just the story of a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███▏                  | 178/1250 [05:35<31:59,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: To anyone who likes the TV series: forget the movie.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███▏                  | 179/1250 [05:36<32:01,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: A very credible and unsettling movie portraying the effects of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███▏                  | 180/1250 [05:38<32:06,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: A rather mild horror movie; if not for a couple\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  14%|███▏                  | 181/1250 [05:40<32:07,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: You know the movie could have been a lot better\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▏                  | 182/1250 [05:42<32:15,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: This is the follow-up creation to Better Off Dead. In\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▏                  | 183/1250 [05:44<33:18,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 338])\n",
      "Prompt: *** Possable spoiler but probably not ***<br /><br />The game\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▏                  | 184/1250 [05:46<33:16,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: Good (not great) little horror film with a high \"creep\"\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▎                  | 185/1250 [05:48<33:09,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: A vampire prince falls for a human girl, unaware that\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▎                  | 186/1250 [05:49<32:58,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: When one considers that Carson McCullers is one of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▎                  | 187/1250 [05:52<35:38,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 407])\n",
      "Prompt: Films belonging to the \"film noir\" genre usually contain similar\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▎                  | 188/1250 [05:53<34:04,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: The Battle at Elderbrush Gulch was Griffith's longest and most\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▎                  | 189/1250 [05:55<33:02,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: \"Hari om\" is an Indian greeting and the compelling title\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▎                  | 190/1250 [05:57<32:23,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: TANDEM is an odd slice in the Japanese pink genre-as\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▎                  | 191/1250 [05:59<31:49,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: 83 minutes? Nope, this thing is 72 minutes, tops.<br /><br\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▍                  | 192/1250 [06:01<31:49,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: i just saw this movie on TNT and let me\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  15%|███▍                  | 193/1250 [06:02<31:26,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: The Outer Limits is a brilliant show that for the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▍                  | 194/1250 [06:04<31:29,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: Brilliant. Ranks along with Citizen Kane, The Matrix and Godfathers.\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▍                  | 195/1250 [06:06<31:02,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: If you believe that any given war movie can make\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▍                  | 196/1250 [06:08<31:48,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: This is such a fun and funny movie. Highly entertaining\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▍                  | 197/1250 [06:09<31:31,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I remember seeing this movie 34 years ago and it\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▍                  | 198/1250 [06:11<31:44,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: A nicely evoked 1930s setting provides much interest for a\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▌                  | 199/1250 [06:13<31:32,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Well, what's wrong with the title \"Separate Lies\" (accused elsewhere\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▌                  | 200/1250 [06:15<33:29,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 381])\n",
      "Prompt: I remember seeing the trailer for this movie when it\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▌                  | 201/1250 [06:17<32:44,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: I saw it in Europe-plex. Great movie!! <br /><br />This\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▌                  | 202/1250 [06:19<32:59,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: I give the show a six because of the fact\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▌                  | 203/1250 [06:21<32:37,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: The acting is generally pretty weak. The dialog was also\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▌                  | 204/1250 [06:23<32:43,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: My husband received DVD of OBWAT for Christmas and it\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▌                  | 205/1250 [06:24<32:18,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: First of all, even IMDb is slacking with this movie,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  16%|███▋                  | 206/1250 [06:26<33:06,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 351])\n",
      "Prompt: I loved the first Grudge, I watched it in an\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▋                  | 207/1250 [06:28<32:47,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Dear Mr. Seitzman, Or Whomever I May Hold Responsible For\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▋                  | 208/1250 [06:30<32:09,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: \"Confirmed Dead\" is an important episode in the series, as\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▋                  | 209/1250 [06:32<32:11,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I didn't expect a lot when i went out to\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▋                  | 210/1250 [06:34<31:59,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: New York family is the last in their neighborhood to\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▋                  | 211/1250 [06:36<31:42,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: Totally different, with loads of understatement and black comedy, this\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▋                  | 212/1250 [06:37<31:07,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Plunkett & Macleane falls into my favourite genre of film\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▋                  | 213/1250 [06:39<32:40,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 356])\n",
      "Prompt: At first glance a film like Northfork, a town set\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▊                  | 214/1250 [06:41<31:55,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: As the mom of a 3 year old and a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▊                  | 215/1250 [06:43<31:22,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This film is a masterpiece. It was exhilarating from beginning\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▊                  | 216/1250 [06:45<31:00,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: The main criticism of AT THE EARTH'S CORE is that\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▊                  | 217/1250 [06:46<30:39,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: In a up and down career with all sorts of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  17%|███▊                  | 218/1250 [06:48<30:48,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: I am completely into this type of story line but\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▊                  | 219/1250 [06:50<32:02,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 350])\n",
      "Prompt: One of the most underrated comedies. Dan Akroyd is hilarious\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▊                  | 220/1250 [06:52<31:31,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: It must be said that the director of The Cell,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▉                  | 221/1250 [06:54<32:17,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 344])\n",
      "Prompt: Its such a shame that an important film like this\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▉                  | 222/1250 [06:56<31:41,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Actually, Son of the Mask did make me laugh a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▉                  | 223/1250 [06:58<31:36,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I don't really consider myself a conservative, so I wasn't\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▉                  | 224/1250 [06:59<31:18,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: It was only a matter of time that a spoof\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▉                  | 225/1250 [07:01<30:59,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: How unfortunate, yet also fortunate, that two films about pot-holing\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▉                  | 226/1250 [07:04<33:42,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 407])\n",
      "Prompt: I've only seen about a half dozen films starring Lino\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|███▉                  | 227/1250 [07:06<33:38,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 341])\n",
      "Prompt: I watched this film on ITV and I enjoyed it\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|████                  | 228/1250 [07:07<32:52,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: One of the best,Lackawanna Blues<br /><br />Great movie,great cast,great music,this\n",
      "Tokenized Prompt Shape: torch.Size([1, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|████                  | 229/1250 [07:09<31:39,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Good idea....shame about the actual movie. Would of liked it\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|████                  | 230/1250 [07:11<31:05,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: This is truly a re-make that should never have gotten\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  18%|████                  | 231/1250 [07:13<30:56,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: This was Hitchcock's third Hollywood feature, and it appears he\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████                  | 232/1250 [07:14<30:51,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: In the final days of the year 1999, most everyone\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████                  | 233/1250 [07:16<30:50,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: The beautifully engaging song with the same name as the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████                  | 234/1250 [07:18<31:22,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 333])\n",
      "Prompt: Not only unique for its time but one of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▏                 | 235/1250 [07:21<33:45,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 399])\n",
      "Prompt: Easily one of my favourite dramatic TV films, in many\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▏                 | 236/1250 [07:22<32:45,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: I'm generally not a fan of high school comedies, they\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▏                 | 237/1250 [07:24<32:28,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: Duchess and her three kittens are enjoying the high life\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▏                 | 238/1250 [07:26<32:07,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: I enjoyed the film, and the fact that it aimed\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▏                 | 239/1250 [07:28<31:23,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This film has a really weird mixture of genres -\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▏                 | 240/1250 [07:30<31:40,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: I've sat through several Pauly Shore movies, but this is\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▏                 | 241/1250 [07:32<32:07,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: One of a few movies filmed at Coronado High School\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▎                 | 242/1250 [07:33<31:15,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Well, I've just seen Buster Keaton's film debut in Fatty\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  19%|████▎                 | 243/1250 [07:35<30:30,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: This British film version of the stage play I AM\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▎                 | 244/1250 [07:37<30:04,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: A fairly interesting look at some characters from India's burgeoning\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▎                 | 245/1250 [07:39<29:52,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: This movie is truly amazing,over the years I have acquired\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▎                 | 246/1250 [07:41<30:29,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: Victor Jory never became a major star. He is better\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▎                 | 247/1250 [07:42<30:13,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: If you have ever wanted to know more about cab\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▎                 | 248/1250 [07:44<30:14,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: There are many so-called anti-war/anti-govt. policy films around now which\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▍                 | 249/1250 [07:46<29:45,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: When A Stranger Calls is actually a pretty good movie.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▍                 | 250/1250 [07:48<31:13,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 359])\n",
      "Prompt: Where would Hollywood have been without Fredric March as Robert\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▍                 | 251/1250 [07:50<32:42,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 373])\n",
      "Prompt: Some movies are off-beat, but enjoyable, but many movies are\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▍                 | 252/1250 [07:52<31:25,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: The story line of a man's love for an innocent\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▍                 | 253/1250 [07:54<31:34,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 333])\n",
      "Prompt: I'm sick of the \"open mind\" argument. I'm generally quite\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▍                 | 254/1250 [07:56<30:58,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: ROCK STAR is a well-told Hollywood-style rendition of the tale\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▍                 | 255/1250 [07:57<30:38,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: Just like all of Mel Brooks' other comedies, Men in\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  20%|████▌                 | 256/1250 [07:59<31:43,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 360])\n",
      "Prompt: Kill the scream queen may sound like a good slasher\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▌                 | 257/1250 [08:01<31:40,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: What makes this documentary special from a film-making perspective is\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▌                 | 258/1250 [08:03<31:04,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: I just watched \"return from lonesome dove\" and it was\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▌                 | 259/1250 [08:05<30:28,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Too much stock footage (almost one third of this 53\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▌                 | 260/1250 [08:07<30:26,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: Reading through the comments, there seems to be a lot\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▌                 | 261/1250 [08:09<30:49,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: You know, I really hate IMDb's censor system, since my\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▌                 | 262/1250 [08:11<30:40,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: While not the first movie I've purchased for myself, this\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▋                 | 263/1250 [08:12<30:09,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: A somewhat typical bit of filmmaking from this era. Obviously,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▋                 | 264/1250 [08:14<29:49,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: An excellent film for those who simply need to switch\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▋                 | 265/1250 [08:16<29:33,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Wow, its been quite a while since I've watched anything\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▋                 | 266/1250 [08:18<29:16,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I am astonished at the major comments here for this\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▋                 | 267/1250 [08:19<29:37,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: Thinly-cloaked retelling of the Garden-of-Eden story -- nothing new, nothing\n",
      "Tokenized Prompt Shape: torch.Size([1, 23])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  21%|████▋                 | 268/1250 [08:21<29:50,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: I must say: out of all modern korean martial arts\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▋                 | 269/1250 [08:23<29:54,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: I saw bits and pieces of this on TV once,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▊                 | 270/1250 [08:25<29:33,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I first saw this when I was a teen in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▊                 | 271/1250 [08:27<31:12,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 370])\n",
      "Prompt: I thought that this movie was incredible. I absolutely loved\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▊                 | 272/1250 [08:29<30:31,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: This film makes several nods to various science fiction films.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▊                 | 273/1250 [08:31<30:20,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: On the cusp of being insufferable. Somehow I stayed just\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▊                 | 274/1250 [08:32<29:36,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This is a really great film! It gets you thinking\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▊                 | 275/1250 [08:34<29:12,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: An atrocious offense to the memory and genius of Welles,\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▊                 | 276/1250 [08:36<29:14,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I just have watched Icon on DVD and despite being\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▉                 | 277/1250 [08:38<28:59,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: \"Return of the Seven\" has a few good action scenes,\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▉                 | 278/1250 [08:40<29:36,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: The girls might be prettier if you're their accompanist or\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▉                 | 279/1250 [08:42<29:33,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Witchcraft/Witchery/La Casa 4/ and whatever else you wish to call\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▉                 | 280/1250 [08:43<28:55,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Cleopatra (the delicious Monica Bellucci) is challenged by Cesar (Alain\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  22%|████▉                 | 281/1250 [08:45<28:34,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Sweeping drama with great sets, costumes and performances Â though\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|████▉                 | 282/1250 [08:47<28:23,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Plunkett and Macleane is an entertaining, fast-paced and refreshing film.\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|████▉                 | 283/1250 [08:48<28:18,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: What an embarassment...This doesnt do justice to the original with\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|████▉                 | 284/1250 [08:50<28:28,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: I do not have much to say than this is\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████                 | 285/1250 [08:52<28:41,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: This movie sucks. It's horrible. If anyone liked it, those\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████                 | 286/1250 [08:54<28:27,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: This movie looked like it was rushed to release for\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████                 | 287/1250 [08:56<29:23,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 339])\n",
      "Prompt: Idiots go camping and act like idiots before they finally\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████                 | 288/1250 [08:58<29:23,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: The notion of marital fidelity portrayed in the film seems\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████                 | 289/1250 [09:00<30:09,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 343])\n",
      "Prompt: I once lived in the u.p and let me tell\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████                 | 290/1250 [09:02<31:12,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 364])\n",
      "Prompt: This is such a great movie to watch and all\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████                 | 291/1250 [09:04<30:45,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Thank God I didn't buy this movie myself! I borrowed\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████▏                | 292/1250 [09:05<30:08,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Nicely filmed, a little uneven, \"Nobody\" is a good evening's\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  23%|█████▏                | 293/1250 [09:07<31:04,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 365])\n",
      "Prompt: Perhaps it's about time we declare 2007 to be \"The\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▏                | 294/1250 [09:09<30:15,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: When I read the synopsis - 3 people lost in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▏                | 295/1250 [09:11<29:40,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Recap: Not entirely familiar with the Shakespeare story of Macbeth,\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▏                | 296/1250 [09:13<28:59,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I wish Depardieu had been able to finish his book\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▏                | 297/1250 [09:15<28:42,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: This movie is a window on the world of Britain\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▏                | 298/1250 [09:17<30:20,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 370])\n",
      "Prompt: THE AFFAIR is a very bad TV movie from the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▎                | 299/1250 [09:20<35:08,  2.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 500])\n",
      "Prompt: This is a great show despite many negative user reviews.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▎                | 300/1250 [09:21<32:50,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: It's hard to use words for this movie, since it\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▎                | 301/1250 [09:23<32:40,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 353])\n",
      "Prompt: OK, we were going along with the stereotypical bad orphanage\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▎                | 302/1250 [09:25<31:21,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: It's 2005, my friends...a time of amazing special effects and\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▎                | 303/1250 [09:27<30:39,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: In \"Lassie Come Home,\" \"National Velvet,\" and \"The Courage of\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▎                | 304/1250 [09:29<29:56,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: I was not very excited to see this movie in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▎                | 305/1250 [09:31<29:44,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: (Very mild spoilers; a basic plot outline, no real details)\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  24%|█████▍                | 306/1250 [09:32<29:02,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This is an astonishingly bad action film. I'd say its\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▍                | 307/1250 [09:34<29:34,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 341])\n",
      "Prompt: I went to see this movie at a book signing\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▍                | 308/1250 [09:37<31:05,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 379])\n",
      "Prompt: Radio is a true story about a man who did\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▍                | 309/1250 [09:38<29:57,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: If \"B\" movies, tired and corny scripts, and golf carts\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▍                | 310/1250 [09:40<30:06,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: This was the first Chan film made by Monogram. What\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▍                | 311/1250 [09:42<29:22,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: This is not a 'real' James Cagney vehicle since his\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▍                | 312/1250 [09:44<30:32,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 370])\n",
      "Prompt: Mr. Bean is just a bunch of unfunny slapstick humour.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▌                | 313/1250 [09:46<29:54,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: The film-makers went well out of their way to find\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▌                | 314/1250 [09:48<29:46,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: There is a lot wrong with this film. I will\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▌                | 315/1250 [09:50<29:53,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: Although little more than a pleasant 11-minute musical diversion (it's\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▌                | 316/1250 [09:52<30:03,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 341])\n",
      "Prompt: William Shakespeare probably didn't envision Stephanos as a gay doctor,\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▌                | 317/1250 [09:54<29:07,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I adore the Ln Chaney version of \"Phantom\" and I\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  25%|█████▌                | 318/1250 [09:56<29:48,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: The trouble with this sort of lyrical film-making is that\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▌                | 319/1250 [09:57<29:18,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Czech movie goers may have enjoyed and rated this film\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▋                | 320/1250 [09:59<28:36,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I loved this film almost as much as the origional\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▋                | 321/1250 [10:01<29:21,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 347])\n",
      "Prompt: I remember seeing the trailer for this film and I\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▋                | 322/1250 [10:03<29:01,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I picked up this movie because it caught my eye\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▋                | 323/1250 [10:05<28:36,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: This film had everything i need in a film: -\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▋                | 324/1250 [10:07<28:46,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: Or at least you feel pretty high after this movie.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▋                | 325/1250 [10:09<28:52,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: This was a fantastically funny footie film. Why won't they\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▋                | 326/1250 [10:10<28:07,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: This movie was by far the worst movie I've ever\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▊                | 327/1250 [10:12<28:04,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: If the following sounds tempting, then by all means rush\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▊                | 328/1250 [10:14<27:51,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: A Cryptozoologist captures a mythical chupacabra on a Caribbean island.To\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▊                | 329/1250 [10:16<27:25,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: SPOILERS<br /><br />*<br /><br />*<br /><br />*<br /><br />*<br /><br\n",
      "Tokenized Prompt Shape: torch.Size([1, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▊                | 330/1250 [10:17<26:35,  1.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: This movie is called \"Solomon Kane\". Which it isn't. The\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  26%|█████▊                | 331/1250 [10:20<30:49,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 458])\n",
      "Prompt: There's an underlying current in all the positive reviews of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▊                | 332/1250 [10:22<29:33,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Okay, make no mistake - this is a pretty awful\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▊                | 333/1250 [10:23<28:44,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Yet another version of mother of all gangster flicks-the Classic\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▉                | 334/1250 [10:25<28:32,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: I own this movie on DVD and I have watched\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▉                | 335/1250 [10:27<28:20,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I totally agree. This is \"Pitch Black underground\" and a\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▉                | 336/1250 [10:29<27:41,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I was hoping this would be of the calibre of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▉                | 337/1250 [10:31<27:25,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Would you be surprised if I told you this movie\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▉                | 338/1250 [10:32<27:41,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: Robot Holocaust is about the lamest, most pathetic attempt at\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▉                | 339/1250 [10:34<27:22,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Although this film changes reality to make it more heroic\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|█████▉                | 340/1250 [10:36<27:09,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: The only thing I expected that this film didn't have\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|██████                | 341/1250 [10:38<27:01,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I, for one, absolutely loved this movie.<br /><br />It is\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|██████                | 342/1250 [10:39<26:40,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Hellraiser: Bloodline is where the sequel mediocrity of the Hellraiser\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  27%|██████                | 343/1250 [10:41<26:42,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: Gracie (Minnie Driver), a woman in her late twenties, is\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████                | 344/1250 [10:43<26:48,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: The film starts with promise because there is more interaction\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████                | 345/1250 [10:45<27:20,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: I didn't know a lot about this film going into\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████                | 346/1250 [10:47<27:11,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Not \"confusing\" in the sense that, \"Gee, this movie is\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████                | 347/1250 [10:49<28:32,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 369])\n",
      "Prompt: <br /><br />I understand that people have different expectations of\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████                | 348/1250 [10:51<27:57,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: There was once someone in my family (not saying who\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████▏               | 349/1250 [10:53<28:15,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: Many teenage sex comedy movies come and go without much\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████▏               | 350/1250 [10:54<28:18,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: I love comedies and I love independent films, but this\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████▏               | 351/1250 [10:56<27:53,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: This film has some pretty gorey parts like a boob\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████▏               | 352/1250 [10:58<29:02,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 366])\n",
      "Prompt: When i found out there was a Christmas Vacation 2,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████▏               | 353/1250 [11:00<28:36,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Sally and Saint Anne is a very funny movie. The\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████▏               | 354/1250 [11:02<28:00,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I rarely even bother to watch comedic movies or television\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████▏               | 355/1250 [11:04<27:29,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I've Seen The Beginning Of The Muppet Movie, But Just\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  28%|██████▎               | 356/1250 [11:06<27:04,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This movie might be o.k. if not for all the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▎               | 357/1250 [11:07<26:41,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Chuck Jones's 'Rabbit Seasoning', the second in the much beloved\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▎               | 358/1250 [11:09<26:45,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: This is without a doubt the WORST sequel I have\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▎               | 359/1250 [11:11<28:20,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 372])\n",
      "Prompt: There is only one word to define the whole movie,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▎               | 360/1250 [11:13<27:59,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: The Stunts sequences (as well as the Special Effects) are\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▎               | 361/1250 [11:15<27:30,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: ****SPOILER ALERT**** My boyfriend, some friends, and I rented this\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▎               | 362/1250 [11:17<27:35,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: I'm a fan of the horror movie, regardless of which\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▍               | 363/1250 [11:19<27:26,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: The answer.....No, sadly not. Though miller and the sweep has\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▍               | 364/1250 [11:20<27:37,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 333])\n",
      "Prompt: I'm in a film class and i know that i\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▍               | 365/1250 [11:22<27:49,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: Part of the movie's low rating is the emphasis on\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▍               | 366/1250 [11:24<27:09,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: A very interesting addition to the Scandavian surrealistic collection. Recommended\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▍               | 367/1250 [11:26<26:52,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: I have never seen this in the theater, my second\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  29%|██████▍               | 368/1250 [11:28<26:38,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Hercules: The TV- Movie Hercules - A very twisted and\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▍               | 369/1250 [11:30<28:27,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 386])\n",
      "Prompt: I accidentally caught this in the middle flipping channels. I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▌               | 370/1250 [11:32<28:00,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: Many times the description \"full of sound and fury signifying\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▌               | 371/1250 [11:34<27:35,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Wicked Little things was a really good movie.I will say\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▌               | 372/1250 [11:36<27:53,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: Christopher Lambert attracted me to this movie. What a waste!\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▌               | 373/1250 [11:37<27:09,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Everyone told me this movie was downright not good, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▌               | 374/1250 [11:39<26:48,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Despite looking dated, \"Inki and the Minah Bird\" is, my\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▌               | 375/1250 [11:41<26:12,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I do not find this show at all funny. I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▌               | 376/1250 [11:43<26:07,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: It's a short movie for such immense feelings. The last\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▋               | 377/1250 [11:44<26:19,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: We are in a small town, a homely widow (Ida\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▋               | 378/1250 [11:46<25:56,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: E. Elias Merhige's existentialist experiment in the enduring is definitely\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▋               | 379/1250 [11:48<26:00,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This film was basically set up for failure by the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▋               | 380/1250 [11:50<26:11,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: I cannot hate on the show. When the old (and\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  30%|██████▋               | 381/1250 [11:52<26:23,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Guess a few upscale film directors were sitting around sipping\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▋               | 382/1250 [11:53<26:24,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: My Santa Lucia Choir was chosen to be in this\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▋               | 383/1250 [11:55<26:30,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Lucio Fulci, later known for his graphic horror films like\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▊               | 384/1250 [11:57<27:29,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 358])\n",
      "Prompt: This movie probably began with a good idea but that's\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▊               | 385/1250 [11:59<27:53,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 345])\n",
      "Prompt: After receiving a DVD of this with a Sunday newspaper,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▊               | 386/1250 [12:01<27:02,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: First things first, how can someone with his creativity on\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▊               | 387/1250 [12:03<26:57,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I figure this to be an \"alternate reality\" teen flick...More\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▊               | 388/1250 [12:05<26:27,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Rarely will anyone deny that Hitchcock remains one of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▊               | 389/1250 [12:07<26:02,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: The original The Man Who Knew Too Much brought Alfred\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▊               | 390/1250 [12:08<25:45,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This is a really bad waste of your time. I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▉               | 391/1250 [12:10<25:29,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: \"What Alice Found\" is the greatest movie that nobody's ever\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▉               | 392/1250 [12:12<25:21,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Critics are falling over themselves within the Weinstein's Sphere of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  31%|██████▉               | 393/1250 [12:14<25:11,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: (***Minor spoilers***)<br /><br />If there's something in the world of\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|██████▉               | 394/1250 [12:15<25:40,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: First and foremost I am a gay man, although do\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|██████▉               | 395/1250 [12:17<25:22,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I haven't seen this fine movie in 50 years but\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|██████▉               | 396/1250 [12:19<25:32,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: The child actor certainly deserves a lot of credit. It\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|██████▉               | 397/1250 [12:21<26:11,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 337])\n",
      "Prompt: I had the honor this evening to see a screening\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████               | 398/1250 [12:23<25:44,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: i love this show! it is amazing...i can never miss\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████               | 399/1250 [12:24<25:19,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: The only interesting part of this movie was it's jazz\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████               | 400/1250 [12:26<25:46,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: Anna Christie (Greta Garbo) returns to see her father Chris\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████               | 401/1250 [12:28<26:14,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 338])\n",
      "Prompt: How could they take such a beautifully animated gem like\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████               | 402/1250 [12:30<26:35,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: This is classic 80's humor. If you were a teen\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████               | 403/1250 [12:32<26:13,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: \"Go Fish\" garnered Rose Troche rightly or wrongly the reputation\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████               | 404/1250 [12:34<26:46,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 346])\n",
      "Prompt: I like Steve Buscemi. I like his work very much,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████▏              | 405/1250 [12:36<26:47,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 333])\n",
      "Prompt: Hoot is a nice plain movie with a simple message.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  32%|███████▏              | 406/1250 [12:38<26:29,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: This is the worst film I have ever seen, so\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▏              | 407/1250 [12:39<25:50,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: ... or should I say unintentionally hilarious? Either way, this\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▏              | 408/1250 [12:41<25:42,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: this show is just plain awful. I liked to watch\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▏              | 409/1250 [12:43<25:48,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Could possibly be the worst film ever made. At least\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▏              | 410/1250 [12:45<25:46,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: SPOILER WARNING<br /><br />I got this dino-documentarie on DVD at\n",
      "Tokenized Prompt Shape: torch.Size([1, 21])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▏              | 411/1250 [12:47<25:04,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I was fortunate enough to see The Last Stop here\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▎              | 412/1250 [12:48<25:04,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: The book was one of Stephen King's best. The movie\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▎              | 413/1250 [12:50<24:53,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: The story takes place on the streets of Sao Paoulo\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▎              | 414/1250 [12:52<24:51,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: **SPOILERS** With the title of the film having the name\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▎              | 415/1250 [12:54<24:35,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I checked out this video expecting to like it. Wanting\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▎              | 416/1250 [12:56<25:04,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: I watched the first few episodes a short while back\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▎              | 417/1250 [12:57<24:56,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Like its near contemporaries \"The Great Race\" and \"Those Magnificent\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  33%|███████▎              | 418/1250 [12:59<25:07,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: A college professor is working on creating zombies and, wouldn't\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▎              | 419/1250 [13:02<27:39,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 413])\n",
      "Prompt: This terrible moovie is fun on many levels - the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▍              | 420/1250 [13:04<27:03,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: From the dire special effects onwards I was absolutely gob\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▍              | 421/1250 [13:06<28:21,  2.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 390])\n",
      "Prompt: A wonderful film - a charming, quirky family story. A\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▍              | 422/1250 [13:08<28:33,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 363])\n",
      "Prompt: I just have to say that this was the third\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▍              | 423/1250 [13:10<27:41,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: The major flaw in this Spanish slasher/shocker is within it's\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▍              | 424/1250 [13:12<26:34,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: This movie packs a punch. There are a few every\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▍              | 425/1250 [13:14<27:03,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 339])\n",
      "Prompt: This scene shows how Wallace's experiment by using his brain\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▍              | 426/1250 [13:15<26:04,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Barney is that idiot dinosaur who (unfortunaltely) didn't go extinct\n",
      "Tokenized Prompt Shape: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▌              | 427/1250 [13:17<25:23,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Let me first start out by saying 1 out of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▌              | 428/1250 [13:19<25:25,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: I didn't really care for this. Had they gotten rid\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▌              | 429/1250 [13:21<25:35,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: The worst movie I have ever seen. The sound quality\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▌              | 430/1250 [13:23<25:41,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: \"The Couch Trip\" is one of those silly comedies that\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  34%|███████▌              | 431/1250 [13:25<25:13,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Abderrahmane Sissako may have known what he was doing when\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▌              | 432/1250 [13:26<24:59,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: My Young Auntie is unique in a lot of ways.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▌              | 433/1250 [13:28<24:37,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Arthur Hunnicutt plays a very stereotypical role as a mountain\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▋              | 434/1250 [13:30<24:40,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: Good attempt at tackling the unconventional topic of May-December romances.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▋              | 435/1250 [13:32<24:42,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: As Joe Bob Briggs would say, this movie relies a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▋              | 436/1250 [13:34<25:05,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: Straight from the brilliant mind of animation pioneer Wladyslaw Starewicz,\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▋              | 437/1250 [13:35<24:35,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: If you like The Three Stooges you'll undoubtedly like this\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▋              | 438/1250 [13:37<24:16,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I bought my first Zep album in 1974 (at 17)\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▋              | 439/1250 [13:39<24:17,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: The Golden Door is the story of a Sicilian family's\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▋              | 440/1250 [13:41<24:18,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: This is one of the funniest movies I have ever\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▊              | 441/1250 [13:43<24:14,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Jason Lee does well to give this doggy movie fleeting\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▊              | 442/1250 [13:44<24:06,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: I loved this movie. My daughter is 3 1/2 and\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  35%|███████▊              | 443/1250 [13:46<23:50,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Wow. I just saw Demon Wind a little while ago,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▊              | 444/1250 [13:48<23:40,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I was very disappointed when this show was canceled. Although\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▊              | 445/1250 [13:50<23:46,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: Five years after she teamed up with James Cagney in\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▊              | 446/1250 [13:51<23:41,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I'll give it this: I didn't stop watching, and it's\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▊              | 447/1250 [13:53<23:48,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Naach A more detailed review can be obtained anywhere else\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▉              | 448/1250 [13:55<23:38,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: An in-name-only sequel to John Carpenter's Vampires, this movie takes\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▉              | 449/1250 [13:57<23:26,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I found the movie at my local video store and\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▉              | 450/1250 [13:58<23:34,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Historical drama is one of the areas where the British\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▉              | 451/1250 [14:00<23:42,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Johnny Crawford is great in this movie of a troubled\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▉              | 452/1250 [14:02<23:55,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Kate Gulden, played by one of the most nominated actresses\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▉              | 453/1250 [14:04<23:41,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: A couple are split apart during a vacation. Early scenes\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|███████▉              | 454/1250 [14:06<23:40,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Anyone who has ever gone on an audition can certainly\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|████████              | 455/1250 [14:08<24:11,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: This is the most stupid movie ever made. The story\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  36%|████████              | 456/1250 [14:09<23:48,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I'm shocked that all the \"hated it\" ratings are sixes\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████              | 457/1250 [14:11<23:41,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: A great look at the 60s through the eyes of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████              | 458/1250 [14:13<23:52,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: OK. Who ever invented this film hates humanity and wants\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████              | 459/1250 [14:15<23:46,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: This movie, which I just discovered at the video store,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████              | 460/1250 [14:17<23:59,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: This movie is crappy beyond any limits. It's incredible -\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████              | 461/1250 [14:18<24:25,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 336])\n",
      "Prompt: If you're coming to this film to learn something about\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████▏             | 462/1250 [14:20<24:11,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Why is it better? Because it's true to the dark\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████▏             | 463/1250 [14:22<23:45,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I'm starting to wonder, after reading some of the opinions\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████▏             | 464/1250 [14:24<23:54,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: On its surface, this is one of the most classically\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████▏             | 465/1250 [14:26<23:46,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: First, I don't see how the movie is on any\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████▏             | 466/1250 [14:28<24:22,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: I had the pleasure of seeing this short film at\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████▏             | 467/1250 [14:30<24:45,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 339])\n",
      "Prompt: And you'd be right. Black Mama, White Mama, also known\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  37%|████████▏             | 468/1250 [14:32<25:53,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 363])\n",
      "Prompt: I once caught about a 20 minute portion of this\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▎             | 469/1250 [14:34<26:06,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 352])\n",
      "Prompt: While Disney have been THE animation studio for the past\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▎             | 470/1250 [14:36<25:18,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: To date this is still the worst piece of rubbish\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▎             | 471/1250 [14:38<24:56,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: I understand \"Checking Out\" will likely be released in Theatres\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▎             | 472/1250 [14:39<24:08,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I got this movie from eBay mainly because I'm gay\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▎             | 473/1250 [14:41<23:43,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: One of the best TV shows out there, if not\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▎             | 474/1250 [14:43<23:26,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I am not understanding why people are praising this movie.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▎             | 475/1250 [14:45<23:28,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Over the years some of them most enjoyable films have\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▍             | 476/1250 [14:46<23:12,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I saw this movie when it was first released in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▍             | 477/1250 [14:48<24:01,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: I was hoping to like this movie, to settle in\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▍             | 478/1250 [14:50<24:39,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: The Late Shift is a great book, I read the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▍             | 479/1250 [14:52<24:49,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: Film critics of the world, I apologize. It is your\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▍             | 480/1250 [14:54<24:41,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: I was hooked in by the premise that the show\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  38%|████████▍             | 481/1250 [14:56<24:40,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: SPOILER NOTHING BUT SPOILER<br /><br />I have to add my\n",
      "Tokenized Prompt Shape: torch.Size([1, 21])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▍             | 482/1250 [14:58<24:05,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: A less than redemptive hunka junk that is mercifully free\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▌             | 483/1250 [15:00<23:45,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I'm a Geena Davis fan for life because of this\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▌             | 484/1250 [15:02<23:15,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Used to watch this when i was very little, then\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▌             | 485/1250 [15:03<23:21,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: -SPOILERS------------ I am a fan of 60's-70's french cinema but\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▌             | 486/1250 [15:05<22:57,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: I am a fan of a few of the Vacation\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▌             | 487/1250 [15:07<23:05,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: Episode No. thirteen of the fanciful (excuse the incredibly gay\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▌             | 488/1250 [15:09<22:42,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: One of my favorite westerns and one of John Ford's\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▌             | 489/1250 [15:11<23:28,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 345])\n",
      "Prompt: First of all I dunno if I was supposed to\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▌             | 490/1250 [15:12<23:02,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: To identify this movie as a vampire movie would be\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▋             | 491/1250 [15:14<22:58,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: Does anyone remember BRAVEHEART ? It starred Mel Gibson who\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▋             | 492/1250 [15:16<23:03,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Lou Gossett, Jr. is an excellent and captivating actor, but\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  39%|████████▋             | 493/1250 [15:18<24:19,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 378])\n",
      "Prompt: Terrible. The only way I could even begin to consider\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▋             | 494/1250 [15:20<24:15,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: I like Arnold, and I love the subject matter, but\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▋             | 495/1250 [15:22<23:38,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Following the movie that represents the pinnacle of the 1980's\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▋             | 496/1250 [15:24<23:21,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: The Emperor's (Richard Haydn) dog is betrothed to Johanna's (Joan\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▋             | 497/1250 [15:26<24:02,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 349])\n",
      "Prompt: I was a fan of the AMERICAN WEREWOLF IN LONDON\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▊             | 498/1250 [15:28<23:35,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: Just had the misfortune to see this truly awful film.<br\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▊             | 499/1250 [15:29<23:19,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: I think it is saying something that the Bollywood \"Bride\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▊             | 500/1250 [15:32<24:00,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 351])\n",
      "Prompt: Wow. this movie is the voice of a climbing generation.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▊             | 501/1250 [15:34<24:18,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 347])\n",
      "Prompt: Let's face it, this is a pretty bad film.However if\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▊             | 502/1250 [15:35<24:06,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I absolutely recommend this movie to anyone who wants to\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▊             | 503/1250 [15:37<24:03,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: This film was hilarious. It provided a somewhat comical view\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▊             | 504/1250 [15:39<23:39,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: This movie is surprisingly good. The ninja fighting sequences were\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▉             | 505/1250 [15:41<23:17,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: I recently rented this film on DVD and thought it\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  40%|████████▉             | 506/1250 [15:43<23:04,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I came out of \"Dark Blue World\" feeling (sigh) 'so\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|████████▉             | 507/1250 [15:45<22:51,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: I don't even like watching those late night talk shows,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|████████▉             | 508/1250 [15:46<22:32,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I really enjoyed this both times I watched it. And\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|████████▉             | 509/1250 [15:48<23:22,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 341])\n",
      "Prompt: The most beautiful film. If one is looking for serious\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|████████▉             | 510/1250 [15:51<23:57,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: It is such a shame when actors and actresses of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|████████▉             | 511/1250 [15:52<23:19,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: First off i'll give this movie a low scoring 4\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|█████████             | 512/1250 [15:54<22:44,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: There was absolutely nothing in this film that hadn't been\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|█████████             | 513/1250 [15:56<22:35,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: Well, it's safe to say that Subconscious Cruelty is one\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|█████████             | 514/1250 [15:58<24:43,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 418])\n",
      "Prompt: ***SPOILERS*** ***SPOILERS*** HERE ON EARTH / (2000) 1/2* (out of\n",
      "Tokenized Prompt Shape: torch.Size([1, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|█████████             | 515/1250 [16:00<24:01,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: I simply cannot believe the folks that made and performed\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|█████████             | 516/1250 [16:02<24:34,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 364])\n",
      "Prompt: As talk-shows go, Larry King Live is not bad, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|█████████             | 517/1250 [16:04<23:29,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I have now seen quite a few films by Pedro\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  41%|█████████             | 518/1250 [16:06<23:07,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: John Sayles, what have you done?<br /><br />\"Silver City\" had\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▏            | 519/1250 [16:08<22:45,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Mickey Rourke is enjoying a renaissance at the moment... and\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▏            | 520/1250 [16:10<23:29,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 359])\n",
      "Prompt: Stumbled over this film on Amazon.com. Had never heard of\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▏            | 521/1250 [16:11<22:40,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: This movie must be exported to the rest of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▏            | 522/1250 [16:13<22:17,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Jeremy Irons and Forrest Whitaker are good actors. But this\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▏            | 523/1250 [16:15<22:16,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: OK....so, by minute 15 in the film, there's still no\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▏            | 524/1250 [16:17<22:48,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 347])\n",
      "Prompt: Son In Law didn't do so hot in the box\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▏            | 525/1250 [16:19<22:18,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: SAIMIN <br /><br />(USA: The Hypnotist /UK: Hypnosis) <br /><br\n",
      "Tokenized Prompt Shape: torch.Size([1, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▎            | 526/1250 [16:20<21:50,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: What I enjoyed most in this film was the scenery\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▎            | 527/1250 [16:22<22:08,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: In the 70's in Afghanistan, the Pushtun boy Amir (Zekeria\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▎            | 528/1250 [16:24<22:48,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 355])\n",
      "Prompt: Director/screenwriter Diane English's 2008 update of George Cukor's 1939 MGM\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▎            | 529/1250 [16:26<22:11,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Noel Coward is perfectly cast as a suave, vain, selfish\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▎            | 530/1250 [16:28<22:20,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: When I was 8 years old, and going through my\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  42%|█████████▎            | 531/1250 [16:30<22:47,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 337])\n",
      "Prompt: Although it might seem a bit bizarre to see a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▎            | 532/1250 [16:32<22:33,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: I really enjoyed this movie... In My DVD collection of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▍            | 533/1250 [16:34<22:30,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: Looking at these reviews and seeing all these high ratings\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▍            | 534/1250 [16:36<22:21,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: This was a great movie for being only 67 minutes\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▍            | 535/1250 [16:38<22:32,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: Usually I do not like movies with/about aliens but K-PAX\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▍            | 536/1250 [16:39<22:28,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: This is a film with a lot of potential, well\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▍            | 537/1250 [16:42<24:12,  2.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 383])\n",
      "Prompt: DON'T EVEN TRY to figure out the logic of this\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▍            | 538/1250 [16:44<23:31,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: This show is actually pretty good. Like all shows on\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▍            | 539/1250 [16:46<23:13,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Daft potboilers don't come much dafter than this, but it's\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▌            | 540/1250 [16:47<22:55,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This film is a fun little private eye detective story\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▌            | 541/1250 [16:49<22:55,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Set in Paris in the year 1910, a retired old\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▌            | 542/1250 [16:51<22:38,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Let me be clear. I hate these kinds of movies.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  43%|█████████▌            | 543/1250 [16:53<22:12,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: This sequel is brilliant and is the last film Donald\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▌            | 544/1250 [16:55<21:58,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: ah man this movie was funny as hell, yet strange.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▌            | 545/1250 [16:57<21:29,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: A long time ago, way back in the early '80s,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▌            | 546/1250 [16:59<21:57,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I first saw it at 5am January 1, 2009, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▋            | 547/1250 [17:00<21:39,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: A gruelling watch, but one of Bergman's finest films. Interesting\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▋            | 548/1250 [17:03<22:46,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 345])\n",
      "Prompt: Terribly disappointed with CITY OF MEN after being swept away\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▋            | 549/1250 [17:05<22:52,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: Well This was a complete waste of celluloid. The preview\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▋            | 550/1250 [17:07<23:13,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: I remember being so excited on Saturday nights when I\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▋            | 551/1250 [17:09<24:16,  2.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 368])\n",
      "Prompt: I was entertained to see that some of the reviews\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▋            | 552/1250 [17:11<23:18,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: The Jaws rip off is the trashiest of the all\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▋            | 553/1250 [17:13<23:16,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: Imagine a world, in which everyone treats anyone nicely, no\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▊            | 554/1250 [17:15<23:01,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: A tough life gets tougher when the three children of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▊            | 555/1250 [17:17<22:46,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I have always been fascinated by silent films. There is\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  44%|█████████▊            | 556/1250 [17:19<22:44,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: If you consider yourself a horror movie fan, chances are\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▊            | 557/1250 [17:20<22:14,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: This movie is one of my favorite comedies of all\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▊            | 558/1250 [17:22<22:21,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Excellent example of the disaster that happens when you combine\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▊            | 559/1250 [17:24<22:05,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I saw this movie when I was a kid and\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▊            | 560/1250 [17:26<21:35,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: One of the myths of the early sound era is\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▊            | 561/1250 [17:28<21:18,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Would somebody please explain why anybody would want to make\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▉            | 562/1250 [17:30<21:04,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: The film has so much potential which was not developed.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▉            | 563/1250 [17:32<21:11,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I watched Pola X because Scott Walker composed the film\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▉            | 564/1250 [17:34<21:34,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: There's a part of me that would like to give\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▉            | 565/1250 [17:35<21:32,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: loved the story of a guy that tries to get\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▉            | 566/1250 [17:38<22:17,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 352])\n",
      "Prompt: \"Hey, I didn't order no cab!\" \"Yeah, well you got\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▉            | 567/1250 [17:40<22:25,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 344])\n",
      "Prompt: Not to be mistaken as the highly touted Samuel L.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  45%|█████████▉            | 568/1250 [17:42<22:58,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 357])\n",
      "Prompt: This noisy, dizzying football film from director Oliver Stone seems\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████            | 569/1250 [17:44<22:54,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: Bean, Kevin & Perry, UK TV creations that have made\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████            | 570/1250 [17:46<22:53,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 341])\n",
      "Prompt: Note, I only saw approximately the last half of this\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████            | 571/1250 [17:48<22:50,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: ... So some people might argue that this can't possible\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████            | 572/1250 [17:50<22:11,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: THE OTHER is a supposed \"horror\" movie made during the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████            | 573/1250 [17:51<21:52,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: The obsession of 'signifie' and 'signifiant' is not enough to\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████            | 574/1250 [17:53<21:37,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: I may differ from many people on this board but\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████            | 575/1250 [17:55<21:40,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: I liked this probably slightly more than Terror by Night\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████▏           | 576/1250 [17:57<21:14,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Well, it is a Monogram quickie from the dreaded period\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████▏           | 577/1250 [18:00<23:29,  2.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 407])\n",
      "Prompt: They do... Each sequel is worst. You, who think that\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████▏           | 578/1250 [18:02<23:25,  2.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 358])\n",
      "Prompt: I saw this documentary film at the 2005 Slamdance independent\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████▏           | 579/1250 [18:03<22:16,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I saw this version about a decade ago, and have\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████▏           | 580/1250 [18:05<21:56,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: I believe that this is one of Elizabeth Montgomery's best\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  46%|██████████▏           | 581/1250 [18:07<21:17,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: It's impossible to make a film based on such a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▏           | 582/1250 [18:09<21:18,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: I think this is the worst movie I have seen\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▎           | 583/1250 [18:11<21:39,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 333])\n",
      "Prompt: **Possible Spoilers Ahead**<br /><br />Whenever fans of bad movies congregate\n",
      "Tokenized Prompt Shape: torch.Size([1, 21])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▎           | 584/1250 [18:13<21:35,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: There is no doubt that the Kokoda Trail depicts a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▎           | 585/1250 [18:15<21:04,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: This is a simple episode ad so far after watching\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▎           | 586/1250 [18:17<21:02,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: The directing is brilliant, the casting is remarkable (though I\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▎           | 587/1250 [18:19<20:43,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: I lasted almost ninety minutes through this dreadful movie waiting\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▎           | 588/1250 [18:20<20:53,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: 'Water' (2005), the final part of Toronto-based Indian film-director Deepa\n",
      "Tokenized Prompt Shape: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▎           | 589/1250 [18:22<20:52,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This was a pleasant musical about the creation of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▍           | 590/1250 [18:24<20:45,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: The vampire \"craze\" has, in my opinion, actually proved its\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▍           | 591/1250 [18:26<21:11,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: OK, well, no one in their right mind(s) would pick\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▍           | 592/1250 [18:28<21:42,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 337])\n",
      "Prompt: This is one of the worst mini-series I have ever\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  47%|██████████▍           | 593/1250 [18:30<21:36,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: All the hype! All the adds! I was bummed that\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▍           | 594/1250 [18:32<21:52,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 357])\n",
      "Prompt: I thought this film was quite good and quite entertaining\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▍           | 595/1250 [18:34<21:13,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: This superb 40's post war classic, tends to be overlooked\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▍           | 596/1250 [18:36<21:06,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: The stark, cold landscape of Big Sky Country, with its\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▌           | 597/1250 [18:38<21:53,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 376])\n",
      "Prompt: In this day and age in which just about every\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▌           | 598/1250 [18:40<21:05,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This has got to be the best movie I've seen.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▌           | 599/1250 [18:42<20:31,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I was actually planning to see this movie when I\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▌           | 600/1250 [18:44<20:29,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: I waited quite awhile till I was able to watch\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▌           | 601/1250 [18:46<20:32,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: This movie is bad. I saw the rated and the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▌           | 602/1250 [18:48<20:27,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: I saw this movie on a show that was showing\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▌           | 603/1250 [18:49<20:09,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: Here's a spoof that's guaranteed to entertain folks in the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▋           | 604/1250 [18:51<19:58,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I would like to thank you for giving me a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▋           | 605/1250 [18:53<19:41,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Honestly - this short film sucks. the dummy used in\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  48%|██████████▋           | 606/1250 [18:55<19:26,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: \"Journey to the Far Side of the Sun\" (aka \"Doppelganger\")\n",
      "Tokenized Prompt Shape: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▋           | 607/1250 [18:56<19:02,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: After watching this film I decided that it was so\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▋           | 608/1250 [18:58<18:58,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Ocean's 12 starts off on annoying and gets worse from\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▋           | 609/1250 [19:00<18:59,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Anthony Quinn was a legend of 20th century in cinema\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▋           | 610/1250 [19:02<19:37,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 342])\n",
      "Prompt: I can't seem to find anything that is good about\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▊           | 611/1250 [19:04<19:47,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: In my analysis of \"Trois couleurs: Blanc\" I wrote that\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▊           | 612/1250 [19:06<19:21,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: The plot is somewhat original, and all the actors did\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▊           | 613/1250 [19:07<19:08,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I just finished watching the movie tonight and I truly\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▊           | 614/1250 [19:09<19:05,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: This film was a wonderful romp, intelligent, playful, mysterious, full\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▊           | 615/1250 [19:11<18:56,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: The Best of Everything is a high gloss large screen\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▊           | 616/1250 [19:13<18:53,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: There is something about this show that keeps me watching\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▊           | 617/1250 [19:15<19:04,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: While driving in a dangerous zigzag manner on a lonely\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  49%|██████████▉           | 618/1250 [19:16<19:10,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: One of the many speculations about Y2K was that the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|██████████▉           | 619/1250 [19:18<19:23,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: This movie was filmed in my hometown and I was\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|██████████▉           | 620/1250 [19:20<19:24,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: There really is very little positive that can be said\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|██████████▉           | 621/1250 [19:22<19:18,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: As many of today's movies are guilty of, the plot\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|██████████▉           | 622/1250 [19:24<19:42,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 341])\n",
      "Prompt: Victor Sjostrom's silent film masterpiece The Phantom Carriage has recently\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|██████████▉           | 623/1250 [19:26<19:07,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: You would really need to remember the Monkees and have\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|██████████▉           | 624/1250 [19:28<19:06,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: \"Who Will Love My Children\" Saddest movie I have ever\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|███████████           | 625/1250 [19:30<21:21,  2.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 439])\n",
      "Prompt: A lovely librarian, played by Playboy model Kristine DeBell, falls\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|███████████           | 626/1250 [19:32<20:39,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: I was duped as well. Here I was expecting all\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|███████████           | 627/1250 [19:34<19:55,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I suffered the watching of this movie at Sitges Festival\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|███████████           | 628/1250 [19:35<19:22,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: \"Quintet\" is definitely not a film most people would find\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|███████████           | 629/1250 [19:37<19:07,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: Notable only as the acting debut of future big-time Hollywood\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|███████████           | 630/1250 [19:39<18:45,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Better than I expected from a film selling itself on\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  50%|███████████           | 631/1250 [19:41<18:59,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: Seriously, I don't understand how Justin Long is becoming increasingly\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████           | 632/1250 [19:43<18:44,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Silly Disney film about a college student who accidentally discovers\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▏          | 633/1250 [19:45<18:55,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: Looking back on Jim Henson's works years after his death\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▏          | 634/1250 [19:46<18:37,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This looks so good on paper - Matt Damon, Lawrence\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▏          | 635/1250 [19:48<18:23,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This version of \"The Magic Flute\" is not only the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▏          | 636/1250 [19:50<18:17,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: I don't know, but the movie was just too similar\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▏          | 637/1250 [19:52<19:14,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: \"The Moon Is Blue\" director Otto Preminger tackled even more\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▏          | 638/1250 [19:54<18:52,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: a scarily real drama, there isn't another drama out there\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▏          | 639/1250 [19:56<19:07,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: This turned out all right and looks interesting. However, as\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▎          | 640/1250 [19:58<19:16,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: This is an enjoyable project, that is not a film\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▎          | 641/1250 [19:59<18:59,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Wow, \"The Curse of Michael Myers\" what a great film.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▎          | 642/1250 [20:01<18:36,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I just watched Atoll K-Laurel and Hardy's last movie together\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  51%|███████████▎          | 643/1250 [20:04<20:21,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 419])\n",
      "Prompt: I just discovered this obscure '70s horror movie while browsing\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▎          | 644/1250 [20:06<21:12,  2.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 395])\n",
      "Prompt: It's really a shame to see so many talented people\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▎          | 645/1250 [20:08<20:07,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I quit watching \"The West Wing\" after Aaron Sorkin quit\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▎          | 646/1250 [20:10<20:19,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 359])\n",
      "Prompt: Hypothetical situations abound, one-time director Harry Ralston gives us the\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▍          | 647/1250 [20:12<19:46,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: Oppenheimer was a GREAT series (it was the first thing\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▍          | 648/1250 [20:13<19:37,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: This three-hour Chinese epic, set in 220 B.C., may ultimately\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▍          | 649/1250 [20:15<19:05,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: sure this movie may have had its funny moments with\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▍          | 650/1250 [20:17<20:05,  2.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 385])\n",
      "Prompt: What a stupid idea. Ewoks should be enslaved and tortured.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▍          | 651/1250 [20:19<19:49,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 336])\n",
      "Prompt: if you are dating a girl that is into wicca!<br\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▍          | 652/1250 [20:21<19:22,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: I won't waste your time by describing the plot for\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▍          | 653/1250 [20:23<18:53,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Goldrush: A Real Life Alaskan Adventure is a great tv\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▌          | 654/1250 [20:25<18:27,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: OK, I am a sucker. I loved it. I had\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▌          | 655/1250 [20:27<18:11,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I really liked this picture, because it realistically dealt with\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  52%|███████████▌          | 656/1250 [20:28<17:53,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I am right now watching \"The Big Chill\" on DVD.\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▌          | 657/1250 [20:30<17:54,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: Ok, so I saw this movie at this year's Sundance,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▌          | 658/1250 [20:32<18:35,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 355])\n",
      "Prompt: I too saw this film at a film festival, but\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▌          | 659/1250 [20:34<18:36,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: How in the world does a thing like this get\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▌          | 660/1250 [20:36<19:02,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 351])\n",
      "Prompt: The preposterous premise of this flick has to do with\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▋          | 661/1250 [20:38<18:45,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: This movie was NOTHING like the book. I think the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▋          | 662/1250 [20:40<18:12,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: When I first saw the trailer for this film, I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▋          | 663/1250 [20:42<17:50,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Ken Loach showed the world the down-and-out flip side of\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▋          | 664/1250 [20:43<17:35,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Why all the negative reviews??? You didn't expect a movie\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▋          | 665/1250 [20:45<18:04,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 341])\n",
      "Prompt: There's nothing much to the story. A young woman steals\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▋          | 666/1250 [20:47<18:03,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: Back in the mid/late 80s, an OAV anime by title\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▋          | 667/1250 [20:49<17:51,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: In 1961, this series was shown on local TV here\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  53%|███████████▊          | 668/1250 [20:51<17:52,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: This absurd movie was about a \"Goodie-two-shoe,\" teen-girl that really\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▊          | 669/1250 [20:52<17:27,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Death Camp Opera: Right Here, Right Now!<br /><br />Ten years\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▊          | 670/1250 [20:55<18:15,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 366])\n",
      "Prompt: This movie was trying to something, but failed miserably. All\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▊          | 671/1250 [20:56<17:48,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: The many other comments about the film say it all\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▊          | 672/1250 [20:58<17:40,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: First of all, season 1 is intolerably bad. The prison\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▊          | 673/1250 [21:00<17:21,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This is one of the best films I have ever\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▊          | 674/1250 [21:02<17:14,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Rita Hayworth lights up the screen in this fun, fancy\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▉          | 675/1250 [21:03<17:16,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: \"Duckman\" is a great show. I first saw it when\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▉          | 676/1250 [21:05<17:07,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: The music is by Stravinsky (and not by stupid incompetent\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▉          | 677/1250 [21:07<17:06,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: This movie is engaging from start to finish with excellent\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▉          | 678/1250 [21:09<17:25,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: I have to give this movie a 4 because of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▉          | 679/1250 [21:11<17:12,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: This is one you can watch over and over and\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▉          | 680/1250 [21:12<17:04,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Definitely not only for urban legend aficionados, Campfire Tales is\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  54%|███████████▉          | 681/1250 [21:14<16:51,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I must admit, I liked this movie, and didnt find\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████          | 682/1250 [21:16<16:54,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Am I the only person who thinks that the entire\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████          | 683/1250 [21:18<18:04,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 378])\n",
      "Prompt: This movie kicks ass, bar none. Bam and his crue\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████          | 684/1250 [21:20<17:37,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: In the twilight years of his career, Charles Bronson forged\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████          | 685/1250 [21:22<17:38,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: Simon Wests pg-13 thriller about a babysitter who gets disturbing\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████          | 686/1250 [21:24<17:37,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: The movie starts with a Spiderman spoof which is your\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████          | 687/1250 [21:25<17:15,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I have seen cheesy kung fu fight films. Living in\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████          | 688/1250 [21:27<17:04,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: I a huge fan of when it comes to Doctor\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████▏         | 689/1250 [21:29<17:09,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: The movie has taken a little flack for playing fast\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████▏         | 690/1250 [21:31<17:19,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: Even though this was set up to be a showcase\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████▏         | 691/1250 [21:33<17:25,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: A quick, funny coming-of-age matinÃ©e romp appealing to the underdog\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████▏         | 692/1250 [21:35<16:55,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: The decline series is amazing and director PS can't get\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  55%|████████████▏         | 693/1250 [21:36<16:46,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This is indeed a spectacularly bad film, but it is\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▏         | 694/1250 [21:38<16:42,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I am so happy not to live in an American\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▏         | 695/1250 [21:40<17:41,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 371])\n",
      "Prompt: Sometimes it's hard to be a pirate...............but by golly Miss\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▏         | 696/1250 [21:42<17:17,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: During the Clete Roberts preface, I was beginning to think\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▎         | 697/1250 [21:44<17:10,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: If you like to get a couple of fleeting glimpses\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▎         | 698/1250 [21:46<16:55,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I gave this a 2, and it only avoided a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▎         | 699/1250 [21:48<16:51,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: This movie treads on very familiar ground -- the confusion\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▎         | 700/1250 [21:49<16:59,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: Some people say the pace of this film is a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▎         | 701/1250 [21:51<16:51,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: This is possibly the worst thing I've ever seen on\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▎         | 702/1250 [21:53<16:44,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Shepitko is the wife of Russian filmmaker Elem Klimov, who\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▎         | 703/1250 [21:55<16:40,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: First off, I'm a huge Bronson fan, have been since\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▍         | 704/1250 [21:57<16:58,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 338])\n",
      "Prompt: This movie was beyond awful, it was a pimple on\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▍         | 705/1250 [21:59<16:42,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I was expecting this movie to be a stinker but\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  56%|████████████▍         | 706/1250 [22:00<16:27,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I recently visited the Magic Kingdom as an adult with\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▍         | 707/1250 [22:02<16:18,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I really enjoyed this movie. During the movie, I felt\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▍         | 708/1250 [22:04<16:09,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: This American masterpiece came as near perfection as popular art\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▍         | 709/1250 [22:06<16:45,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 347])\n",
      "Prompt: Three American lads are backpacking their way around Europe, challenging\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▍         | 710/1250 [22:08<17:35,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 375])\n",
      "Prompt: ***SPOILERS*** ***SPOILERS*** Well, seeing as I am a major H:LOTS\n",
      "Tokenized Prompt Shape: torch.Size([1, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▌         | 711/1250 [22:10<16:53,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: True, there are some goofs, for the one who wants\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▌         | 712/1250 [22:12<16:26,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: There is a reason Chairman of the Board got a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▌         | 713/1250 [22:13<16:10,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I rented Boogie Nights last week and I could tell\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▌         | 714/1250 [22:15<16:03,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Little did I know that when I signed up the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▌         | 715/1250 [22:17<15:52,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I've enjoyed watching Lost from the beginning and endured a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▌         | 716/1250 [22:19<15:49,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I really enjoyed this Minghella epic, thought not quite so\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▌         | 717/1250 [22:20<15:56,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Although this starts out promisingly, a woman in a car\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  57%|████████████▋         | 718/1250 [22:23<16:41,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 359])\n",
      "Prompt: Even before this film it is clear to see that\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▋         | 719/1250 [22:24<16:17,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: \"Shadows\" is often acclaimed as the film that was the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▋         | 720/1250 [22:26<16:05,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: i guess if they are not brother this film will\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▋         | 721/1250 [22:28<15:55,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This movie is silly and very short of being a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▋         | 722/1250 [22:30<15:47,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: \"The Bone Snatcher\" starts out extremely promising, with the introduction\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▋         | 723/1250 [22:31<15:33,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Archbishop Desmond Tutu, who is seldom a favorite of mine,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▋         | 724/1250 [22:33<15:25,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Though I saw this movie dubbed in French, so I'm\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▊         | 725/1250 [22:35<15:26,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I'm Mike Sedlak. I co-wrote the score for this movie.\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▊         | 726/1250 [22:37<15:38,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: I've seen some bad things in my time. A half\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▊         | 727/1250 [22:39<15:48,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: This film is an excellent teaching tool as a pre-study\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▊         | 728/1250 [22:40<15:41,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Hello all--for what it's worth, I'm in a doctoral program\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▊         | 729/1250 [22:42<15:32,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: A SOUND OF THUNDER. One of the greatest short stories\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▊         | 730/1250 [22:44<15:51,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: \"Cleo's Second Husband\" is an amateurish attempt at psychodrama with\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  58%|████████████▊         | 731/1250 [22:46<15:33,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: The thirty years that have passed since the making of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|████████████▉         | 732/1250 [22:48<15:33,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: Dead or Alive: Final, the movie that supposedly brings together\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|████████████▉         | 733/1250 [22:49<15:22,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: The worst movie ever?? HARDLY!!! This is one of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|████████████▉         | 734/1250 [22:51<15:17,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: One can only sit in utter amazement at this mess\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|████████████▉         | 735/1250 [22:53<15:09,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: By many accounts, Stu Ungar was not a very nice\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|████████████▉         | 736/1250 [22:55<15:27,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: Corey Haim plays a kid who teams up with a\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|████████████▉         | 737/1250 [22:56<15:17,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This is definitely one of the most scary and spell-binding\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|████████████▉         | 738/1250 [22:59<16:13,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 372])\n",
      "Prompt: I'm not a sports fan - but I love sports\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|█████████████         | 739/1250 [23:00<16:05,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: ... And boy is it soft <br /><br />I saw\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|█████████████         | 740/1250 [23:02<15:48,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: I love movies in this genre. Beautiful girls, toilet humor,\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|█████████████         | 741/1250 [23:04<15:33,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: What is it now-a-days that minority comedians feel its okay\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|█████████████         | 742/1250 [23:06<15:27,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: With the exception of the fine rack on Clara Evans...this\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  59%|█████████████         | 743/1250 [23:08<15:31,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: This, without any doubt, is the greatest spin off to\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████         | 744/1250 [23:10<15:28,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: Once again Woody Allen seems to be completely devoid of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████         | 745/1250 [23:11<15:18,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: When Jurassic Park first came out, it was revolutionary in\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▏        | 746/1250 [23:13<15:22,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: Some of the secondary actors try, really hard. And camera\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▏        | 747/1250 [23:15<15:14,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: i read the book before i saw the movie i\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▏        | 748/1250 [23:17<15:02,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I could not watch more than 10 minutes of this\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▏        | 749/1250 [23:19<15:04,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: \"Graduation Day\" is a result of the success of \"Friday\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▏        | 750/1250 [23:20<15:00,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Anderson's animation easily rivals that of Pixar and goes well\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▏        | 751/1250 [23:22<15:02,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: This film is like a dirge. UNTIL it gets to\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▏        | 752/1250 [23:24<14:57,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: This is one of the most unoriginal, cliche-ridden movies I\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▎        | 753/1250 [23:26<14:42,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I was at the world premier of this movie, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▎        | 754/1250 [23:27<14:41,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Most of the other posts beat this movie up, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▎        | 755/1250 [23:29<14:41,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Low-budget but memorable would-be shocker that instead emerges as theater\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  60%|█████████████▎        | 756/1250 [23:31<14:30,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Contain spoilers! These guys are total scam, they did the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▎        | 757/1250 [23:33<14:30,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: \"Joe\" is one of those movies where, although you think\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▎        | 758/1250 [23:34<14:31,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This focuses around the lives of four women, all good\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▎        | 759/1250 [23:36<14:32,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Written, produced and directed by Charlie Chaplin, this is the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▍        | 760/1250 [23:38<14:51,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: As if the world needed another Seagal movie. Add a\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▍        | 761/1250 [23:40<14:43,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: I watched this film on Telly the other night and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▍        | 762/1250 [23:42<14:58,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: The antiwar musical \"Hair\" is my number one cult-movie. I\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▍        | 763/1250 [23:44<15:16,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 345])\n",
      "Prompt: The college teacher Larry Donner (Billy Cristal) is a blocked\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▍        | 764/1250 [23:46<14:51,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: i just wanted to say that when i was young\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▍        | 765/1250 [23:47<14:40,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Yes, my summary just about tells it all.<br /><br />If\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▍        | 766/1250 [23:49<14:31,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: The mod squad gets started 'after' the formation of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▍        | 767/1250 [23:51<14:24,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Most of the criticism of \"Attack of Show\" is from\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  61%|█████████████▌        | 768/1250 [23:53<14:28,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: I just happened to stumble to this film and checked\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▌        | 769/1250 [23:54<14:23,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I can't believe I rarely ever see this title mentioned\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▌        | 770/1250 [23:56<14:32,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: If you watch this series you will get an interesting\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▌        | 771/1250 [23:58<14:54,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: There are so many positive reviews on Return to Me\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▌        | 772/1250 [24:00<14:58,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: I purchased this film on DVD for Â£4, but it\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▌        | 773/1250 [24:02<15:41,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 379])\n",
      "Prompt: Flash Gordon is, undoubtedly, the best of all American serials.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▌        | 774/1250 [24:04<15:07,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I love Ustinov's distinctive, literate narration. And the photography is\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▋        | 775/1250 [24:06<14:48,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: I just finished watching Dog Watch. I thought parts of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▋        | 776/1250 [24:08<14:59,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 338])\n",
      "Prompt: Director Kinji Fukasaku is perhaps best known, in his homeland\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▋        | 777/1250 [24:10<14:41,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I was greatly disappointed by the quality of this documentary.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▋        | 778/1250 [24:12<14:41,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: This is by far one the most boring movies I've\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▋        | 779/1250 [24:14<14:50,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Brodzki's creation is a great example of how NOT to\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▋        | 780/1250 [24:15<14:36,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: I gave Soul Plane the benefit of the doubt and\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  62%|█████████████▋        | 781/1250 [24:17<14:29,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: ***SPOILERS*** ***SPOILERS*** It's easy to see why the script for\n",
      "Tokenized Prompt Shape: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▊        | 782/1250 [24:19<14:05,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: WARNING!! This review may contain spoilers. The back of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▊        | 783/1250 [24:21<13:59,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: The Monkees \"Head\" is one of those peculiar phenomenons I've\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▊        | 784/1250 [24:22<13:56,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Supposedly, director William Shatner had in mind a much 'darker'\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▊        | 785/1250 [24:24<14:01,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: Mostly uninvolving biblical mumbo-jumbo that drags on for well over\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▊        | 786/1250 [24:26<14:02,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: Fantastically written, acted, and produced! Loved seeing this gleaming, talented\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▊        | 787/1250 [24:28<13:47,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Certainly this proves beyond a shadow of doubt that Patricia\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▊        | 788/1250 [24:30<13:44,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Have wanted to see this for a while: I never\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▉        | 789/1250 [24:31<13:44,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Almost missed it. While visiting friends in Philadelphia sometime in\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▉        | 790/1250 [24:33<13:56,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: This performance leaves you with no wishes. We saw it\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▉        | 791/1250 [24:35<13:53,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: I enjoy B movies. I think Bruce Campbell is a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▉        | 792/1250 [24:37<13:47,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I cant see how some people cant find this film\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  63%|█████████████▉        | 793/1250 [24:39<13:54,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: MONKEY is surely one of the best shows to have\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|█████████████▉        | 794/1250 [24:41<13:52,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: If at all possible, try to view all five of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|█████████████▉        | 795/1250 [24:43<14:38,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 374])\n",
      "Prompt: Dr. Paul Flanner (Richard Gere), a successful surgeon, has his\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████        | 796/1250 [24:44<14:08,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I just finished watching this film. For me, the most\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████        | 797/1250 [24:46<13:50,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: The silent film masterpiece Battleship Potemkin (1925) was commissioned by\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████        | 798/1250 [24:48<13:42,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: This movie was really funny even though it wasn't meant\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████        | 799/1250 [24:50<14:11,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 352])\n",
      "Prompt: Every time I see a film like this I get\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████        | 800/1250 [24:52<14:11,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: A lovely little film about the introduction of motion pictures\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████        | 801/1250 [24:54<14:03,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: This turned out to be more of a women's romance-soap-suspense\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████        | 802/1250 [24:56<13:57,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: When I first saw this film around 6 months ago,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████▏       | 803/1250 [24:57<13:47,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Giant Robot was the most popular Japanese TV serial ever\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████▏       | 804/1250 [24:59<13:37,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Shwaas may have a good story, but the director is\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████▏       | 805/1250 [25:01<13:44,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: Two city guys are driving through Hicksville USA when a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  64%|██████████████▏       | 806/1250 [25:03<13:39,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Jefferey dahmer was one sick guy. There's not much to\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▏       | 807/1250 [25:05<13:20,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: This is one of Peter Sellers' best movies. Why is\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▏       | 808/1250 [25:06<13:13,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Possibly John Cassavetes best film to date, and definitely his\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▏       | 809/1250 [25:08<13:02,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: This is a silly movie with much singing and dancing.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▎       | 810/1250 [25:10<13:13,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: I just finished watching Disappearances at AFI FEST 2006 with\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▎       | 811/1250 [25:12<13:11,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: I absolutely loved every minute of this film. Jack Black\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▎       | 812/1250 [25:14<13:06,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Positively ridiculous film.<br /><br />If Doris Roberts, Shirley Jones and\n",
      "Tokenized Prompt Shape: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▎       | 813/1250 [25:15<13:02,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: A lumberman finds a young cougar in need of help.\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▎       | 814/1250 [25:17<12:53,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Hard up, No proper jobs going down at the pit,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▎       | 815/1250 [25:19<12:52,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: To sum it all up, skip End of Days and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▎       | 816/1250 [25:21<12:51,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: When the word \"presents\" finds its way into a title,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▍       | 817/1250 [25:22<12:43,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Ah, Hitchcock! It's hard to find a bad Hitchcock movie\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  65%|██████████████▍       | 818/1250 [25:24<12:52,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: Wow, this movie really sucked down below the normal scale\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▍       | 819/1250 [25:26<13:07,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: After seeing Shootfighter 1, and the buckets of blood they\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▍       | 820/1250 [25:28<13:25,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 342])\n",
      "Prompt: Seen all 4 installments, this one is by far the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▍       | 821/1250 [25:30<13:09,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Went to the Preview Engagement of \"Grand Champion\" today (Dallas/Fort\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▍       | 822/1250 [25:32<13:27,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 349])\n",
      "Prompt: This film, like much of their music, is either underrated\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▍       | 823/1250 [25:34<13:08,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: As I read the script on-line, I thought \"Capote\" needed\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▌       | 824/1250 [25:35<12:56,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I love a cute heartfelt movie with a happy ending.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▌       | 825/1250 [25:37<12:55,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I remember ignoring the TV series when it first debuted\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▌       | 826/1250 [25:39<12:47,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Slow-moving ponderous movie with terrible acting on the whole -\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▌       | 827/1250 [25:41<13:00,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 333])\n",
      "Prompt: Okay wait let me get this street, there are actually\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▌       | 828/1250 [25:43<12:47,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: It is important to realise that Eisenstein was a committed\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▌       | 829/1250 [25:45<12:36,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: The best British Comedy Film ever! For years English comedy\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▌       | 830/1250 [25:47<12:58,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 342])\n",
      "Prompt: 10/10<br /><br />PLOT DISCUSSION<br /><br />This is one of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  66%|██████████████▋       | 831/1250 [25:48<12:39,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: This movie is bad. Really bad. So bad it made\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▋       | 832/1250 [25:50<12:40,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Zeppelin is my favorite band, so when I heard that\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▋       | 833/1250 [25:52<12:57,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: Terrible terrible movie for Television. Once again Lifetime brings us\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▋       | 834/1250 [25:54<12:38,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: \"Hit and Run\" is a shattering story starring the always\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▋       | 835/1250 [25:56<12:40,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: I caught this a few times on TV in the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▋       | 836/1250 [25:57<12:44,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: I turned over to this film in the middle of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▋       | 837/1250 [25:59<12:30,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: It's not plot driven, OK; it's not a character study,\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▋       | 838/1250 [26:01<12:19,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I completely disagree with the previous reviewer: this movie has\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▊       | 839/1250 [26:03<12:14,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Colonel Chabert is one of the best adaptations from novel\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▊       | 840/1250 [26:05<12:08,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: There have been very few great comedy films in the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▊       | 841/1250 [26:06<12:31,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 339])\n",
      "Prompt: How can this movie be described? Oh yeah I've got\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▊       | 842/1250 [26:08<12:17,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This conglomeration fails so miserably on every level that it\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  67%|██████████████▊       | 843/1250 [26:10<12:25,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: Recap: Simon leads a little team of special agents that\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▊       | 844/1250 [26:12<12:11,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: George C. Scott gives his finest and funniest with wonderful\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▊       | 845/1250 [26:14<12:24,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 333])\n",
      "Prompt: As someone already said the Living Dead Dolls were cute\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▉       | 846/1250 [26:16<12:27,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: Not too bad entry in the series, heavily ladled with\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▉       | 847/1250 [26:17<12:12,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I saw this film on TV in the UK some\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▉       | 848/1250 [26:19<12:40,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 354])\n",
      "Prompt: Two movies: \"the fifth element\", \"armageddon\". The same subject: to\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▉       | 849/1250 [26:21<12:19,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: When my parents rented this movie, I was expecting a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▉       | 850/1250 [26:24<13:20,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 404])\n",
      "Prompt: I got a chance to see this movie at an\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▉       | 851/1250 [26:25<12:54,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: This is one peace of art! If you like comedy\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|██████████████▉       | 852/1250 [26:27<12:56,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 339])\n",
      "Prompt: Very odd, this seems like a very average movie to\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|███████████████       | 853/1250 [26:29<12:29,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: After learning that her sister Susan is contemplating divorce, Kate\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|███████████████       | 854/1250 [26:31<12:30,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: If I'm to like a movie, I need to care\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|███████████████       | 855/1250 [26:33<12:28,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: The NYT review says that Sigourney Weaver's character is taut\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  68%|███████████████       | 856/1250 [26:35<12:08,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I agree with msinabottle; this is a great movie. Here\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████       | 857/1250 [26:36<11:51,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This is a very strange product from Hollywood. Apparently it\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████       | 858/1250 [26:38<11:42,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: The word impossible has led many to select a particular\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████       | 859/1250 [26:40<11:47,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: This movie is one of my all time favorites. I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▏      | 860/1250 [26:42<11:53,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: Uncle Frank is everyone's uncle. This documentary covered all aspects\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▏      | 861/1250 [26:44<11:54,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: I found the movie to be very light and enjoyable.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▏      | 862/1250 [26:45<11:52,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: When I went to see this documentary on Communist bloc\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▏      | 863/1250 [26:47<12:04,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: Someone else called this film a \"fable-horror\" movie, and I\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▏      | 864/1250 [26:49<11:43,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This is another of those films I can remember from\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▏      | 865/1250 [26:51<12:01,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 336])\n",
      "Prompt: Jack, Sawyer and Sayid swim to the boat and find\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▏      | 866/1250 [26:53<11:47,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I have rented this film out about 6 times! it\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▎      | 867/1250 [26:55<11:38,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Excerpt from TV GUIDE:<br /><br />This week on THE LOVE\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  69%|███████████████▎      | 868/1250 [26:57<11:38,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: just watched this \"film\" and it actually made me want\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▎      | 869/1250 [26:59<13:30,  2.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 481])\n",
      "Prompt: To think this film was made the year I was\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▎      | 870/1250 [27:01<12:46,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: After sitting through this god-awful 82-minute excuse of a film,\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▎      | 871/1250 [27:03<12:59,  2.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 374])\n",
      "Prompt: Of all the movies in the history of movies I\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▎      | 872/1250 [27:05<12:31,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: Some people say this show was good in it's early\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▎      | 873/1250 [27:07<12:21,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: I just got back from the GLBT Film Festival at\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▍      | 874/1250 [27:09<12:00,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: I really enjoy this particular production of \"The Mikado.\" The\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▍      | 875/1250 [27:11<11:58,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: The film has no connection with the real life in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▍      | 876/1250 [27:13<11:44,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: Very lovely love story between Brenda Blethyn and Alfred Molina.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▍      | 877/1250 [27:14<11:32,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: this movie is so bad and Hellraiser part 1 to\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▍      | 878/1250 [27:16<11:21,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Wow. Not because of the 3-D imagery, which at times\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▍      | 879/1250 [27:18<11:19,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: Black Snake Moan is uproarious. It is over-flowingly rich, fantastically\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▍      | 880/1250 [27:20<11:19,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: A few years ago I saw The Scent of Green\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  70%|███████████████▌      | 881/1250 [27:22<11:11,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: This ingenious and innovate comedy packs many moments priceless and\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▌      | 882/1250 [27:23<11:03,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: How can anyone even begin to like this film is\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▌      | 883/1250 [27:25<11:04,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: Miranda Cosgrove is known for her debut in \"School of\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▌      | 884/1250 [27:27<10:59,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I remember seeing this film in my late teens or\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▌      | 885/1250 [27:29<10:51,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: The movie invites comparisons to Shakespeare. The Mandarin is beautifully\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▌      | 886/1250 [27:31<10:54,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I normally don't comment on movies on IMDB, but in\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▌      | 887/1250 [27:32<10:48,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This film is an insult to the play upon which\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▋      | 888/1250 [27:34<10:56,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: \"I haven't laughed this hard since granny got caught in\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▋      | 889/1250 [27:36<10:56,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This one is a cut above the usual softcore T&A,\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▋      | 890/1250 [27:38<11:08,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: The Romanian cinema is little known out of Romania. No\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▋      | 891/1250 [27:40<10:56,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I've seen a few movies in my time, but this\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▋      | 892/1250 [27:42<10:57,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Haggard: The Movie is the real life story of Ryan\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  71%|███████████████▋      | 893/1250 [27:43<10:51,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: this is the worst film I've seen in a long\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▋      | 894/1250 [27:45<11:09,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 346])\n",
      "Prompt: I only came here to check Terror Hospital for an\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▊      | 895/1250 [27:47<11:21,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 344])\n",
      "Prompt: <br /><br />my favorite science fiction, incredible ride through mistrust\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▊      | 896/1250 [27:49<11:10,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: In these modern times (as subject known quite well to\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▊      | 897/1250 [27:51<10:53,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Ruthless evil warlord Samanosuke (superbly played to the hateful hilt\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▊      | 898/1250 [27:53<11:03,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 345])\n",
      "Prompt: Out to Sea was a great movie. I expected comedy\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▊      | 899/1250 [27:55<10:57,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Look, this is a low budget horror film that suffers\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▊      | 900/1250 [27:57<10:52,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: Watched this on KQED, with Frank Baxter commenting, as I\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▊      | 901/1250 [27:59<11:07,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 351])\n",
      "Prompt: This is one of the many Techno-phobic movies that sprouted\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▉      | 902/1250 [28:01<11:17,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 352])\n",
      "Prompt: I must be getting old because I was riveted to\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▉      | 903/1250 [28:03<11:06,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: Recently released on British DVD, this is a good movie\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▉      | 904/1250 [28:04<11:04,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: It's awful.<br /><br />Pretty succinct review I know, but it\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▉      | 905/1250 [28:07<11:19,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 363])\n",
      "Prompt: An untidy man, known as Bill, lives in a small\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  72%|███████████████▉      | 906/1250 [28:08<10:58,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: This second full-length Lone Ranger feature doesn't measure up to\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|███████████████▉      | 907/1250 [28:10<10:45,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: It's now 2005 and 15+ years since this cartoon first\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|███████████████▉      | 908/1250 [28:12<10:33,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: This is probably one of the worst movies I have\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|███████████████▉      | 909/1250 [28:14<10:26,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: This is really the only chance to see the magic\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████      | 910/1250 [28:16<10:22,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: How to round up every possible clichÃ© and stereotype existing\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████      | 911/1250 [28:17<10:23,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: this western/musical/comedy is not one of the best of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████      | 912/1250 [28:19<10:31,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: Propaganda pro-American war effort film that came out in 1942\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████      | 913/1250 [28:21<10:31,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: So after the initial disappointment of the first Final Fantasy\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████      | 914/1250 [28:23<10:36,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: <br /><br />Very slow, plodding movie with a confusing story\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████      | 915/1250 [28:25<10:33,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: This DVD usually sells for around $20. I wouldn't pay\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████      | 916/1250 [28:27<10:20,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: When I first saw this DVD in a bargain bin\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████▏     | 917/1250 [28:29<10:17,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Scientist Carl Lehman (well played by David McIlwraith) gets blown\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  73%|████████████████▏     | 918/1250 [28:31<10:23,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 338])\n",
      "Prompt: 1st watched 3/17/2002 - 2 out of 10(Dir-Mario Pinzauti): Silly,\n",
      "Tokenized Prompt Shape: torch.Size([1, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▏     | 919/1250 [28:32<10:00,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: ...now please move on because that's getting on my nerves.<br\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▏     | 920/1250 [28:34<09:49,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: My jaw fell so many times watching this flick, I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▏     | 921/1250 [28:36<09:50,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: Seriously. If this had been the first Shack movie, it\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▏     | 922/1250 [28:38<09:55,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: This movie felt so real. I actually felt all of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▏     | 923/1250 [28:40<10:07,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 338])\n",
      "Prompt: I'd heard this Japanese flick is edgy, creatively interesting, a\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▎     | 924/1250 [28:41<10:02,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Awful in a whole new way, ANYTHING BUT LOVE probably\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▎     | 925/1250 [28:43<09:51,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Yeah, what did I expect? I thought this would be\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▎     | 926/1250 [28:45<09:42,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: This movie is beautiful in many ways: the plot, the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▎     | 927/1250 [28:47<09:35,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: The director of this movie is a famous french TV\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▎     | 928/1250 [28:49<09:39,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: A lot of people give this movie a lot of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▎     | 929/1250 [28:50<09:34,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I know we shouldn't expect much from a low-budget indie\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▎     | 930/1250 [28:52<09:46,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: Louis Khan was one of the most influential architects of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  74%|████████████████▍     | 931/1250 [28:54<09:43,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: I like the shepherd! Sure the acting wasn't good but\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▍     | 932/1250 [28:56<09:55,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 342])\n",
      "Prompt: The aftermath of World War Two almost resulted in the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▍     | 933/1250 [28:58<09:48,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: So many literary adaptations are disappointments. There are many reasons\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▍     | 934/1250 [29:00<09:40,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: A blatant rip-off of \"Air Bud\", this movie is REALLY\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▍     | 935/1250 [29:01<09:37,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: An interesting look at the immigrant experience, told as a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▍     | 936/1250 [29:03<09:27,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: If there's one thing I want to distinguish myself from\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▍     | 937/1250 [29:05<09:27,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: The concept of this movie is unique, however its execution\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▌     | 938/1250 [29:07<09:23,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: The reason I am reviewing this is that the previous\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▌     | 939/1250 [29:09<09:31,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: Coen Brothers-wannabe from writer-director Paul Chart relies far too much\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▌     | 940/1250 [29:10<09:19,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: There are a number of movies that my high school\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▌     | 941/1250 [29:12<09:20,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: If this is classed as 'real life' of London, then\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▌     | 942/1250 [29:14<09:23,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: can someone please help me i missed the last view\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  75%|████████████████▌     | 943/1250 [29:16<09:20,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: Sacchi is the best Bogart impersonator ever... dry and droll\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▌     | 944/1250 [29:18<09:20,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: First I am a teenager. OK, and I have to\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▋     | 945/1250 [29:20<09:14,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: This was a pretty good movie that was overall done\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▋     | 946/1250 [29:21<09:18,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: I don't think it's necessary to outline the plot for\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▋     | 947/1250 [29:23<09:12,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: it's unfortunate that many of the other detractors of this\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▋     | 948/1250 [29:25<09:17,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: This is a very realistic movie. It's the most realistic\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▋     | 949/1250 [29:27<09:10,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: It starts out looking like it may be going somewhere,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▋     | 950/1250 [29:29<09:18,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: This is indeed one of the weakest films based on\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▋     | 951/1250 [29:31<09:15,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: This isn't far away from the trash that Bollywood normally\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▊     | 952/1250 [29:33<09:11,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: Even with it's low budget this movie could have been\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▊     | 953/1250 [29:34<08:59,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Made it through the first half an hour and deserved\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▊     | 954/1250 [29:36<08:58,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: This hugely entertaining short is considered one of the best\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▊     | 955/1250 [29:38<08:50,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Fame is one of the best movies I've seen about\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  76%|████████████████▊     | 956/1250 [29:40<08:47,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: I am a fan of the paranormal and I love\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▊     | 957/1250 [29:41<08:43,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: I don't cry easily over movies, but I have to\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▊     | 958/1250 [29:43<08:46,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Best thing I can say about this porno-horror film is:\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▉     | 959/1250 [29:45<08:46,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: I am still waiting for years a new DVD issue\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▉     | 960/1250 [29:47<08:40,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Despite having an absolutely horrid script (more about that later),\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▉     | 961/1250 [29:49<08:36,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Hopper has never been worse as if he felt as\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▉     | 962/1250 [29:50<08:31,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: A talented high school graduating senior with a bad attitude\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▉     | 963/1250 [29:52<08:32,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: This movie was ridiculous from the start. Let me save\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▉     | 964/1250 [29:54<08:31,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: What a disappointment! I've enjoyed the Jon Cleary books about\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|████████████████▉     | 965/1250 [29:56<08:24,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I have a little hobby of finding really cool pics\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|█████████████████     | 966/1250 [29:58<08:28,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: When one thinks of Soviet cinema, the propaganda masterpieces of\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|█████████████████     | 967/1250 [30:00<08:40,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 336])\n",
      "Prompt: I saw it last night and I was laughing out\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  77%|█████████████████     | 968/1250 [30:01<08:35,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: One of the best movies ever, the idea of a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████     | 969/1250 [30:03<08:38,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: For a really wonderful movie, you could also try seeing\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████     | 970/1250 [30:05<08:32,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: Watching the first few moments, you realize it's going to\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████     | 971/1250 [30:07<08:23,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I hate to comment on something I didn't finish, but\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████     | 972/1250 [30:09<08:20,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: this is awesome!!! there is no partnership quite like Errol,\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████     | 973/1250 [30:10<08:14,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I give \"Flashdance\" a lowest rating of 1 out of\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████▏    | 974/1250 [30:12<08:21,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: I was very curious about Anatomy (aka Anatomie) and if\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████▏    | 975/1250 [30:14<08:19,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Well, Killshot is not awful, but it comes close. Production\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████▏    | 976/1250 [30:16<08:14,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: My brother was working at a movie theater when I\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████▏    | 977/1250 [30:18<08:25,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 338])\n",
      "Prompt: This was so much better than i expected, the film\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████▏    | 978/1250 [30:20<08:31,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: Pitch Black is a survival story. It's about how to\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████▏    | 979/1250 [30:22<08:35,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: The Ali G character works brilliantly within the confines of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████▏    | 980/1250 [30:24<08:35,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: I am not familiar with the producer's other works, but\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  78%|█████████████████▎    | 981/1250 [30:25<08:23,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Poor Jane Austen. This dog of a production does NOT\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▎    | 982/1250 [30:27<08:22,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: My curiosity and patience to finally see this controversial film,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▎    | 983/1250 [30:30<09:43,  2.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 493])\n",
      "Prompt: People call a 976 \"party line\" to talk dirty to\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▎    | 984/1250 [30:33<10:07,  2.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 431])\n",
      "Prompt: Here we have a miniseries, which revels in in its\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▎    | 985/1250 [30:34<09:24,  2.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I enjoy science-fiction just as much as the next manÂ\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▎    | 986/1250 [30:36<08:53,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Dirty Dancing one of my MOST favorite movies. I've only\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▎    | 987/1250 [30:38<08:37,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: \"Snowball Express\" from the Disney Studios isn't quite as dated\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▍    | 988/1250 [30:40<08:32,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 336])\n",
      "Prompt: I was lucky enough recently to see Ingrid Bergman's name\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▍    | 989/1250 [30:42<08:12,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: The story, as I understand, is \"based on real events.\"\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▍    | 990/1250 [30:43<08:00,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: \"San Francisco, Oh you marvelously desolated town, Thank You, God,\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▍    | 991/1250 [30:45<07:55,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: Dodgy plot, dodgy script, dodgy almost everything in fact. The\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▍    | 992/1250 [30:47<07:46,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Alright, how someone can actually think this movie is awesome,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  79%|█████████████████▍    | 993/1250 [30:49<07:51,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: I have recently found this film on one of my\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|█████████████████▍    | 994/1250 [30:51<07:46,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Virtual Sexuality proves that Britain can produce romantic comedies as\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|█████████████████▌    | 995/1250 [30:53<07:46,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 320])\n",
      "Prompt: As the metaphoric flies fled this steaming watery stool of\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|█████████████████▌    | 996/1250 [30:54<07:44,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: My friend made me sit down and watch this film.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|█████████████████▌    | 997/1250 [30:56<07:37,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: The most worthless film of the decade. The responsible parties\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|█████████████████▌    | 998/1250 [30:58<07:48,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: Okay, I just had to sound off on this one...\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|█████████████████▌    | 999/1250 [31:00<07:37,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: The movie contains a very short scene of Deneuve in\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|████████████████▊    | 1000/1250 [31:02<07:32,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This is definitely a girl movie. My husband found it\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|████████████████▊    | 1001/1250 [31:03<07:30,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: I haven't read the source, Richard Brooks' novel \"The Brick\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|████████████████▊    | 1002/1250 [31:05<07:28,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: The Andrew Davies adaptation of the Sarah Waters' novel was\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|████████████████▊    | 1003/1250 [31:07<07:37,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: Dirty War is absolutely one of the best political, government,\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|████████████████▊    | 1004/1250 [31:09<07:30,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This film really used its locations well with some amazing\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|████████████████▉    | 1005/1250 [31:11<07:23,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Honestly, at first, I watched this movie because of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  80%|████████████████▉    | 1006/1250 [31:12<07:16,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I watched this film with high expectations but was somewhat\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|████████████████▉    | 1007/1250 [31:15<07:32,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 349])\n",
      "Prompt: Almost 20 years before Frank Marshall brought tears to your\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|████████████████▉    | 1008/1250 [31:16<07:24,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: \"Pixote\" is the one of most powerful, shocking, and moving\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|████████████████▉    | 1009/1250 [31:18<07:21,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: Being a Harrison Ford fan I am probably being kind.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|████████████████▉    | 1010/1250 [31:20<07:12,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: In Everything Is Illuminated, Elijah Wood plays Jonathan Foer, a\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|████████████████▉    | 1011/1250 [31:22<07:07,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: This movie is sort of similar to \"Better Off Dead\"\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|█████████████████    | 1012/1250 [31:23<07:04,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Ladies and gentlemen: the show begins with this documentary film.\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|█████████████████    | 1013/1250 [31:26<07:39,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 396])\n",
      "Prompt: TV director uses astral projection to kill people taking the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|█████████████████    | 1014/1250 [31:28<07:39,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: Laura Fraser creates her ideal man on a virtual reality\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|█████████████████    | 1015/1250 [31:29<07:30,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: The people who bash this movie were looking for it\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|█████████████████    | 1016/1250 [31:31<07:25,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 323])\n",
      "Prompt: Ever wonder where that episode, \"Tuttle,\" came from in the\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|█████████████████    | 1017/1250 [31:33<07:13,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Thomas Edison had no other reason to make this film\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  81%|█████████████████    | 1018/1250 [31:35<07:05,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: LIFEFORCE is an extremely schizophrenic movie, based on Colin Wilson`s\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████    | 1019/1250 [31:37<06:59,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Along with having minor flaws to it, this film is\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▏   | 1020/1250 [31:38<06:54,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: The show was amazing and very professional. Madonna is a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▏   | 1021/1250 [31:40<07:03,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 337])\n",
      "Prompt: Dooley and his canine partner, Jerry Lee are together again\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▏   | 1022/1250 [31:43<07:36,  2.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 405])\n",
      "Prompt: The video box for 'Joyride' says \"starring second generation superstars\",\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▏   | 1023/1250 [31:44<07:14,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This Is one of my favourite westerns. What a cast!\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▏   | 1024/1250 [31:46<07:06,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Let me clarify that. This is not a \"good movie\",\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▏   | 1025/1250 [31:48<06:59,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I was so offended by this film that I had\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▏   | 1026/1250 [31:50<06:59,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: A fun romp...a lot of good twists and turns! (and\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▎   | 1027/1250 [31:52<07:05,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 345])\n",
      "Prompt: There is no plot. There are no central characters. There\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▎   | 1028/1250 [31:54<06:54,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Audrey, I know you truly cherish your husband Ted's memory\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▎   | 1029/1250 [31:56<06:52,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: I thought I had seen this film before as the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▎   | 1030/1250 [31:57<06:44,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This movie is juxtaposition of various super bad tough guy\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  82%|█████████████████▎   | 1031/1250 [31:59<06:43,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: This movie is a real shame, not just for the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▎   | 1032/1250 [32:01<06:41,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Let me waste a moment of your time to explain\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▎   | 1033/1250 [32:03<06:38,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: \"The Love Letter\" is a somewhat pleasant, very very low-key\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▎   | 1034/1250 [32:05<06:29,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Not sure I've ever seen a black comedy from Denamark\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▍   | 1035/1250 [32:07<06:44,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 337])\n",
      "Prompt: The only good thing about this movie is, that I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▍   | 1036/1250 [32:09<06:45,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: This wretched psychodrama uses every shabby device in the book\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▍   | 1037/1250 [32:10<06:37,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Blue ribbon banners, stars and stripes forever, decorated generals, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▍   | 1038/1250 [32:12<06:27,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Oh my. Started out with such great potential - a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▍   | 1039/1250 [32:14<06:33,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: Contains spoilers I had it recorded a while ago when\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▍   | 1040/1250 [32:16<06:35,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: This critique tells the story of 4 little friends who\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▍   | 1041/1250 [32:18<06:32,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Shame on Fox for dumping this movie. It was a\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▌   | 1042/1250 [32:20<06:33,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 333])\n",
      "Prompt: Keep away from this one. The worst thing is the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  83%|█████████████████▌   | 1043/1250 [32:22<06:26,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: I saw this movie over 5 years ago and the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▌   | 1044/1250 [32:24<06:25,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: Story about a widowed father (Claude Rains) bringing up his\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▌   | 1045/1250 [32:25<06:26,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 335])\n",
      "Prompt: Very strange screenplay by Cameron Crowe (following on the heels\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▌   | 1046/1250 [32:27<06:31,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 346])\n",
      "Prompt: The plot of the movie is pretty simple : a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▌   | 1047/1250 [32:30<06:59,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 411])\n",
      "Prompt: Really, REALLY... What pleases audience (american one!) in this so\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▌   | 1048/1250 [32:32<06:36,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This film was a Mexican made horror film from the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▌   | 1049/1250 [32:33<06:26,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: James Aaron, a chubby actor living in Chicago, is a\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▋   | 1050/1250 [32:36<06:36,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 368])\n",
      "Prompt: I wasn't planning on watching wasted when I saw the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▋   | 1051/1250 [32:37<06:30,  1.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: Child death and horror movies will always remain a sensitive\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▋   | 1052/1250 [32:39<06:34,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 345])\n",
      "Prompt: It's as if the editor and screenwriter only had 40\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▋   | 1053/1250 [32:41<06:27,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: A very weird, psychedelic, esoteric, (and did I say weird?\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▋   | 1054/1250 [32:43<06:13,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: While I was watching this movie I never thought I'd\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▋   | 1055/1250 [32:45<06:04,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: 2001 is one of those movies where, if you don't\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  84%|█████████████████▋   | 1056/1250 [32:47<06:05,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: I didn't like watching DS9 compared to other Star Treks\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▊   | 1057/1250 [32:49<06:04,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: While some of the things in Haggard are dumb and\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▊   | 1058/1250 [32:51<06:01,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: Even with the low standards of a dedicated horror fan,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▊   | 1059/1250 [32:53<06:12,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 360])\n",
      "Prompt: Apparently, in the eyes of some - there aren't enough\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▊   | 1060/1250 [32:55<06:01,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: <br /><br />Summary: Not worth the film<br /><br />As an\n",
      "Tokenized Prompt Shape: torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▊   | 1061/1250 [32:56<05:47,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I have always had this morbid curiosity when it comes\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▊   | 1062/1250 [32:58<05:50,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: Well this movie certainly was in keeping with the current\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▊   | 1063/1250 [33:00<05:42,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: To say I was disappointed is an understatement. An amateur\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▉   | 1064/1250 [33:02<05:38,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: I found it almost impossible to empathize with Ricci's character\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▉   | 1065/1250 [33:03<05:32,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: \"Christmas in Connecticut\" is an absolute gem, and a must-see\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▉   | 1066/1250 [33:05<05:31,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: I suppose that to say this is an all-out terrible\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▉   | 1067/1250 [33:07<05:31,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: I picked out this DVD out of the cheepo bin\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  85%|█████████████████▉   | 1068/1250 [33:09<05:32,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: I agree with Andy, this is a good movie. Kevin\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|█████████████████▉   | 1069/1250 [33:11<05:30,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Better than it has any right to be, this movie\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|█████████████████▉   | 1070/1250 [33:13<05:26,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Thankfully I watched this film alone, enabling me to fast-forward\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|█████████████████▉   | 1071/1250 [33:14<05:20,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Alleged \"scream queen\" Debbie Rochon and her group of frontier\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████   | 1072/1250 [33:16<05:17,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: Back in 1994 the Power Rangers had become a huge\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████   | 1073/1250 [33:18<05:18,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: I was blubbing like an idiot during the last ten\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████   | 1074/1250 [33:20<05:20,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: I loved this movie. To be very fair, the movie\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████   | 1075/1250 [33:22<05:18,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: If a movie can't hold your interest in the first\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████   | 1076/1250 [33:23<05:14,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: When a movie's claim to fame is that Martin Sheen's\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████   | 1077/1250 [33:25<05:10,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: IÂ´m from germany so please excuse my style of writing.\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████   | 1078/1250 [33:27<05:13,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: A touching love story reminiscent of ÂIn the Mood for\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████▏  | 1079/1250 [33:29<05:08,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I was looking forward to watching this film and was\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████▏  | 1080/1250 [33:31<05:07,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: This movie is terrible. It's about some no brain surfin\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  86%|██████████████████▏  | 1081/1250 [33:32<05:02,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: \"Western Union\" is something of a forgotten classic western! Perhaps\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▏  | 1082/1250 [33:34<04:58,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I saw it tonight and fell asleep in the movie.<br\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▏  | 1083/1250 [33:36<04:57,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: First of all..I've seen better acting and more realistic makeup\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▏  | 1084/1250 [33:38<04:54,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: If you tried to make a bad film, you could\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▏  | 1085/1250 [33:39<04:56,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 321])\n",
      "Prompt: pretty disappointing. i was expecting more of a horror/thriller --\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▏  | 1086/1250 [33:41<04:51,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: THE EXPERT, starring Jeff Speakman, is the definition of DULL!!!<br\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▎  | 1087/1250 [33:43<04:47,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Contains Spoiler The movie is a good action/comedy but i\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▎  | 1088/1250 [33:45<04:53,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 334])\n",
      "Prompt: While escaping from a heist of a bank, the outlaw\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▎  | 1089/1250 [33:47<04:52,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: This may be the most tension-filled movie I have ever\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▎  | 1090/1250 [33:49<04:50,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: <br /><br />Very good 1970s movie about mob operations in\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▎  | 1091/1250 [33:50<04:44,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I normally finish every movie or book I start, even\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▎  | 1092/1250 [33:52<04:50,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 337])\n",
      "Prompt: Closet land is not at happy movie. Neither is it\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  87%|██████████████████▎  | 1093/1250 [33:54<04:45,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Completely overlooking the whole movie adaptation of a video game,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▍  | 1094/1250 [33:56<04:39,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: It resembles so much to movies like PULP FICTION or\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▍  | 1095/1250 [33:58<04:41,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: as a fan of robocop, i always loved this movie.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▍  | 1096/1250 [33:59<04:35,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: <br /><br />After the wit and liveliness of Highway 61\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▍  | 1097/1250 [34:01<04:34,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I decided to watch this movie because I'd not seen\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▍  | 1098/1250 [34:03<04:34,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: The film was apparently spawned from an idea one of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▍  | 1099/1250 [34:05<04:31,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Lucille Ball's version of \"Mame\" in my opinion is one\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▍  | 1100/1250 [34:06<04:26,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Ben, (Rupert Grint), is a deeply unhappy adolescent, the son\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▍  | 1101/1250 [34:08<04:33,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 343])\n",
      "Prompt: We really don't know where to begin when talking about\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▌  | 1102/1250 [34:10<04:28,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: with this film being directed by Roger Avery and Quentin\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▌  | 1103/1250 [34:12<04:26,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: It is so bad, I can not tear myself away.\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▌  | 1104/1250 [34:14<04:28,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: If you can make it through this flick without laughing\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▌  | 1105/1250 [34:16<04:26,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: I've never seen the original movie others have commented on,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  88%|██████████████████▌  | 1106/1250 [34:18<04:23,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: I liked all the Lilo and Stitch movies. The TV\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▌  | 1107/1250 [34:19<04:22,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: The comments already left for this show are way more\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▌  | 1108/1250 [34:21<04:20,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: Don't waste your time or money on going to see\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▋  | 1109/1250 [34:23<04:14,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: \"Beyond the Clouds\" is an over-the-top artsy group of four\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▋  | 1110/1250 [34:25<04:14,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: This was a letdown in many ways. The location filming\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▋  | 1111/1250 [34:27<04:08,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: For all its many flaws, I'm inclined to be charitable\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▋  | 1112/1250 [34:28<04:09,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: I just spent the last half an hour reading through\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▋  | 1113/1250 [34:30<04:11,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: I'm glad I never watched this show when it came\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▋  | 1114/1250 [34:32<04:20,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 360])\n",
      "Prompt: As a serious marathoner, I was seriously disappointed in this\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▋  | 1115/1250 [34:34<04:13,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: A low-rent, cheaply made police thriller that's kept bearable by\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▋  | 1116/1250 [34:36<04:08,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: THE ENGLISH PATIENT not only has it all (doomed romance,\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▊  | 1117/1250 [34:38<04:03,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: When I was young, I was a big fan of\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  89%|██████████████████▊  | 1118/1250 [34:40<04:02,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: I just saw \"Everything is Illuminated\" at the Telluride Film\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▊  | 1119/1250 [34:41<04:01,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Flipper is a nice heartwarming movie for whole family. It's\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▊  | 1120/1250 [34:43<04:00,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: As I was flipping through the channel I came to\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▊  | 1121/1250 [34:45<03:58,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Human Traffic is purely a `been there, done that' experience\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▊  | 1122/1250 [34:47<03:53,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Out of any category, this is one demented and over\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▊  | 1123/1250 [34:49<03:52,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: This is an excellent movie that tackles the issue of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▉  | 1124/1250 [34:51<03:48,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: There is not much to add to what others have\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▉  | 1125/1250 [34:52<03:45,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: The first time I saw this film I was a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▉  | 1126/1250 [34:54<03:43,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: As a Long Island independent film maker myself, and having\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▉  | 1127/1250 [34:56<03:39,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Probably the biggest thing about Wild Rebels that hurts it\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▉  | 1128/1250 [34:58<03:37,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: \"Family Guy\" is probably the most ballsy sitcom ever produced.\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▉  | 1129/1250 [34:59<03:36,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: There was nothing else on tv yesterday afternoon, so I\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|██████████████████▉  | 1130/1250 [35:01<03:36,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: Okul is the first of its kind in Turkish cinema,\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  90%|███████████████████  | 1131/1250 [35:03<03:32,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: This film promised a lot, so many beautiful and well\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████  | 1132/1250 [35:05<03:31,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: This should have rocked. VH1 moved away from the traditional\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████  | 1133/1250 [35:07<03:30,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: I watched this movie to see the direction one of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████  | 1134/1250 [35:08<03:27,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: \"Dead Man Walking\" is a piece of incredible filmmaking. All\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████  | 1135/1250 [35:10<03:33,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 349])\n",
      "Prompt: Believe it or not, the Mona Lisa actually got stolen\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████  | 1136/1250 [35:12<03:29,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Even though this movie starts off with the usual: something\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████  | 1137/1250 [35:14<03:30,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: I think that Vanessa Marcil is the best actor in\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████  | 1138/1250 [35:16<03:33,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 342])\n",
      "Prompt: I absolutely positively can't believe my fellow IMDb reviewers. All\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████▏ | 1139/1250 [35:18<03:26,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Right there. Good, entertaining and accurate era-feel to most scenes.\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████▏ | 1140/1250 [35:20<03:20,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This movie was recommended to me by several people, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████▏ | 1141/1250 [35:21<03:18,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: I got to watch this movie in my french class\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████▏ | 1142/1250 [35:23<03:15,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: A terminally dull mystery-thriller, which may sound pretty sound theoretically\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  91%|███████████████████▏ | 1143/1250 [35:25<03:11,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: Just Before Dawn is one of those really good slashers\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▏ | 1144/1250 [35:27<03:14,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 337])\n",
      "Prompt: This looks decidedly like \"the amateur\" hour. How this piece\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▏ | 1145/1250 [35:29<03:11,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: \"The Dead\" truly is a work of art. Clearly, John\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▎ | 1146/1250 [35:31<03:11,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 330])\n",
      "Prompt: Corey Haim is never going to be known as one\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▎ | 1147/1250 [35:32<03:07,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This was one of the best half-hour horror/suspense/fantasy shows of\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▎ | 1148/1250 [35:34<03:01,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: This is possibly one of the worst movies I have\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▎ | 1149/1250 [35:36<03:06,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 342])\n",
      "Prompt: I happened to see a promo for this movie on\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▎ | 1150/1250 [35:38<03:04,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Hey, I know Angel isn't the kind of show that\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▎ | 1151/1250 [35:40<03:07,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 343])\n",
      "Prompt: A great performance by Clint Eastwood and particularly John Malkovich\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▎ | 1152/1250 [35:42<03:01,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Despite what its critics ensue, I enjoyed immensely for precisely\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▎ | 1153/1250 [35:44<02:58,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: I realize a period piece is expensive to make, and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▍ | 1154/1250 [35:46<03:08,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 389])\n",
      "Prompt: Yeah, I know my title sucks. I couldn't think of\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▍ | 1155/1250 [35:48<03:03,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: Soul Calibur is more solid than it ever was... with\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  92%|███████████████████▍ | 1156/1250 [35:50<03:00,  1.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 324])\n",
      "Prompt: The game of hockey I play and watch has something\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▍ | 1157/1250 [35:52<03:04,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 368])\n",
      "Prompt: Lackawanna Blues is a moving story about a boy who\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▍ | 1158/1250 [35:53<02:57,  1.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: Awful, awful, awful times a hundred still doesn't begin to\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▍ | 1159/1250 [35:55<02:49,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: Instead of writing a paragraph, I'll give four good reasons\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▍ | 1160/1250 [35:57<02:44,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Most of this political thriller presented as a mostly run\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▌ | 1161/1250 [35:59<02:42,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: This is from much of the same creative team behind\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▌ | 1162/1250 [36:01<02:39,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: A really realistic, sensible movie by Ramgopal Verma . No\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▌ | 1163/1250 [36:02<02:37,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: I made it through half of this, but was not\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▌ | 1164/1250 [36:04<02:37,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 327])\n",
      "Prompt: I rented Dark Harvest (the first one) because it looked\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▌ | 1165/1250 [36:06<02:36,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: Johnny Knoxville has gone insane.<br /><br />In the first Jackass\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▌ | 1166/1250 [36:08<02:32,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Imagine the worst thing that could ever possibly be conceived\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▌ | 1167/1250 [36:10<02:34,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 339])\n",
      "Prompt: This really is a great film. Full of love and\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  93%|███████████████████▌ | 1168/1250 [36:12<02:31,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: Robert Jordan is a television star. Robert Jordan likes things\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▋ | 1169/1250 [36:13<02:27,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: I found this movie to be okay.<br /><br />On paper,\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▋ | 1170/1250 [36:15<02:27,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: I'm a Petty Officer 1st Class (E-6) and have been\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▋ | 1171/1250 [36:17<02:27,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 337])\n",
      "Prompt: The sort of \"little\" film which studios used to excel\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▋ | 1172/1250 [36:19<02:23,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 310])\n",
      "Prompt: Motorama viewers should already by keen on other offbeat b-grade\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▋ | 1173/1250 [36:21<02:21,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: This show was a really good one in many ways,\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▋ | 1174/1250 [36:23<02:17,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This was a great show...I don't remember much about about\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▋ | 1175/1250 [36:24<02:15,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Remake of the classic 1951 \"The Thing From Another World\".\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▊ | 1176/1250 [36:26<02:15,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: CHE! is a bad movie and deserves it reputation as\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▊ | 1177/1250 [36:28<02:12,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: While it comes no closer to the Tarzan of Edgar\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▊ | 1178/1250 [36:30<02:11,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: I like movies about quirky people. \"One Flew Over the\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▊ | 1179/1250 [36:32<02:09,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Just watched Hair after a lapse of 20 years. It\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▊ | 1180/1250 [36:33<02:06,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: it was very sensitive very deep. It's my favorite all\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  94%|███████████████████▊ | 1181/1250 [36:35<02:04,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: This is the best comedy period. It is so underrated!\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▊ | 1182/1250 [36:37<02:01,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: Not even original in the plot. Ho hum. There were\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▊ | 1183/1250 [36:39<02:01,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 319])\n",
      "Prompt: Honestly, people who gave this movie a ten would have\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▉ | 1184/1250 [36:41<01:58,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: I had never heard of this film until it came\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▉ | 1185/1250 [36:42<01:56,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: The fun that was present in the other 'movies' has\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▉ | 1186/1250 [36:44<01:54,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: Reading the other user comments, the review by A666333 has\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▉ | 1187/1250 [36:46<01:52,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: This movie is great from start to finish about a\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▉ | 1188/1250 [36:48<01:50,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 305])\n",
      "Prompt: Great British director Christopher Nolan (Momento, Insomnia), directs this odd\n",
      "Tokenized Prompt Shape: torch.Size([1, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▉ | 1189/1250 [36:50<01:50,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 332])\n",
      "Prompt: I have seen this movie twice and it's theme is\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|███████████████████▉ | 1190/1250 [36:53<02:08,  2.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 425])\n",
      "Prompt: I was very concerned about this film, it was scheduled\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|████████████████████ | 1191/1250 [36:54<01:59,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: I stumbled across this movie late at night on TV.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|████████████████████ | 1192/1250 [36:56<01:57,  2.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 351])\n",
      "Prompt: Begotten is, no doubt, someone's attempt at originality, but, what\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  95%|████████████████████ | 1193/1250 [36:58<01:51,  1.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: Right, here we go, you have probably read in previous\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████ | 1194/1250 [37:00<01:45,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: How do stories this bad get made. That's not a\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████ | 1195/1250 [37:02<01:42,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: I have some great memories watching \"Robin of Sherwood\" on\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████ | 1196/1250 [37:03<01:39,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 317])\n",
      "Prompt: Pretty.<br /><br />Pretty actresses and actors. Pretty bad script. Pretty\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████ | 1197/1250 [37:05<01:36,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 312])\n",
      "Prompt: If you are having trouble sleeping or just want to\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▏| 1198/1250 [37:07<01:37,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: Yes, the movie was that boring and insipid. after a\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▏| 1199/1250 [37:09<01:33,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Rare and auspicious are the moments in film-making when greatness\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▏| 1200/1250 [37:11<01:30,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: Hayao Miyazaki's latest and eighth film for Studio Ghibili, \"Gake\n",
      "Tokenized Prompt Shape: torch.Size([1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▏| 1201/1250 [37:13<01:28,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 325])\n",
      "Prompt: As social satire, Idiocracy is just as good as Office\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▏| 1202/1250 [37:15<01:30,  1.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 355])\n",
      "Prompt: There are a limited number of fans for movies in\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▏| 1203/1250 [37:16<01:28,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 328])\n",
      "Prompt: God, I never felt so insulted in my whole life\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▏| 1204/1250 [37:18<01:27,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 336])\n",
      "Prompt: Who will love my children has changed my heart, it\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▏| 1205/1250 [37:20<01:23,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: I saw this movie, when it first came out. Patty\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  96%|████████████████████▎| 1206/1250 [37:22<01:20,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: The only redeeming scene in this movie is when the\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▎| 1207/1250 [37:25<01:32,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 500])\n",
      "Prompt: As long as you go into this movie with the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▎| 1208/1250 [37:27<01:27,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 308])\n",
      "Prompt: This film could cure sleep disorders, thats how bad it\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▎| 1209/1250 [37:29<01:21,  1.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: I've always loved \"Gone With The Wind\" and have seen\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▎| 1210/1250 [37:31<01:26,  2.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 444])\n",
      "Prompt: I don't know what Dick steel was talking about, but\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▎| 1211/1250 [37:33<01:20,  2.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: It is now clear that the true golden age of\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▎| 1212/1250 [37:35<01:15,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: I find it almost touching how Star Trek fans try\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▍| 1213/1250 [37:36<01:10,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: This moody, creepy horror flick begins on a castle atop\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▍| 1214/1250 [37:38<01:07,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: I am a pretty much a sucker for those Ghost\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▍| 1215/1250 [37:40<01:04,  1.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Like a lot of movies involving little kids, this starts\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▍| 1216/1250 [37:42<01:01,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: A young girl becomes a war-time marine's pen-pal, and when\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▍| 1217/1250 [37:43<00:58,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 304])\n",
      "Prompt: It's not often I feel strongly enough to post something\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  97%|████████████████████▍| 1218/1250 [37:45<00:56,  1.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Prompt: I loved this film, Independent film-making at its best. The\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▍| 1219/1250 [37:47<00:54,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: This episode was boring and was not even in the\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▍| 1220/1250 [37:49<00:53,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 313])\n",
      "Prompt: Although this movie (and I use the term loosely) was\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▌| 1221/1250 [37:51<00:51,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 309])\n",
      "Prompt: This is Clive Barker's masterpiece in my opinion. The movie\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▌| 1222/1250 [37:52<00:50,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: The Happiest Days of Your Life showcases some of Britain's\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▌| 1223/1250 [37:54<00:48,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 314])\n",
      "Prompt: Leatherheads is an apt title, however a leather strap would\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▌| 1224/1250 [37:56<00:46,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: I go this game and it is alright I guess.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▌| 1225/1250 [37:58<00:44,  1.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Chris Noth plays a maniac who wrote a children's book\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▌| 1226/1250 [38:00<00:45,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 370])\n",
      "Prompt: Cleopatra 2525 is a very funny, entertaining show. You shouldn't\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▌| 1227/1250 [38:02<00:42,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 322])\n",
      "Prompt: This film was released soon after the Conan films, a\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▋| 1228/1250 [38:03<00:40,  1.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 316])\n",
      "Prompt: I've been waiting for this movie for SO many years!\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▋| 1229/1250 [38:06<00:41,  1.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 389])\n",
      "Prompt: STAR RATING: ***** Jodie Marsh **** Michelle Marsh *** Kym\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▋| 1230/1250 [38:07<00:38,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: \"The Dresser\" is a small but absolutely wonderful film, brilliantly\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  98%|████████████████████▋| 1231/1250 [38:09<00:36,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 326])\n",
      "Prompt: You know those movies that are so unspeakably bad that\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▋| 1232/1250 [38:11<00:34,  1.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 355])\n",
      "Prompt: Loved today's show!!! It was a variety and not solely\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▋| 1233/1250 [38:13<00:32,  1.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: a really awful movie about a 30 meters long shark.\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▋| 1234/1250 [38:15<00:30,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 318])\n",
      "Prompt: Not a stunner, but a good movie to see once\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▋| 1235/1250 [38:17<00:28,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 329])\n",
      "Prompt: o dear god i suffered having to watch this film\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▊| 1236/1250 [38:19<00:26,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 315])\n",
      "Prompt: Norma had spent most of the 20s playing beautiful ingenues\n",
      "Tokenized Prompt Shape: torch.Size([1, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▊| 1237/1250 [38:21<00:23,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 306])\n",
      "Prompt: There is not one character on this sitcom with any\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▊| 1238/1250 [38:23<00:22,  1.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 351])\n",
      "Prompt: I haven't actually seen a lot of movies with Holly\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▊| 1239/1250 [38:24<00:20,  1.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Oh yes, I have to agree with the others who\n",
      "Tokenized Prompt Shape: torch.Size([1, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▊| 1240/1250 [38:26<00:18,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: Yet another \"gay\" film ruined by asinine politics. Luigi's final\n",
      "Tokenized Prompt Shape: torch.Size([1, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▊| 1241/1250 [38:28<00:16,  1.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 331])\n",
      "Prompt: Contains Spoilers<br /><br />Luchino Visconti's film adaptation of Thomas Mann's\n",
      "Tokenized Prompt Shape: torch.Size([1, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▊| 1242/1250 [38:30<00:14,  1.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: Hey, I'm a fan of so-bad-so-good movies but there's nothing\n",
      "Tokenized Prompt Shape: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress:  99%|████████████████████▉| 1243/1250 [38:31<00:12,  1.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 301])\n",
      "Prompt: It's exactly what I expected from it. Relaxing, humorous and\n",
      "Tokenized Prompt Shape: torch.Size([1, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress: 100%|████████████████████▉| 1244/1250 [38:33<00:10,  1.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 340])\n",
      "Prompt: Some twenty or so years ago, Charles Bukowski was a\n",
      "Tokenized Prompt Shape: torch.Size([1, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress: 100%|████████████████████▉| 1245/1250 [38:35<00:09,  1.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 311])\n",
      "Prompt: I viewed this movie for the first time last night\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress: 100%|████████████████████▉| 1246/1250 [38:37<00:07,  1.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 307])\n",
      "Prompt: This film has a premise that is good enough to\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress: 100%|████████████████████▉| 1247/1250 [38:39<00:05,  1.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 410])\n",
      "Prompt: This is probable one of the worst movies i have\n",
      "Tokenized Prompt Shape: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress: 100%|████████████████████▉| 1248/1250 [38:41<00:03,  1.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 303])\n",
      "Prompt: Well, where do I start...<br /><br />As one of the\n",
      "Tokenized Prompt Shape: torch.Size([1, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress: 100%|████████████████████▉| 1249/1250 [38:43<00:02,  2.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 401])\n",
      "Prompt: I'M BOUT IT(1997)<br /><br />Developed & published by No Limit\n",
      "Tokenized Prompt Shape: torch.Size([1, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Progress: 100%|█████████████████████| 1250/1250 [38:45<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Tokens Shape: torch.Size([1, 302])\n",
      "Sample Predictions:\n",
      "Pred: and the movie. The roles are not quite as good as the movie, but they are not as good. The dialogue is not quite good. I think it's a good movie. I'm not really sure it's the best. The characters are not particularly good. There is a lot of potential to be lost in this. The movie is not really good. It is not a good film. I don't think it is a good one. The main problem is the fact that it is not good. A lot of fun. The film is not particularly fun. I want to see it. The plot is not as fun. It's not a fun movie. It was not a very fun movie, though it was a fun one. I can assure you that it was not quite fun. A good one, but it was quite a fun and I think the main problem with the movie is the direction of the film. The direction of this film is the main issue. The fact that the direction is not very good. In fact, it is the most fun and the film is to watch. The action is not much fun. There are some of the best roles in the movie and the best supporting roles. The role is not the best of the movie; it is also the most entertaining. The character is not so much fun to watch as the main plot. The story is not about the plot. It has a lot to be done with the best direction. The best direction is the best way to watch the movie as it is about the direction and the most exciting. The ending is not too much fun, though the ending is a bit of fun to see.\n",
      "Ground: and Murphy playing a police and an actor. Although they share the most screen time together, they do not reach their expected performances such films like Analyse This, Meet the Parents, Dr Doolittle and Nutty Professor. The film starts interestingly but becomes a thin, ordinary comedy which is quite disappointing.It feels like especially De Niro doesn't enjoy being in Showtime. Thats a shame because he really shows his feelings thats what I think. Unfortunately, if the idea had been used cleverly this could have been a more interesting piece of work and could be followed with a sequel like any other popular Hollywood movie. Well, I don't think there would be a sequel to this at least casting De Niro and Murpy again. ** out of *****\n",
      "\n",
      "Pred: her family. She is also the mother of the children. She was also the father of the child. She's also the child of the family. The child is also a child of a family. I think it's a child who is not a child. I'm not a kid. I don't think it is a child, but I'm a child with a family, but a child in the family, who is a kid with a child and a child on the other side of the road. I want to see it as a child's family. A child with an child on a side of road. A kid with an adult on the side of a road. The children are also the children of a child or child with whom they are not a children. I believe it's not a family of children. The family is also not a \"child\" in the sense of the word \"child\". I think the family is not \"child.\" In fact, I think they're not \"Child\" in The sense of The word \"Child.\" In the sense, I'm also not an \"Child in the Family.\" I think that the family will be \"Child In the Family\" in a sense ofthe word \"Children\" in an earlier post. I also think that it's an \"child in theFamily.\" The family will not be \"child-in the Family\". In fact there is a lot of potential for the family to be involved in the story.\n",
      "Ground: save him from the Sauce's assassin Shax. While Phoebe looks in the Book of Shadow how to vanquish the demon, Prue and Piper fight and chase Shax on the streets to destroy him. However, they are filmed and exposed live in the television news as witches. They become national sensation with a crowd in front of their house. Phoebe trusts on Cole and goes to the underworld with Leo to ask him to summon Tempus and revert time while a fanatic woman shots Piper, who dies. The source proposes Phoebe to stay with him and in return he would save her sister. Phoebe accepts the deal, and the time is reverted to the moment Shax is attacking Prue, Piper and Dr. Griffits.<br /><br />\"All Hell Breaks Loose\" is a good but incoherent episode. With Piper dead and The Power of Three destroyed, why should The Source revert time to save her? But this dramatic show is certainly one of the best of the Third Season and let the viewers anxiously waiting for the next episode. My vote is nine.<br /><br />Title (Brazil): \"Voltando no Tempo\" (\"Back in Time\")\n",
      "\n",
      "Pred: I think it's a classic movie. The film is not a classic. The movie is not the classic. It is not an original. The original is a classic, but a classic of the movie. A classic of a classic film. The main problem is that it is not as much of a movie as the original. It's not a movie that is a masterpiece. The plot is not quite as much as the movie is. The dialogue is not particularly good. The characters are not quite good. I believe they are not as good as the film. I'm not really sure that they're not as bad as the plot. The story is not about the plot, but it is about the fact that the film is a very good film. It was a classic and classic of The classic. I can't say it's not about a classic but a masterpiece of the classic, the film, and the fact is that the main problem with the film was not the plot or the plot of the original, but the fact of the film's original direction. The direction was not quite so much of the plot as the direction of the main plot. It wasn't about the direction, but its direction was a masterpiece, and it was about the main issue with the direction. It could have been about the original direction of The original direction, which was not about The direction of a masterpiece or the direction and direction of an original film. A masterpiece of a true masterpiece of an American film.\n",
      "Ground: I mean it doesn't take much to make a good zombie movie besides good special effects, lots of blood and gore, some scary moments and a decent plot. Does House of the Dead 2 do any of these things right? No, not one. Of course, its not as bad as its predecessor, from Uwe Bowle and thats the only thing about this movie that scares me.<br /><br />The dialog in this movie is notorious, with such lines as \"What do you do for a living?\" in response \"I kill zombies\" and \"I was never a disk jockey, I was a soldier.\" The special effects are embarrassing even for a made for TV movie, I mean seriously, the zombies all look like they have bloody lips are hyped up on crack. The army base in this movie, is a parking garage, with a desk and a open gated room. This movie is so low budget that they couldn't even get co-ed locker rooms. In fact it seems like this entire movie was filmed in a middle school.<br /><br />Also, why is it that the all the female soldiers in this movie are models? And for that matter why is everyone in this movie so clueless at to what is going on that they simply just stand around letting the zombies kill them. Heck one guy even trys to give food to the zombie.<br /><br />Overall, this movie makes even the worst of Scifi Channel movies looks fantastic.\n",
      "\n",
      "Pred: The film is a masterpiece of the classic \"The Wind of the Wind.\" The film was a masterpiece. The main problem is that it was not a masterpiece, but a masterpiece by the director. The movie is a classic \"Wind of the wind.\" The main issue is that the film is not a classic. The plot is not quite as good as the original \"Wind Of The Wind.\" It is a very good film. The ending is not as good. The dialogue is not particularly good. It is not an original \"wind of the sun.\" The ending was not quite good. There is a lot of potential to be lost. The story is not much of a story. The characters are not quite like the original. The original \"Witchy\" and the ending is a bit of a bit-of-of a tale. The character is not too much of an original. It's not a \"WITCHy\" or a bity.\" The plot was not too bad. The script is not overly-br /><br / />- /><BR />©©© is not very good. In fact, it's not quite a masterpiece! The plot, the main problem with \"Witchesy\" is the fact that it's a bit too much. The premise is not entirely original. There are some of the best and most excellent roles. The fact is that they are not too far from the original, but they are quite good, and they are also quite good for the film.\n",
      "Ground: The only good that comes from this kind of pointless drivel, is the fact that seeing films like this get distribution makes indy horror filmmakers like me confident that my upcoming feature will make the cut too. I mean, if this represents the market for indy horror, I could make a fortune videotaping myself taking out the garbage for 83 minutes. <br /><br />A complete list of what this film lacks would take way too long to write out. But, the highlites are: no story, terrible acting, awful cinematography, and virtually no editing. That last one bothered me the most. As an editor myself, this film drove me absolutely crazy because it had almost no editing at all. Every scene was shot in a master. They had absolutely no coverage at all. For anyone who doesn't know...\"coverage\" is shooting a scene from multiple angles to have cutting options when editing to make for a desirable viewing experience. Yeah, this movie had none of that. I'm talking about even the simplest of scenes. Example: an ordinary conversation scene between two people sitting at a table would typically start out with a master establishing who's in the scene and where they are. Then, as the conversation goes on, you would cut back and forth to over-the-shoulder shots as the conversation continues. You may even throw in a cutaway shot or two of something on the table, or in someone's hand. Anything. This is \"Film 101\" stuff guys. It seems as though these people had no idea this is how films work. Every shot was a camera lock-down. No movement, no cutting, no nothing. If I was teaching a course in filmmaking, this would be the visual aid for my \"What not to do\" lesson.<br /><br />In closing, don't waste your time folks. The only amazing this about this film is that it ever scored distribution at all.<br /><br /> <br /><br />\n",
      "\n",
      "Pred: space-based space-exploitation vehicle. The film is a classic film. The movie is a masterpiece of the classic film, but it is also a classic movie. The main problem is that it is not a classic. The plot is not quite as simple as the film. It is a very simple and very much like the movie. It's a classic, but a classic of the movie, but with a lot of potential. The story is not as simple. The ending is not really as simple, but the ending is a bit of a bit-of-a-a.-a-hoot-out. The dialogue is not particularly good. The script is not very good. It was a classic and a classic in the film, and it is a good film. A classic of a classic-style film. I think it's a masterpiece. The best film. If you're looking for a classic sci-fi film, you'll find it in the best place. The original film was a masterpiece, but its director, John Dutton, who is also the director, was a brilliant and brilliant director. He was also a brilliant director, and he was also an excellent director. The director was also the best of the best. The fact is that he was not a movie. I believe it's not a masterpiece but a masterpiece in the way of a sci-fantasy film. This is a film. There is a lot to be said about it. The first thing I think is that John Denny Denny's \"The Story of the American Dream\" is a wonderful piece of sci-Fi. The premise is simple. It makes the film a classic American Dream. The characters are not as much as the original. The character is not the original, but an excellent piece of fantasy. The cast is not so much as a fantasy fantasy fantasy.\n",
      "Ground: DNA machine, a powerful and revolutionary invent, fall in a jungle in Pacific. The insurance company sponsors a rescue expedition, commanded by Harlan Knowles (Lance Henriksen), the owner of a huge corporation, which owns the prototype, and father of one of the scientist. There, the group finds the rests of the plane five miles far from the expected location and the machine and the remains of the persons. Further, they realize that a Sasquatch, a kind of Big Foot, is chasing them. This movie is so ridiculous that I do not know what I am doing, spending my time again in this garbage. The direction is awful, the actors and the lines are horrible, copying parts of `The Predator' and even `The Blair Witch Project'. To summarize how bad this movie is, its best scene is when Marla Lawson, the character of Andrea Roth, is wounded, and the guide of the expedition says that she needs to have an injection of tetanus vaccine. Andrea undresses her jeans, and the guide says: 'Nice butts, but the shot needs to be in your arm'. Ridiculous! My vote is two.<br /><br />Title (Brazil): `Sasquatch, O AbominÃ¡vel' (`Sasquatch, The Abominable')<br /><br />\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.02008190923851741, 'precisions': [0.24351890858420558, 0.04634772854131329, 0.007895423699321386, 0.001825086343770972], 'brevity_penalty': 1.0, 'length_ratio': 1.1171453826358992, 'translation_length': 370308, 'reference_length': 331477}\n"
     ]
    }
   ],
   "source": [
    "## os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# # Load model and set to evaluation mode\n",
    "model.load_state_dict(torch.load('./model_epoch_7_2024-06-05_15-56-39.pt'))\n",
    "model.eval()\n",
    "\n",
    "def test(model, testDL, max_length):\n",
    "    pred = []\n",
    "    ground = []\n",
    "  \n",
    "    for text in tqdm(testDL, desc=\"Testing Progress\"):\n",
    "        # To Use 10 word\n",
    "        text = text[0]\n",
    "        prompt = \" \".join(text.split()[:10])\n",
    "        temp_ground = \" \".join(text.split()[10:])\n",
    "        ground.append([temp_ground])\n",
    "        \n",
    "        # Tokenize Prompt\n",
    "        tokenized = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "      \n",
    "        ground_tokens = tokenizer.encode(temp_ground, add_special_tokens=False)\n",
    "        target_length = len(ground_tokens)\n",
    "       \n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        print(f\"Tokenized Prompt Shape: {tokenized.shape}\")\n",
    "        # print(f\"Ground Truth Tokens: {ground_tokens}\")\n",
    "        \n",
    "        try:\n",
    "            # gen_token = model.module.generate(\n",
    "            #     input_ids=tokenized, \n",
    "            \n",
    "            #     max_length=max_length,\n",
    "            #     # no_repeat_ngram_size=3,\n",
    "            #     # num_return_sequences=1,  # 한 개의 시퀀스만 생성\n",
    "            #     # no_repeat_ngram_size=2,  # 반복 방지를 위해 N그램 설정\n",
    "            #     # early_stopping=True      # 조기 종료를 사용\n",
    "            # )\n",
    "            gen_token = model.module.generate(\n",
    "                input_ids=tokenized, \n",
    "                min_length=300,    \n",
    "                max_length=500,\n",
    "                # num_return_sequences=1,  \n",
    "                no_repeat_ngram_size=3,  \n",
    "                # # early_stopping=True,    \n",
    "                # num_beams=5,             \n",
    "                # temperature=0.5,         \n",
    "                # top_k=50,                \n",
    "                # top_p=0.95               \n",
    "            )\n",
    "            print(f\"Generated Tokens Shape: {gen_token.shape}\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error during generation: {e}\")\n",
    "            print(f\"Tokenized input: {tokenized}\")\n",
    "            continue\n",
    "        \n",
    "        # Decode the Generated Text\n",
    "        temp_pred = tokenizer.batch_decode(gen_token, skip_special_tokens=True)[0]\n",
    "        # Comparation start from the 11th word. \n",
    "        temp_pred = \" \".join(temp_pred.split()[10:])\n",
    "        \n",
    "        # Pred should be wrapped by list\n",
    "        pred.append(temp_pred)\n",
    "    print(\"Sample Predictions:\")\n",
    "    for i in range(min(5, len(pred))):\n",
    "        print(f\"Pred: {pred[i]}\")\n",
    "        print(f\"Ground: {ground[i][0]}\\n\")\n",
    "        \n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    results = bleu.compute(predictions=pred, references=ground)\n",
    "    print(results)\n",
    "\n",
    "\n",
    "test(model, movRevTestSubDL, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5a518-de64-493d-9278-044c62c518e6",
   "metadata": {},
   "source": [
    "<h2>BERT SENTIMENT CLASSIFICATION & Analysis and Visulation </h2>\n",
    "All the needed explanation is in submitted report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "365eb629-8219-448e-a07a-65c501aa3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = pipeline(\"text-classification\", model=\"textattack/bert-base-uncased-SST-2\")\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-SST-2\")\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-SST-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6a0ada9e-f2d0-4234-a7ea-eed07371bbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.9986995458602905}, {'label': 'LABEL_0', 'score': 0.9965370893478394}, {'label': 'LABEL_0', 'score': 0.9843654632568359}, {'label': 'LABEL_0', 'score': 0.9980173110961914}, {'label': 'LABEL_0', 'score': 0.9946562051773071}, {'label': 'LABEL_0', 'score': 0.9970692992210388}, {'label': 'LABEL_0', 'score': 0.6378469467163086}, {'label': 'LABEL_0', 'score': 0.9979678988456726}, {'label': 'LABEL_0', 'score': 0.8281629085540771}, {'label': 'LABEL_0', 'score': 0.9966611862182617}, {'label': 'LABEL_0', 'score': 0.9566648006439209}, {'label': 'LABEL_1', 'score': 0.9935171604156494}, {'label': 'LABEL_1', 'score': 0.6264100670814514}, {'label': 'LABEL_0', 'score': 0.9838851690292358}, {'label': 'LABEL_0', 'score': 0.7056890726089478}, {'label': 'LABEL_0', 'score': 0.9973963499069214}, {'label': 'LABEL_0', 'score': 0.9987564086914062}, {'label': 'LABEL_0', 'score': 0.9559622406959534}, {'label': 'LABEL_0', 'score': 0.9972262978553772}, {'label': 'LABEL_1', 'score': 0.6421734690666199}, {'label': 'LABEL_0', 'score': 0.9250929951667786}, {'label': 'LABEL_0', 'score': 0.9961082339286804}, {'label': 'LABEL_1', 'score': 0.9993765950202942}, {'label': 'LABEL_0', 'score': 0.9953845143318176}, {'label': 'LABEL_0', 'score': 0.9974597096443176}, {'label': 'LABEL_0', 'score': 0.9986664056777954}, {'label': 'LABEL_0', 'score': 0.9940552711486816}, {'label': 'LABEL_0', 'score': 0.8534249067306519}, {'label': 'LABEL_0', 'score': 0.7230114936828613}, {'label': 'LABEL_0', 'score': 0.9978466033935547}]\n",
      "Accuracy: 0.9\n",
      "Text: The movie's themes were simple and simple. The main problem with this film is that it is not a simple film, but it is a very good one. The plot is simple, but the main problem is not simple. It is a simple movie, but I think it deserves to be considered as a classic.\n",
      "Label: LABEL_1\n",
      "True:LABEL_0\n",
      "Text: The editing of the movie was excellent. The dialogue is excellent, but the dialogue is not as good as it was in the original film. The main problem is that it is not a good movie. The plot is not quite good. The direction of the film is not very good.\n",
      "Label: LABEL_0\n",
      "True:LABEL_1\n",
      "Text: The movie's rewatch value is one of the best things I've ever seen in a movie. I'm glad that I'm not the only one who has seen this movie, but I think it's the best thing I've seen in the movie.\n",
      "Label: LABEL_1\n",
      "True:LABEL_0\n",
      "POS 5 NEG 25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-SST-2\")\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-SST-2\")\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model=model2, tokenizer=tokenizer2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = classifier(gen_text)\n",
    "print(results)\n",
    "# Convert results to labels\n",
    "labels = [\"LABEL_1\" if result['label'] == 'LABEL_1' else \"LABEL_0\" for result in results]\n",
    "\n",
    "\n",
    "true_labels = [\n",
    "    \"LABEL_1\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\",\n",
    "    \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_1\", \"LABEL_0\",\n",
    "    \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_1\", \"LABEL_0\",\n",
    "    \"LABEL_1\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\", \"LABEL_0\",\n",
    "    \"LABEL_0\", \"LABEL_0\"\n",
    "]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "pos = 0 \n",
    "neg = 0\n",
    "\n",
    "for text, label, true in zip(gen_text, labels, true_labels):\n",
    "    if(label == \"LABEL_1\") :\n",
    "        pos = pos +1\n",
    "    else: neg = neg +1\n",
    "   \n",
    "    if(label != true):\n",
    "        print(f\"Text: {text}\\nLabel: {label}\\nTrue:{true}\")\n",
    "print(\"POS\",pos,\"NEG\",neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc32cae-8703-4565-a505-e75d77b95f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT BERT Env",
   "language": "python",
   "name": "gpt_bert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
